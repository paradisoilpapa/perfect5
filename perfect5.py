# -*- coding: utf-8 -*-
import streamlit as st
import pandas as pd
import numpy as np
import unicodedata, re, math, random, json

# ==============================
# ãƒšãƒ¼ã‚¸è¨­å®š
# ==============================
st.set_page_config(page_title="ãƒ´ã‚§ãƒ­ãƒ“ï¼šç´šåˆ¥Ã—æ—¥ç¨‹ãƒ€ã‚¤ãƒŠãƒŸã‚¯ã‚¹ï¼ˆ5ã€œ9è»Šãƒ»è²·ã„ç›®ä»˜ãï¼‰", layout="wide")

# ==============================
# å®šæ•°
# ==============================
WIND_COEFF = {
    "å·¦ä¸Š": -0.03, "ä¸Š": -0.05, "å³ä¸Š": -0.035,
    "å·¦": +0.05,  "å³": -0.05,
    "å·¦ä¸‹": +0.035, "ä¸‹": +0.05, "å³ä¸‹": +0.035,
    "ç„¡é¢¨": 0.0
}
BASE_BY_KAKU = {"é€ƒ":1.58, "æ²":1.65, "å·®":1.79, "ãƒ":1.45}

KEIRIN_DATA = {
    "å‡½é¤¨":{"bank_angle":30.6,"straight_length":51.3,"bank_length":400},
    "é’æ£®":{"bank_angle":32.3,"straight_length":58.9,"bank_length":400},
    "ã„ã‚ãå¹³":{"bank_angle":32.9,"straight_length":62.7,"bank_length":400},
    "å¼¥å½¦":{"bank_angle":32.4,"straight_length":63.1,"bank_length":400},
    "å‰æ©‹":{"bank_angle":36.0,"straight_length":46.7,"bank_length":335},
    "å–æ‰‹":{"bank_angle":31.5,"straight_length":54.8,"bank_length":400},
    "å®‡éƒ½å®®":{"bank_angle":25.8,"straight_length":63.3,"bank_length":500},
    "å¤§å®®":{"bank_angle":26.3,"straight_length":66.7,"bank_length":500},
    "è¥¿æ­¦åœ’":{"bank_angle":29.4,"straight_length":47.6,"bank_length":400},
    "äº¬ç‹é–£":{"bank_angle":32.2,"straight_length":51.5,"bank_length":400},
    "ç«‹å·":{"bank_angle":31.2,"straight_length":58.0,"bank_length":400},
    "æ¾æˆ¸":{"bank_angle":29.8,"straight_length":38.2,"bank_length":333},
    "å·å´":{"bank_angle":32.2,"straight_length":58.0,"bank_length":400},
    "å¹³å¡š":{"bank_angle":31.5,"straight_length":54.2,"bank_length":400},
    "å°ç”°åŸ":{"bank_angle":35.6,"straight_length":36.1,"bank_length":333},
    "ä¼Šæ±":{"bank_angle":34.7,"straight_length":46.6,"bank_length":333},
    "é™å²¡":{"bank_angle":30.7,"straight_length":56.4,"bank_length":400},
    "åå¤å±‹":{"bank_angle":34.0,"straight_length":58.8,"bank_length":400},
    "å²é˜œ":{"bank_angle":32.3,"straight_length":59.3,"bank_length":400},
    "å¤§å£":{"bank_angle":30.6,"straight_length":56.0,"bank_length":400},
    "è±Šæ©‹":{"bank_angle":33.8,"straight_length":60.3,"bank_length":400},
    "å¯Œå±±":{"bank_angle":33.7,"straight_length":43.0,"bank_length":333},
    "æ¾å‚":{"bank_angle":34.4,"straight_length":61.5,"bank_length":400},
    "å››æ—¥å¸‚":{"bank_angle":32.3,"straight_length":62.4,"bank_length":400},
    "ç¦äº•":{"bank_angle":31.5,"straight_length":52.8,"bank_length":400},
    "å¥ˆè‰¯":{"bank_angle":33.4,"straight_length":38.0,"bank_length":333},
    "å‘æ—¥ç”º":{"bank_angle":30.5,"straight_length":47.3,"bank_length":400},
    "å’Œæ­Œå±±":{"bank_angle":32.3,"straight_length":59.9,"bank_length":400},
    "å²¸å’Œç”°":{"bank_angle":30.9,"straight_length":56.7,"bank_length":400},
    "ç‰é‡":{"bank_angle":30.6,"straight_length":47.9,"bank_length":400},
    "åºƒå³¶":{"bank_angle":30.8,"straight_length":57.9,"bank_length":400},
    "é˜²åºœ":{"bank_angle":34.7,"straight_length":42.5,"bank_length":333},
    "é«˜æ¾":{"bank_angle":33.3,"straight_length":54.8,"bank_length":400},
    "å°æ¾å³¶":{"bank_angle":29.8,"straight_length":55.5,"bank_length":400},
    "é«˜çŸ¥":{"bank_angle":24.5,"straight_length":52.0,"bank_length":500},
    "æ¾å±±":{"bank_angle":34.0,"straight_length":58.6,"bank_length":400},
    "å°å€‰":{"bank_angle":34.0,"straight_length":56.9,"bank_length":400},
    "ä¹…ç•™ç±³":{"bank_angle":31.5,"straight_length":50.7,"bank_length":400},
    "æ­¦é›„":{"bank_angle":32.0,"straight_length":64.4,"bank_length":400},
    "ä½ä¸–ä¿":{"bank_angle":31.5,"straight_length":40.2,"bank_length":400},
    "åˆ¥åºœ":{"bank_angle":33.7,"straight_length":59.9,"bank_length":400},
    "ç†Šæœ¬":{"bank_angle":34.3,"straight_length":60.3,"bank_length":400},
    "æ‰‹å…¥åŠ›":{"bank_angle":30.0,"straight_length":52.0,"bank_length":400},
}

# ==============================
# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
# ==============================
def clamp(x,a,b): return max(a, min(b, x))

def zscore_list(arr):
    arr = np.array(arr, dtype=float)
    m, s = float(np.mean(arr)), float(np.std(arr))
    return np.zeros_like(arr) if s==0 else (arr-m)/s

def zscore_val(x, xs):
    xs = np.array(xs, dtype=float); m, s = float(np.mean(xs)), float(np.std(xs))
    return 0.0 if s==0 else (float(x)-m)/s

def extract_car_list(s, nmax):
    s = str(s or "").strip()
    return [int(c) for c in s if c.isdigit() and 1 <= int(c) <= nmax]

def build_line_maps(lines):
    labels = "ABCDEFG"
    line_def = {labels[i]: lst for i,lst in enumerate(lines) if lst}
    car_to_group = {c:g for g,mem in line_def.items() for c in mem}
    return line_def, car_to_group

def role_in_line(car, line_def):
    for g, mem in line_def.items():
        if car in mem:
            if len(mem)==1: return 'single'
            idx = mem.index(car)
            return ['head','second','thirdplus'][idx] if idx<3 else 'thirdplus'
    return 'single'

def pos_coeff(role, line_factor):
    base = {'head':1.0,'second':0.7,'thirdplus':0.5,'single':0.9}.get(role,0.9)
    return base * line_factor

def tenscore_correction(tenscores):
    n = len(tenscores)
    if n<=2: return [0.0]*n
    df = pd.DataFrame({"å¾—ç‚¹":tenscores})
    df["é †ä½"] = df["å¾—ç‚¹"].rank(ascending=False, method="min").astype(int)
    hi = min(n,8); baseline = df[df["é †ä½"].between(2,hi)]["å¾—ç‚¹"].mean()
    def corr(row): return round(abs(baseline-row["å¾—ç‚¹"])*0.03, 3) if row["é †ä½"] in [2,3,4] else 0.0
    return df.apply(corr, axis=1).tolist()

def wind_adjust(wind_dir, wind_speed, role, prof_escape):
    if wind_dir=="ç„¡é¢¨" or wind_speed==0: return 0.0
    wd = WIND_COEFF.get(wind_dir,0.0)
    pos_multi = {'head':0.32,'second':0.30,'thirdplus':0.25,'single':0.30}.get(role,0.30)
    coeff = 0.4 + 0.6*prof_escape
    val = wind_speed * wd * pos_multi * coeff
    return round(clamp(val, -0.05, 0.05), 3)

def bank_character_bonus(bank_angle, straight_length, prof_escape, prof_sashi):
    straight_factor = (float(straight_length)-40.0)/10.0
    angle_factor = (float(bank_angle)-25.0)/5.0
    total = clamp(-0.1*straight_factor + 0.1*angle_factor, -0.05, 0.05)
    return round(total*prof_escape - 0.5*total*prof_sashi, 3)

def bank_length_adjust(bank_length, prof_oikomi):
    delta = clamp((float(bank_length)-411.0)/100.0, -0.05, 0.05)
    return round(delta*prof_oikomi, 3)

def compute_lineSB_bonus(line_def, S, B, line_factor=1.0, exclude=None, cap=0.06, enable=True):
    if not enable or not line_def:
        return {g:0.0 for g in line_def.keys()} if line_def else {}, {}
    w_pos_base = {'head':1.0,'second':0.4,'thirdplus':0.2,'single':0.7}
    Sg, Bg = {}, {}
    for g, mem in line_def.items():
        s=b=0.0
        for car in mem:
            if exclude is not None and car==exclude: continue
            w = w_pos_base[role_in_line(car, line_def)] * line_factor
            s += w*float(S.get(car,0)); b += w*float(B.get(car,0))
        Sg[g]=s; Bg[g]=b
    raw={}
    for g in line_def.keys():
        s, b = Sg[g], Bg[g]
        ratioS = s/(s+b+1e-6)
        raw[g] = (0.6*b + 0.4*s) * (0.6 + 0.4*ratioS)
    zz = zscore_list(list(raw.values())) if raw else []
    bonus={g: clamp(0.02*float(zz[i]), -cap, cap) for i,g in enumerate(raw.keys())}
    return bonus, raw

def input_float_text(label: str, key: str, placeholder: str = "") -> float | None:
    s = st.text_input(label, value=st.session_state.get(key, ""), key=key, placeholder=placeholder)
    ss = unicodedata.normalize("NFKC", str(s)).replace(",", "").strip()
    if ss == "": return None
    if not re.fullmatch(r"[+-]?\d+(\.\d+)?", ss):
        st.warning(f"{label} ã¯æ•°å€¤ã§å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆå…¥åŠ›å€¤: {s}ï¼‰")
        return None
    return float(ss)

# ==============================
# ã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼šé–‹å‚¬æƒ…å ± / ãƒãƒ³ã‚¯ãƒ»é¢¨ãƒ»é ­æ•°
# ==============================
st.sidebar.header("é–‹å‚¬æƒ…å ± / ãƒãƒ³ã‚¯ãƒ»é¢¨ãƒ»é ­æ•°")
n_cars = st.sidebar.selectbox("å‡ºèµ°æ•°ï¼ˆ5ã€œ9ï¼‰", [5,6,7,8,9], index=2)

track_names = list(KEIRIN_DATA.keys())
track = st.sidebar.selectbox("ç«¶è¼ªå ´ï¼ˆãƒ—ãƒªã‚»ãƒƒãƒˆï¼‰", track_names, index=track_names.index("å·å´") if "å·å´" in track_names else 0)
info = KEIRIN_DATA[track]

wind_dir = st.sidebar.selectbox("é¢¨å‘", ["ç„¡é¢¨","å·¦ä¸Š","ä¸Š","å³ä¸Š","å·¦","å³","å·¦ä¸‹","ä¸‹","å³ä¸‹"], 0)
wind_speed = st.sidebar.number_input("é¢¨é€Ÿ(m/s)", 0.0, 30.0, 3.0, 0.1)
straight_length = st.sidebar.number_input("ã¿ãªã—ç›´ç·š(m)", 30.0, 80.0, float(info["straight_length"]), 0.1)
bank_angle = st.sidebar.number_input("ãƒãƒ³ã‚¯è§’(Â°)", 20.0, 45.0, float(info["bank_angle"]), 0.1)
bank_length = st.sidebar.number_input("å‘¨é•·(m)", 300.0, 500.0, float(info["bank_length"]), 0.1)

base_laps = st.sidebar.number_input("å‘¨å›ï¼ˆé€šå¸¸4ï¼‰", 1, 10, 4, 1)
day_label = st.sidebar.selectbox("é–‹å‚¬æ—¥", ["åˆæ—¥","2æ—¥ç›®","æœ€çµ‚æ—¥"], 0)
eff_laps = int(base_laps) + {"åˆæ—¥":1,"2æ—¥ç›®":2,"æœ€çµ‚æ—¥":3}[day_label]

race_no = st.sidebar.selectbox("ãƒ¬ãƒ¼ã‚¹ç•ªå·", list(range(1,13)), 0)
race_time = st.sidebar.selectbox("é–‹å‚¬åŒºåˆ†", ["ãƒ¢ãƒ¼ãƒ‹ãƒ³ã‚°","ãƒ‡ã‚¤","ãƒŠã‚¤ã‚¿ãƒ¼","ãƒŸãƒƒãƒ‰ãƒŠã‚¤ãƒˆ"], 1)
race_class = st.sidebar.selectbox("ç´šåˆ¥", ["ï¼³ç´š","ï¼¡ç´š","ï¼¡ç´šãƒãƒ£ãƒ¬ãƒ³ã‚¸","ã‚¬ãƒ¼ãƒ«ã‚º"], 0)

# ä¼šå ´styleï¼ˆå…ˆè¡Œâ‡„å·®ã—ï¼‰
angles = [KEIRIN_DATA[k]["bank_angle"] for k in KEIRIN_DATA]
straights = [KEIRIN_DATA[k]["straight_length"] for k in KEIRIN_DATA]
lengths = [KEIRIN_DATA[k]["bank_length"] for k in KEIRIN_DATA]
angle_z = zscore_val(bank_angle, angles)
straight_z = zscore_val(straight_length, straights)
length_z = zscore_val(bank_length, lengths)
style_raw = clamp(0.50*angle_z - 0.35*straight_z - 0.30*length_z, -1.0, +1.0)

override = st.sidebar.slider("ä¼šå ´ãƒã‚¤ã‚¢ã‚¹è£œæ­£ï¼ˆâˆ’2å·®ã— â†â†’ +2å…ˆè¡Œï¼‰", -2.0, 2.0, 0.0, 0.1)
style = clamp(style_raw + 0.25*override, -1.0, +1.0)

# ç´šåˆ¥ä¿‚æ•°ï¼ˆã‚¹ã‚³ã‚¢åºƒãŒã‚Š/ãƒ©ã‚¤ãƒ³çµæŸï¼‰
CLASS_FACTORS = {
    "ï¼³ç´š":           {"spread":1.00, "line":1.00},
    "ï¼¡ç´š":           {"spread":0.90, "line":0.85},
    "ï¼¡ç´šãƒãƒ£ãƒ¬ãƒ³ã‚¸": {"spread":0.80, "line":0.70},
    "ã‚¬ãƒ¼ãƒ«ã‚º":       {"spread":0.85, "line":1.00},
}
cf = CLASS_FACTORS[race_class]

# æ—¥ç¨‹ä¿‚æ•°ï¼ˆãƒ©ã‚¤ãƒ³åŠ›ï¼‰
DAY_FACTOR = {"åˆæ—¥":1.00, "2æ—¥ç›®":0.60, "æœ€çµ‚æ—¥":0.85}
day_factor = DAY_FACTOR[day_label]

# ãƒ©ã‚¤ãƒ³ä¿‚æ•°ãƒ»SBcapï¼ˆä¼šå ´â†’ç´šåˆ¥â†’æ—¥ç¨‹ï¼‰
cap_base = clamp(0.06 + 0.02*style, 0.04, 0.08)
line_factor_eff = cf["line"] * day_factor
cap_SB_eff = cap_base * day_factor
if race_time == "ãƒŸãƒƒãƒ‰ãƒŠã‚¤ãƒˆ":
    line_factor_eff *= 0.95
    cap_SB_eff *= 0.95

# ã‚¬ãƒ¼ãƒ«ã‚ºã¯ãƒ©ã‚¤ãƒ³SBç„¡åŠ¹
line_sb_enable = (race_class != "ã‚¬ãƒ¼ãƒ«ã‚º")

st.sidebar.caption(
    f"ä¼šå ´ã‚¹ã‚¿ã‚¤ãƒ«: {style:+.2f}ï¼ˆraw {style_raw:+.2f}ï¼‰ / "
    f"ç´šåˆ¥: spread={cf['spread']:.2f}, line={cf['line']:.2f} / "
    f"æ—¥ç¨‹ä¿‚æ•°(line)={day_factor:.2f} â†’ lineä¿‚æ•°={line_factor_eff:.2f}, SBcapÂ±{cap_SB_eff:.2f}"
)

# ==============================
# ãƒ¡ã‚¤ãƒ³
# ==============================
st.title("â­ ãƒ´ã‚§ãƒ­ãƒ“ï¼ˆç´šåˆ¥Ã—æ—¥ç¨‹ãƒ€ã‚¤ãƒŠãƒŸã‚¯ã‚¹ / 5ã€œ9è»Šãƒ»è²·ã„ç›®ä»˜ãï¼‰â­")

# ãƒ©ã‚¤ãƒ³å…¥åŠ›
st.subheader("ãƒ©ã‚¤ãƒ³æ§‹æˆï¼ˆæœ€å¤§7ï¼šå˜é¨ã‚‚1ãƒ©ã‚¤ãƒ³ï¼‰")
line_inputs = [
    st.text_input("ãƒ©ã‚¤ãƒ³1ï¼ˆä¾‹ï¼š317ï¼‰", key="line_1", max_chars=9),
    st.text_input("ãƒ©ã‚¤ãƒ³2ï¼ˆä¾‹ï¼š6ï¼‰", key="line_2", max_chars=9),
    st.text_input("ãƒ©ã‚¤ãƒ³3ï¼ˆä¾‹ï¼š425ï¼‰", key="line_3", max_chars=9),
    st.text_input("ãƒ©ã‚¤ãƒ³4ï¼ˆä»»æ„ï¼‰", key="line_4", max_chars=9),
    st.text_input("ãƒ©ã‚¤ãƒ³5ï¼ˆä»»æ„ï¼‰", key="line_5", max_chars=9),
    st.text_input("ãƒ©ã‚¤ãƒ³6ï¼ˆä»»æ„ï¼‰", key="line_6", max_chars=9),
    st.text_input("ãƒ©ã‚¤ãƒ³7ï¼ˆä»»æ„ï¼‰", key="line_7", max_chars=9),
]
lines = [extract_car_list(x, n_cars) for x in line_inputs if str(x).strip()]
line_def, car_to_group = build_line_maps(lines)
active_cars = sorted({c for lst in lines for c in lst}) if lines else list(range(1, n_cars+1))

# å€‹äººãƒ‡ãƒ¼ã‚¿
st.subheader("å€‹äººãƒ‡ãƒ¼ã‚¿ï¼ˆç›´è¿‘4ã‹æœˆï¼šå›æ•°ï¼‰")
cols = st.columns(n_cars)
ratings, S, B = {}, {}, {}
k_esc, k_mak, k_sashi, k_mark = {}, {}, {}, {}
x1, x2, x3, x_out = {}, {}, {}, {}

for i, no in enumerate(active_cars):
    with cols[i]:
        st.markdown(f"**{no}ç•ª**")
        ratings[no] = input_float_text("å¾—ç‚¹ï¼ˆç©ºæ¬„å¯ï¼‰", key=f"pt_{no}", placeholder="ä¾‹: 55.0")
        S[no] = st.number_input("S", 0, 99, 0, key=f"s_{no}")
        B[no] = st.number_input("B", 0, 99, 0, key=f"b_{no}")
        k_esc[no]   = st.number_input("é€ƒ", 0, 99, 0, key=f"ke_{no}")
        k_mak[no]   = st.number_input("æ²", 0, 99, 0, key=f"km_{no}")
        k_sashi[no] = st.number_input("å·®", 0, 99, 0, key=f"ks_{no}")
        k_mark[no]  = st.number_input("ãƒ", 0, 99, 0, key=f"kk_{no}")
        x1[no]  = st.number_input("1ç€", 0, 99, 0, key=f"x1_{no}")
        x2[no]  = st.number_input("2ç€", 0, 99, 0, key=f"x2_{no}")
        x3[no]  = st.number_input("3ç€", 0, 99, 0, key=f"x3_{no}")
        x_out[no]= st.number_input("ç€å¤–", 0, 99, 0, key=f"xo_{no}")

# å¾—ç‚¹ã®å®Ÿæ•°ï¼ˆæœªå…¥åŠ›ã¯55.0ï¼‰
ratings_val = {no: (ratings[no] if ratings[no] is not None else 55.0) for no in active_cars}

# 1ç€ãƒ»2ç€ã®ç¸®ç´„ï¼ˆç´šåˆ¥Ã—ä¼šå ´ã®äº‹å‰åˆ†å¸ƒã‚’æ··ãœã‚‹ï¼‰
def prior_by_class(cls, style_adj):
    if "ã‚¬ãƒ¼ãƒ«" in cls: p1,p2 = 0.18,0.24
    elif "ï¼³ç´š" in cls: p1,p2 = 0.22,0.26
    elif "ãƒãƒ£ãƒ¬ãƒ³ã‚¸" in cls: p1,p2 = 0.18,0.22
    else: p1,p2 = 0.20,0.25
    p1 += 0.010*style_adj; p2 -= 0.005*style_adj
    return clamp(p1,0.05,0.60), clamp(p2,0.05,0.60)

def n0_by_n(n):
    if n<=6: return 12
    if n<=14: return 8
    if n<=29: return 5
    return 3

p1_eff, p2_eff = {}, {}
for no in active_cars:
    n = x1[no]+x2[no]+x3[no]+x_out[no]
    p1_prior, p2_prior = prior_by_class(race_class, style)
    n0 = n0_by_n(n)
    if n==0:
        p1_eff[no], p2_eff[no] = p1_prior, p2_prior
    else:
        p1_eff[no] = clamp((x1[no] + n0*p1_prior)/(n+n0), 0.0, 0.40)
        p2_eff[no] = clamp((x2[no] + n0*p2_prior)/(n+n0), 0.0, 0.50)

# ãƒ•ã‚©ãƒ¼ãƒ æŒ‡æ¨™ï¼ˆ0-1ï¼‰
Form = {no: 0.7*p1_eff[no] + 0.3*p2_eff[no] for no in active_cars}

# è„šè³ªãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ï¼ˆä¼šå ´é©æ€§ï¼‰
prof_base, prof_escape, prof_sashi, prof_oikomi = {}, {}, {}, {}
for no in active_cars:
    tot = k_esc[no]+k_mak[no]+k_sashi[no]+k_mark[no]
    if tot==0: esc=mak=sashi=mark = 0.25
    else:
        esc=k_esc[no]/tot; mak=k_mak[no]/tot; sashi=k_sashi[no]/tot; mark=k_mark[no]/tot
    prof_escape[no]=esc; prof_sashi[no]=sashi; prof_oikomi[no]=mark
    base = esc*BASE_BY_KAKU["é€ƒ"] + mak*BASE_BY_KAKU["æ²"] + sashi*BASE_BY_KAKU["å·®"] + mark*BASE_BY_KAKU["ãƒ"]
    k = 0.06
    venue_bonus = k * style * ( +1.00*esc +0.40*mak -0.60*sashi -0.25*mark )
    prof_base[no] = base + clamp(venue_bonus, -0.06, +0.06)

# SBãªã—åˆè¨ˆï¼ˆç’°å¢ƒè£œæ­£ + å¾—ç‚¹å¾®è£œæ­£ï¼‰ â†’ ç´šåˆ¥spreadã§åºƒãŒã‚Šåœ§ç¸®
tens_list = [ratings_val[no] for no in active_cars]
t_corr = tenscore_correction(tens_list) if active_cars else []
tens_corr = {no:t_corr[i] for i,no in enumerate(active_cars)} if active_cars else {}

rows=[]
for no in active_cars:
    role = role_in_line(no, line_def)
    wind = wind_adjust(wind_dir, wind_speed, role, prof_escape[no])
    extra = max(eff_laps-2, 0)
    fatigue_scale = 1.0 if race_class=="ï¼³ç´š" else (1.1 if race_class=="ï¼¡ç´š" else (1.2 if race_class=="ï¼¡ç´šãƒãƒ£ãƒ¬ãƒ³ã‚¸" else 1.05))
    laps_adj = (-0.10*extra*(1.0 if prof_escape[no]>0.5 else 0.0) + 0.05*extra*(1.0 if prof_oikomi[no]>0.4 else 0.0)) * fatigue_scale
    bank_b = bank_character_bonus(bank_angle, straight_length, prof_escape[no], prof_sashi[no])
    length_b = bank_length_adjust(bank_length, prof_oikomi[no])
    total_raw = (prof_base[no] + wind + cf["spread"]*tens_corr.get(no,0.0) + bank_b + length_b + laps_adj)
    rows.append([no, role, round(prof_base[no],3), wind, round(cf["spread"]*tens_corr.get(no,0.0),3),
                 round(bank_b,3), round(length_b,3), round(laps_adj,3), total_raw])

df = pd.DataFrame(rows, columns=["è»Šç•ª","å½¹å‰²","è„šè³ªåŸºæº–(ä¼šå ´)","é¢¨è£œæ­£","å¾—ç‚¹è£œæ­£","ãƒãƒ³ã‚¯è£œæ­£","å‘¨é•·è£œæ­£","å‘¨å›è£œæ­£","åˆè¨ˆ_SBãªã—_raw"])
mu = float(df["åˆè¨ˆ_SBãªã—_raw"].mean()) if not df.empty else 0.0
df["åˆè¨ˆ_SBãªã—"] = mu + 1.0*(df["åˆè¨ˆ_SBãªã—_raw"] - mu)
df_sorted_wo = df.sort_values("åˆè¨ˆ_SBãªã—", ascending=False).reset_index(drop=True)

# å€™è£œCï¼ˆå¾—ç‚¹Ã—2ç€ç‡ãƒ–ãƒ¬ãƒ³ãƒ‰ ä¸Šä½3ï¼‰
blend = {no: (ratings_val[no] + min(50.0, p2_eff[no]*100.0))/2.0 for no in active_cars}
C = [kv[0] for kv in sorted(blend.items(), key=lambda x:x[1], reverse=True)[:min(3,len(blend))]]

# ãƒ©ã‚¤ãƒ³SBï¼ˆç´šåˆ¥Ã—æ—¥ç¨‹Ã—ä¼šå ´capã€ã‚¬ãƒ¼ãƒ«ã‚ºã¯ç„¡åŠ¹ï¼‰
bonus_init,_ = compute_lineSB_bonus(line_def, S, B, line_factor=line_factor_eff, exclude=None, cap=cap_SB_eff, enable=line_sb_enable)

v_wo = dict(zip(df["è»Šç•ª"], df["åˆè¨ˆ_SBãªã—"]))

# â—ï¼šCå†…ã§ã€ŒSBåŠ ç‚¹ + SBãªã—åˆè¨ˆã€ãŒæœ€å¤§
def anchor_score(no):
    g = car_to_group.get(no, None); role = role_in_line(no, line_def)
    # â˜…ä¿®æ­£â‘ ï¼šline_factorã®äºŒé‡æ›ã‘ã‚’è§£æ¶ˆï¼ˆpos_coeffã®ç¬¬äºŒå¼•æ•°ã‚’ 1.0 å›ºå®šï¼‰
    sb = bonus_init.get(g,0.0) * (pos_coeff(role, 1.0) if line_sb_enable else 0.0)
    zt = zscore_list([ratings_val[n] for n in active_cars]) if active_cars else []
    zt_map = {n:float(zt[i]) for i,n in enumerate(active_cars)} if active_cars else {}
    return v_wo.get(no, -1e9) + sb + 0.01*zt_map.get(no, 0.0)

anchor_no = max(C, key=lambda x: anchor_score(x)) if C else int(df_sorted_wo.loc[0,"è»Šç•ª"])

# è‡ªä¿¡åº¦ï¼ˆå€™è£œCå†…ã®å·® / åºƒãŒã‚Šï¼‰
cand_scores = [anchor_score(no) for no in C] if len(C)>=2 else [0,0]
cand_scores_sorted = sorted(cand_scores, reverse=True)
conf = cand_scores_sorted[0]-cand_scores_sorted[1] if len(cand_scores_sorted)>=2 else 0.0
spread = float(np.std(list(v_wo.values()))) if len(v_wo)>=2 else 0.0
norm = conf / (spread if spread>1e-6 else 1.0)
confidence = "å¼·" if norm>=1.0 else ("ä¸­" if norm>=0.5 else "å¼±")

# ã€‡ï¼šCæ®‹ã‚Š â†’ â—é™¤å¤–ã§SBå†è¨ˆç®— â†’ æœ€å¤§
bonus_re,_ = compute_lineSB_bonus(line_def, S, B, line_factor=line_factor_eff, exclude=anchor_no, cap=cap_SB_eff, enable=line_sb_enable)
def himo_score(no):
    g = car_to_group.get(no, None); role = role_in_line(no, line_def)
    # â˜…ä¿®æ­£â‘ ï¼šäºŒé‡æ›ã‘è§£æ¶ˆ
    sb = bonus_re.get(g,0.0) * (pos_coeff(role, 1.0) if line_sb_enable else 0.0)
    return v_wo.get(no, -1e9) + sb

restC = [no for no in C if no!=anchor_no]
o_no = max(restC, key=lambda x: himo_score(x)) if restC else None

# â–²ï¼šSBãªã—ä¸‹ä½åŸŸã‹ã‚‰ã€ä¼šå ´é©åˆÃ—â€œå¹³æ»‘2ç€%â€ æ¡ä»¶ã§1é ­
def venue_match(no):
    tot = k_esc[no]+k_mak[no]+k_sashi[no]+k_mark[no]
    if tot==0: esc=mak=sashi=mark=0.25
    else:
        esc=k_esc[no]/tot; mak=k_mak[no]/tot; sashi=k_sashi[no]/tot; mark=k_mark[no]/tot
    return style * (1.00*esc + 0.40*mak - 0.60*sashi - 0.25*mark)

rank_wo = {int(df_sorted_wo.loc[i,"è»Šç•ª"]): i+1 for i in range(len(df_sorted_wo))}
# â˜…ä¿®æ­£â‘¢ï¼šä¸‹ä½40%ã—ãã„
lower_rank_threshold = max(5, int(np.ceil(len(df_sorted_wo)*0.6)))
lower_pool = [no for no in active_cars if rank_wo.get(no,99) >= lower_rank_threshold]

p2_C_mean = np.mean([p2_eff[no] for no in C]) if C else 0.0
min_p2 = 0.22 if race_class=="ï¼³ç´š" else 0.20

# â˜…ä¿®æ­£â‘¡ï¼šç”Ÿæ¯”ç‡ã§ã¯ãªãå¹³æ»‘ p2_eff ã‚’ä½¿ç”¨
pool_filtered = [no for no in lower_pool
                 if no not in {anchor_no, o_no}
                 and ( p2_eff[no] >= min_p2 )
                 and ( p2_eff[no] <= p2_C_mean + 1e-9 )]

a_no = max(pool_filtered, key=lambda x: venue_match(x)) if pool_filtered else None
if a_no is None:
    fb = [no for no in lower_pool if no not in {anchor_no, o_no}]
    if fb: a_no = max(fb, key=lambda x: venue_match(x))

# å°é›†ç´„
result_marks, reasons = {}, {}
result_marks["â—"] = anchor_no; reasons[anchor_no] = "æœ¬å‘½(Cä¸Šä½3â†’ãƒ©ã‚¤ãƒ³SBé‡è¦–)â€»ã‚¬ãƒ¼ãƒ«ã‚ºã¯å€‹äººè¦ç´ ã®ã¿"
if o_no is not None:
    result_marks["ã€‡"] = o_no; reasons[o_no] = "å¯¾æŠ—(Cæ®‹ã‚Šâ†’â—é™¤å¤–SBå†è¨ˆç®—)"
if a_no is not None:
    result_marks["â–²"] = a_no; reasons[a_no] = "å˜ç©´(SBãªã—ä¸‹ä½Ã—ä¼šå ´é©åˆÃ—2ç€%)"

used = set(result_marks.values())
for m,no in zip([m for m in ["â–³","Ã—","Î±","Î²"] if m not in result_marks],
                [int(df_sorted_wo.loc[i,"è»Šç•ª"]) for i in range(len(df_sorted_wo)) if int(df_sorted_wo.loc[i,"è»Šç•ª"]) not in used]):
    result_marks[m]=no

# å‡ºåŠ›ï¼ˆSBãªã—ãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼‰
st.markdown("### ãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼†å°ï¼ˆâ—=ãƒ©ã‚¤ãƒ³SBè€ƒæ…® / ã€‡=å®‰å®š / â–²=é€†è¥²ï¼‰")
velobi_wo = list(zip(df_sorted_wo["è»Šç•ª"].astype(int).tolist(), df_sorted_wo["åˆè¨ˆ_SBãªã—"].round(3).tolist()))

rows_out=[]
for r,(no,sc) in enumerate(velobi_wo, start=1):
    mark = "".join([m for m,v in result_marks.items() if v==no])
    n_tot = x1.get(no,0)+x2.get(no,0)+x3.get(no,0)+x_out.get(no,0)
    p1 = (x1.get(no,0)/(n_tot+1e-9))*100
    p2 = (x2.get(no,0)/(n_tot+1e-9))*100
    rows_out.append({
        "é †(SBãªã—)": r, "å°": mark, "è»Š": no,
        "SBãªã—ã‚¹ã‚³ã‚¢": sc,
        "å¾—ç‚¹": ratings_val.get(no, None),
        "1ç€å›": x1.get(no,0), "2ç€å›": x2.get(no,0), "3ç€å›": x3.get(no,0), "ç€å¤–": x_out.get(no,0),
        "1ç€%": round(p1,1), "2ç€%": round(p2,1),
        "ãƒ©ã‚¤ãƒ³": car_to_group.get(no,"-")
    })
st.dataframe(pd.DataFrame(rows_out), use_container_width=True)

st.markdown("#### è£œæ­£å†…è¨³ï¼ˆSBãªã—ï¼‰")
show=[]
for no,_ in velobi_wo:
    rec = df[df["è»Šç•ª"]==no].iloc[0]
    show.append({
        "è»Š":int(no),"ãƒ©ã‚¤ãƒ³":car_to_group.get(int(no),"-"),
        "è„šè³ªåŸºæº–(ä¼šå ´)":round(rec["è„šè³ªåŸºæº–(ä¼šå ´)"],3),
        "é¢¨è£œæ­£":rec["é¢¨è£œæ­£"],"å¾—ç‚¹è£œæ­£":rec["å¾—ç‚¹è£œæ­£"],
        "ãƒãƒ³ã‚¯è£œæ­£":rec["ãƒãƒ³ã‚¯è£œæ­£"],"å‘¨é•·è£œæ­£":rec["å‘¨é•·è£œæ­£"],
        "å‘¨å›è£œæ­£":rec["å‘¨å›è£œæ­£"],"åˆè¨ˆ_SBãªã—_raw":round(rec["åˆè¨ˆ_SBãªã—_raw"],3),
        "åˆè¨ˆ_SBãªã—":round(rec["åˆè¨ˆ_SBãªã—"],3)
    })
st.dataframe(pd.DataFrame(show), use_container_width=True)

st.caption(
    f"ç«¶è¼ªå ´ã€€{track}{race_no}R / {race_time}ã€€{race_class} / "
    f"é–‹å‚¬æ—¥ï¼š{day_label}ï¼ˆlineä¿‚æ•°={line_factor_eff:.2f}, SBcapÂ±{cap_SB_eff:.2f}ï¼‰ / "
    f"ä¼šå ´ã‚¹ã‚¿ã‚¤ãƒ«:{style:+.2f} / é¢¨:{wind_dir} / æœ‰åŠ¹å‘¨å›={eff_laps} / è‡ªä¿¡åº¦ï¼š**{confidence}**ï¼ˆNorm={norm:.2f}ï¼‰"
)

# ==============================
# è²·ã„ç›®ï¼ˆæƒ³å®šçš„ä¸­ç‡ / å¿…è¦ã‚ªãƒƒã‚º / EVï¼‰
# ==============================
st.markdown("### ğŸ¯ è²·ã„ç›®ï¼ˆæƒ³å®šçš„ä¸­ç‡ / å¿…è¦ã‚ªãƒƒã‚º / EVï¼‰")

one = result_marks.get("â—", None)
two = result_marks.get("ã€‡", None)
three = result_marks.get("â–²", None)
if one is None:
    st.warning("â—æœªæ±ºå®šã®ãŸã‚è²·ã„ç›®ã¯ã‚¹ã‚­ãƒƒãƒ—")
    buy_table = None
else:
    # å¼·ã•ãƒ™ã‚¯ãƒˆãƒ«ï¼šSBãªã—ã‚¹ã‚³ã‚¢ â†’ æ¨™æº–åŒ–softmax
    strength_map = dict(velobi_wo)
    xs = np.array([strength_map.get(i,0.0) for i in range(1, n_cars+1)], dtype=float)
    if xs.std()<1e-12:
        probs = np.ones_like(xs)/len(xs)
    else:
        z = (xs - xs.mean())/(xs.std()+1e-12); e = np.exp(z); probs = e/e.sum()

    rng = np.random.default_rng(20250830)
    trials = st.slider("ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³è©¦è¡Œå›æ•°", 1000, 20000, 8000, 1000)

    def sample_order():
        # Gumbel-Max
        g = -np.log(-np.log(np.clip(rng.random(len(probs)),1e-12,1-1e-12)))
        score = np.log(probs+1e-12) + g
        order = np.argsort(-score)+1
        return order.tolist()

    # 2åˆ—ç›®å€™è£œã‚»ãƒƒãƒˆ
    second_set = [x for x in [two, three] if x is not None]
    rest = [i for i in range(1, n_cars+1) if i not in {one} | set(second_set)]
    # 3é€£è¤‡A: â—-ï¼ˆã€‡/â–²ï¼‰-{æ®‹ã‚Šä¸Šä½ã‹ã‚‰æœ€å¤§5é ­}
    third_A = (second_set + rest)[:min(5, max(1, n_cars-2))]
    # 3é€£è¤‡B: â—-{äºŒåˆ—å€™è£œ4é ­}-åŒæ 
    box_B = (second_set + rest)[:4]
    # 3é€£è¤‡C: â—-ï¼ˆã€‡/â–²ï¼‰-å…¨
    set_23 = second_set[:]

    hit_A=hit_B=hit_C=hit_EX=hit_QN=hit_WD=0
    for _ in range(trials):
        order = sample_order()
        top2 = set(order[:2]); top3 = set(order[:3])

        if (one in top3) and (len(top3 & set([two, three]))>=1) and (len(top3 & set(third_A))>=2):
            hit_A += 1
        if (one in top3) and (len(top3 & set(box_B))>=2):
            hit_B += 1
        if (one in top3) and (len(top3 & set(set_23))>=1):
            hit_C += 1

        if len(set_23)>0 and order[0]==one and order[1] in set_23:
            hit_EX += 1
        if len(set_23)>0 and set(order[:2]) & set(set_23) and one in set(order[:2]):
            hit_QN += 1
        if (one in order[:3]) and (len(set(order[:3]) & set(set_23))>=1):
            hit_WD += 1

    def pct(x): return f"{(x/trials)*100:.1f}%"
    def need(x): return "-" if x==0 else f"{trials/x:.2f}"

    buy_rows = [
        ["ä¸‰é€£è¤‡A", f"{one}-{set_23 if set_23 else 'â€”'}-{third_A}", pct(hit_A), need(hit_A)],
        ["ä¸‰é€£è¤‡B", f"{one}-{box_B}-{box_B}", pct(hit_B), need(hit_B)],
        ["ä¸‰é€£è¤‡C", f"{one}-{set_23 if set_23 else 'â€”'}-å…¨", pct(hit_C), need(hit_C)],
        ["äºŒè»Šå˜",   f"{one}-{set_23}" , pct(hit_EX), need(hit_EX)],
        ["äºŒè»Šè¤‡",   f"{one}-{set_23}" , pct(hit_QN), need(hit_QN)],
        ["ãƒ¯ã‚¤ãƒ‰",   f"{one}-{set_23}" , pct(hit_WD), need(hit_WD)],
    ]
    buy_table = pd.DataFrame(buy_rows, columns=["åˆ¸ç¨®","è²·ã„ç›®ï¼ˆ1=â—,2=ã€‡/â–²ï¼‰","æƒ³å®šçš„ä¸­ç‡","å¿…è¦ã‚ªãƒƒã‚º"])

st.dataframe(buy_table, use_container_width=True) if 'buy_table' in locals() and buy_table is not None else None

# noteï¼ˆæ‰‹å‹•ã‚³ãƒ”ãƒ¼ï¼šè²·ã„ç›®ä»˜ãï¼‰
st.markdown("### ğŸ“‹ noteè¨˜äº‹ç”¨ï¼ˆæ‰‹å‹•ã‚³ãƒ”ãƒ¼ï¼‰")
line_text="ã€€".join([x for x in line_inputs if str(x).strip()])
score_order_text=" ".join(str(no) for no,_ in velobi_wo)  # SBãªã—é †
marks_line=" ".join(f"{m}{result_marks[m]}" for m in ["â—","ã€‡","â–²","â–³","Ã—","Î±","Î²"] if m in result_marks)

buy_lines = ""
if 'buy_table' in locals() and buy_table is not None:
    bl = []
    for _,r in buy_table.iterrows():
        bl.append(f"{r['åˆ¸ç¨®']}: {r['è²·ã„ç›®ï¼ˆ1=â—,2=ã€‡/â–²ï¼‰']}  p={r['æƒ³å®šçš„ä¸­ç‡']} å¿…è¦={r['å¿…è¦ã‚ªãƒƒã‚º']}å€")
    buy_lines = "ã€è²·ã„ç›®ï¼ˆæƒ³å®šçš„ä¸­ç‡ / å¿…è¦ã‚ªãƒƒã‚ºï¼‰ã€‘\n" + "\n".join(bl)

note_text=(f"ç«¶è¼ªå ´ã€€{track}{race_no}R\n"
           f"{race_time}ã€€{race_class}\n"
           f"ãƒ©ã‚¤ãƒ³ã€€{line_text}\n"
           f"ã‚¹ã‚³ã‚¢é †ï¼ˆSBãªã—ï¼‰ã€€{score_order_text}\n"
           f"{marks_line}\n"
           f"è‡ªä¿¡åº¦ï¼š{confidence}\n"
           + (("\n"+buy_lines) if buy_lines else ""))

st.text_area("ã“ã“ã‚’é¸æŠã—ã¦ã‚³ãƒ”ãƒ¼", note_text, height=260)
