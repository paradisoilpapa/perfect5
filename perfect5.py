# -*- coding: utf-8 -*-
import streamlit as st
import pandas as pd
import numpy as np   # â† ã“ã“ï¼NumPy ã‚’ np ã«ã™ã‚‹
import unicodedata, re
import math, json, requests
from statistics import mean, pstdev
from itertools import combinations
from datetime import datetime, date, time, timedelta, timezone

# ===========================F===
# ãƒšãƒ¼ã‚¸è¨­å®š
# ==============================
st.set_page_config(page_title="ãƒ´ã‚§ãƒ­ãƒ“ï¼šç´šåˆ¥Ã—æ—¥ç¨‹ãƒ€ã‚¤ãƒŠãƒŸã‚¯ã‚¹ï¼ˆ5ã€œ9è»Šãƒ»è²·ã„ç›®ä»˜ã / çµ±åˆç‰ˆï¼‰", layout="wide")

# ==============================
# â˜… æ–°è¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆåå·®å€¤ï¼†æ¨å¥¨ãƒ­ã‚¸ãƒƒã‚¯ï¼‰
# ==============================
HEN_W_SB   = 0.20   # SBé‡ã¿
HEN_W_PROF = 0.30   # è„šè³ªé‡ã¿
HEN_W_IN   = 0.50   # å…¥ç€é‡ã¿ï¼ˆç¸®ç´„3ç€å†…ç‡ï¼‰
HEN_DEC_PLACES = 1  # åå·®å€¤ å°æ•°ä¸€æ¡

HEN_THRESHOLD = 55.0     # åå·®å€¤ã‚¯ãƒªã‚¢é–¾å€¤
HEN_STRONG_ONE = 60.0    # å˜ç‹¬å¼·è€…ã®ç›®å®‰

MAX_TICKETS = 6          # è²·ã„ç›®æœ€å¤§ç‚¹æ•°

# æ¨å¥¨ãƒ©ãƒ™ãƒ«åˆ¤å®šç”¨ï¼ˆã‚¯ãƒªã‚¢å°æ•°â†’æ–¹é‡ï¼‰
# k>=5:ã€Œ2è»Šè¤‡ãƒ»ãƒ¯ã‚¤ãƒ‰ã€ä¸­å¿ƒï¼ˆåºƒãï¼‰ / k=3,4:ã€Œ3é€£è¤‡ã€ / k=1,2:ã€ŒçŠ¶æ³æ¬¡ç¬¬ï¼ˆè»¸æµã—å¯„ã‚Šï¼‰ã€ / k=0:ã‚±ãƒ³
LABEL_MAP = {
    "wide_qn": lambda k: k >= 5,
    "trio":    lambda k: 3 <= k <= 4,
    "axis":    lambda k: k in (1,2),
    "ken":     lambda k: k == 0,
}

# æœŸå¾…å€¤ãƒ¬ãƒ³ã‚¸ï¼ˆå†…éƒ¨åŸºæº–ã§ä½¿ç”¨å¯ã€‚ç”»é¢éè¡¨ç¤ºï¼‰
P_FLOOR = {"sanpuku": 0.06, "nifuku": 0.12, "wide": 0.25, "nitan": 0.07, "santan": 0.03}
E_MIN, E_MAX = 0.10, 0.60

# ==============================
# æ—¢å­˜ï¼šé¢¨ãƒ»ä¼šå ´ãƒ»ãƒã‚¹ã‚¿
# ==============================
WIND_COEFF = {
    "å·¦ä¸Š": -0.03, "ä¸Š": -0.05, "å³ä¸Š": -0.035,
    "å·¦": +0.05,  "å³": -0.05,
    "å·¦ä¸‹": +0.035, "ä¸‹": +0.05, "å³ä¸‹": +0.035,
    "ç„¡é¢¨": 0.0
}
WIND_MODE = "speed_only"
WIND_SIGN = -1
WIND_GAIN = 3.0
WIND_CAP  = 0.10
WIND_ZERO = 1.5
SPECIAL_DIRECTIONAL_VELODROMES = {"å¼¥å½¦", "å‰æ©‹"}

SESSION_HOUR = {"ãƒ¢ãƒ¼ãƒ‹ãƒ³ã‚°": 8, "ãƒ‡ã‚¤": 11, "ãƒŠã‚¤ã‚¿ãƒ¼": 18, "ãƒŸãƒƒãƒ‰ãƒŠã‚¤ãƒˆ": 22}
JST = timezone(timedelta(hours=9))

BASE_BY_KAKU = {"é€ƒ":1.58, "æ²":1.65, "å·®":1.79, "ãƒ":1.45}

KEIRIN_DATA = {
    "å‡½é¤¨":{"bank_angle":30.6,"straight_length":51.3,"bank_length":400},
    "é’æ£®":{"bank_angle":32.3,"straight_length":58.9,"bank_length":400},
    "ã„ã‚ãå¹³":{"bank_angle":32.9,"straight_length":62.7,"bank_length":400},
    "å¼¥å½¦":{"bank_angle":32.4,"straight_length":63.1,"bank_length":400},
    "å‰æ©‹":{"bank_angle":36.0,"straight_length":46.7,"bank_length":335},
    "å–æ‰‹":{"bank_angle":31.5,"straight_length":54.8,"bank_length":400},
    "å®‡éƒ½å®®":{"bank_angle":25.8,"straight_length":63.3,"bank_length":500},
    "å¤§å®®":{"bank_angle":26.3,"straight_length":66.7,"bank_length":500},
    "è¥¿æ­¦åœ’":{"bank_angle":29.4,"straight_length":47.6,"bank_length":400},
    "äº¬ç‹é–£":{"bank_angle":32.2,"straight_length":51.5,"bank_length":400},
    "ç«‹å·":{"bank_angle":31.2,"straight_length":58.0,"bank_length":400},
    "æ¾æˆ¸":{"bank_angle":29.8,"straight_length":38.2,"bank_length":333},
    "å·å´":{"bank_angle":32.2,"straight_length":58.0,"bank_length":400},
    "å¹³å¡š":{"bank_angle":31.5,"straight_length":54.2,"bank_length":400},
    "å°ç”°åŸ":{"bank_angle":35.6,"straight_length":36.1,"bank_length":333},
    "ä¼Šæ±":{"bank_angle":34.7,"straight_length":46.6,"bank_length":333},
    "é™å²¡":{"bank_angle":30.7,"straight_length":56.4,"bank_length":400},
    "åå¤å±‹":{"bank_angle":34.0,"straight_length":58.8,"bank_length":400},
    "å²é˜œ":{"bank_angle":32.3,"straight_length":59.3,"bank_length":400},
    "å¤§å£":{"bank_angle":30.6,"straight_length":56.0,"bank_length":400},
    "è±Šæ©‹":{"bank_angle":33.8,"straight_length":60.3,"bank_length":400},
    "å¯Œå±±":{"bank_angle":33.7,"straight_length":43.0,"bank_length":333},
    "æ¾å‚":{"bank_angle":34.4,"straight_length":61.5,"bank_length":400},
    "å››æ—¥å¸‚":{"bank_angle":32.3,"straight_length":62.4,"bank_length":400},
    "ç¦äº•":{"bank_angle":31.5,"straight_length":52.8,"bank_length":400},
    "å¥ˆè‰¯":{"bank_angle":33.4,"straight_length":38.0,"bank_length":333},
    "å‘æ—¥ç”º":{"bank_angle":30.5,"straight_length":47.3,"bank_length":400},
    "å’Œæ­Œå±±":{"bank_angle":32.3,"straight_length":59.9,"bank_length":400},
    "å²¸å’Œç”°":{"bank_angle":30.9,"straight_length":56.7,"bank_length":400},
    "ç‰é‡":{"bank_angle":30.6,"straight_length":47.9,"bank_length":400},
    "åºƒå³¶":{"bank_angle":30.8,"straight_length":57.9,"bank_length":400},
    "é˜²åºœ":{"bank_angle":34.7,"straight_length":42.5,"bank_length":333},
    "é«˜æ¾":{"bank_angle":33.3,"straight_length":54.8,"bank_length":400},
    "å°æ¾å³¶":{"bank_angle":29.8,"straight_length":55.5,"bank_length":400},
    "é«˜çŸ¥":{"bank_angle":24.5,"straight_length":52.0,"bank_length":500},
    "æ¾å±±":{"bank_angle":34.0,"straight_length":58.6,"bank_length":400},
    "å°å€‰":{"bank_angle":34.0,"straight_length":56.9,"bank_length":400},
    "ä¹…ç•™ç±³":{"bank_angle":31.5,"straight_length":50.7,"bank_length":400},
    "æ­¦é›„":{"bank_angle":32.0,"straight_length":64.4,"bank_length":400},
    "ä½ä¸–ä¿":{"bank_angle":31.5,"straight_length":40.2,"bank_length":400},
    "åˆ¥åºœ":{"bank_angle":33.7,"straight_length":59.9,"bank_length":400},
    "ç†Šæœ¬":{"bank_angle":34.3,"straight_length":60.3,"bank_length":400},
    "æ‰‹å…¥åŠ›":{"bank_angle":30.0,"straight_length":52.0,"bank_length":400},
}
VELODROME_MASTER = {
    "å‡½é¤¨":{"lat":41.77694,"lon":140.76283,"home_azimuth":None},
    "é’æ£®":{"lat":40.79717,"lon":140.66469,"home_azimuth":None},
    "ã„ã‚ãå¹³":{"lat":37.04533,"lon":140.89150,"home_azimuth":None},
    "å¼¥å½¦":{"lat":37.70778,"lon":138.82886,"home_azimuth":None},
    "å‰æ©‹":{"lat":36.39728,"lon":139.05778,"home_azimuth":None},
    "å–æ‰‹":{"lat":35.90175,"lon":140.05631,"home_azimuth":None},
    "å®‡éƒ½å®®":{"lat":36.57197,"lon":139.88281,"home_azimuth":None},
    "å¤§å®®":{"lat":35.91962,"lon":139.63417,"home_azimuth":None},
    "è¥¿æ­¦åœ’":{"lat":35.76983,"lon":139.44686,"home_azimuth":None},
    "äº¬ç‹é–£":{"lat":35.64294,"lon":139.53372,"home_azimuth":None},
    "ç«‹å·":{"lat":35.70214,"lon":139.42300,"home_azimuth":None},
    "æ¾æˆ¸":{"lat":35.80417,"lon":139.91119,"home_azimuth":None},
    "å·å´":{"lat":35.52844,"lon":139.70944,"home_azimuth":None},
    "å¹³å¡š":{"lat":35.32547,"lon":139.36342,"home_azimuth":None},
    "å°ç”°åŸ":{"lat":35.25089,"lon":139.14947,"home_azimuth":None},
    "ä¼Šæ±":{"lat":34.954667,"lon":139.092639,"home_azimuth":None},
    "é™å²¡":{"lat":34.973722,"lon":138.419417,"home_azimuth":None},
    "åå¤å±‹":{"lat":35.175560,"lon":136.854028,"home_azimuth":None},
    "å²é˜œ":{"lat":35.414194,"lon":136.783917,"home_azimuth":None},
    "å¤§å£":{"lat":35.361389,"lon":136.628444,"home_azimuth":None},
    "è±Šæ©‹":{"lat":34.770167,"lon":137.417250,"home_azimuth":None},
    "å¯Œå±±":{"lat":36.757250,"lon":137.234833,"home_azimuth":None},
    "æ¾å‚":{"lat":34.564611,"lon":136.533833,"home_azimuth":None},
    "å››æ—¥å¸‚":{"lat":34.965389,"lon":136.634500,"home_azimuth":None},
    "ç¦äº•":{"lat":36.066889,"lon":136.253722,"home_azimuth":None},
    "å¥ˆè‰¯":{"lat":34.681111,"lon":135.823083,"home_azimuth":None},
    "å‘æ—¥ç”º":{"lat":34.949222,"lon":135.708389,"home_azimuth":None},
    "å’Œæ­Œå±±":{"lat":34.228694,"lon":135.171833,"home_azimuth":None},
    "å²¸å’Œç”°":{"lat":34.477500,"lon":135.369389,"home_azimuth":None},
    "ç‰é‡":{"lat":34.497333,"lon":133.961389,"home_azimuth":None},
    "åºƒå³¶":{"lat":34.359778,"lon":132.502889,"home_azimuth":None},
    "é˜²åºœ":{"lat":34.048778,"lon":131.568611,"home_azimuth":None},
    "é«˜æ¾":{"lat":34.345936,"lon":134.061994,"home_azimuth":None},
    "å°æ¾å³¶":{"lat":34.005667,"lon":134.594556,"home_azimuth":None},
    "é«˜çŸ¥":{"lat":33.566694,"lon":133.526083,"home_azimuth":None},
    "æ¾å±±":{"lat":33.808889,"lon":132.742333,"home_azimuth":None},
    "å°å€‰":{"lat":33.885722,"lon":130.883167,"home_azimuth":None},
    "ä¹…ç•™ç±³":{"lat":33.316667,"lon":130.547778,"home_azimuth":None},
    "æ­¦é›„":{"lat":33.194083,"lon":130.023083,"home_azimuth":None},
    "ä½ä¸–ä¿":{"lat":33.161667,"lon":129.712833,"home_azimuth":None},
    "åˆ¥åºœ":{"lat":33.282806,"lon":131.460472,"home_azimuth":None},
    "ç†Šæœ¬":{"lat":32.789167,"lon":130.754722,"home_azimuth":None},
    "æ‰‹å…¥åŠ›":{"lat":None,"lon":None,"home_azimuth":None},
}

# --- æœ€æ–°ã®å°åˆ¥å®Ÿæ¸¬ç‡ï¼ˆè¡¨ç¤ºã¯ã—ãªã„ãŒå†…éƒ¨ä¿æŒï¼‰
RANK_STATS = {
    "â—": {"p1": 0.216, "pTop2": 0.456, "pTop3": 0.624},
    "ã€‡": {"p1": 0.193, "pTop2": 0.360, "pTop3": 0.512},
    "â–²": {"p1": 0.208, "pTop2": 0.384, "pTop3": 0.552},
    "â–³": {"p1": 0.152, "pTop2": 0.248, "pTop3": 0.384},
    "Ã—": {"p1": 0.128, "pTop2": 0.256, "pTop3": 0.384},
    "Î±": {"p1": 0.088, "pTop2": 0.152, "pTop3": 0.312},
    "Î²": {"p1": 0.076, "pTop2": 0.151, "pTop3": 0.244},
}
RANK_FALLBACK_MARK = "â–³"
if RANK_FALLBACK_MARK not in RANK_STATS:
    RANK_FALLBACK_MARK = next(iter(RANK_STATS.keys()))
FALLBACK_DIST = RANK_STATS.get(RANK_FALLBACK_MARK, {"p1": 0.15, "pTop2": 0.30, "pTop3": 0.45})

# KO(å‹ã¡ä¸ŠãŒã‚Š)é–¢é€£
KO_GIRLS_SCALE = 0.0
KO_HEADCOUNT_SCALE = {5:0.6, 6:0.8, 7:1.0, 8:1.0, 9:1.0}
KO_GAP_DELTA = 0.010
KO_STEP_SIGMA = 0.4

# â—ãƒ©ã‚¤ãƒ³æ ¼ä¸Šã’
LINE_BONUS_ON_TENKAI = {"å„ªä½"}
LINE_BONUS = {"second": 0.08, "thirdplus": 0.04}
LINE_BONUS_CAP = 0.10
PROB_U = {"second": 0.00, "thirdplus": 0.00}

# --- å®‰å®šåº¦ï¼ˆç€é †åˆ†å¸ƒï¼‰ã‚’Tæœ¬ä½“ã«å…¥ã‚Œã‚‹ãŸã‚ã®é‡ã¿ ---
STAB_W_IN3  = 0.10   # 3ç€å†…ç‡ã®é‡ã¿
STAB_W_OUT  = 0.12   # ç€å¤–ç‡ã®é‡ã¿ï¼ˆãƒã‚¤ãƒŠã‚¹è£œæ­£ï¼‰
STAB_W_LOWN = 0.05   # ã‚µãƒ³ãƒ—ãƒ«ä¸è¶³è£œæ­£
STAB_PRIOR_IN3 = 0.33
STAB_PRIOR_OUT = 0.45
def _stab_n0(n: int) -> int:
    """ã‚µãƒ³ãƒ—ãƒ«ä¸è¶³æ™‚ã®äº‹å‰åˆ†å¸ƒã®å¼·ã•ï¼ˆnãŒå°ã•ã„ã»ã©å¼·ãåŠ¹ã‹ã›ã‚‹ï¼‰"""
    if n <= 6: return 12
    if n <= 14: return 8
    if n <= 29: return 5
    return 3
# ==============================
# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
# ==============================
def clamp(x,a,b): return max(a, min(b, x))
def zscore_list(arr):
    arr = np.array(arr, dtype=float)
    m, s = float(np.mean(arr)), float(np.std(arr))
    return np.zeros_like(arr) if s==0 else (arr-m)/s
def zscore_val(x, xs):
    xs = np.array(xs, dtype=float); m, s = float(np.mean(xs)), float(np.std(xs))
    return 0.0 if s==0 else (float(x)-m)/s
def extract_car_list(s, nmax):
    s = str(s or "").strip()
    return [int(c) for c in s if c.isdigit() and 1 <= int(c) <= nmax]
def build_line_maps(lines):
    labels = "ABCDEFG"
    line_def = {labels[i]: lst for i,lst in enumerate(lines) if lst}
    car_to_group = {c:g for g,mem in line_def.items() for c in mem}
    return line_def, car_to_group
def role_in_line(car, line_def):
    for g, mem in line_def.items():
        if car in mem:
            if len(mem)==1: return 'single'
            idx = mem.index(car)
            return ['head','second','thirdplus'][idx] if idx<3 else 'thirdplus'
    return 'single'
def pos_coeff(role, line_factor):
    base = {'head':1.0,'second':0.7,'thirdplus':0.5,'single':0.9}.get(role,0.9)
    return base * line_factor
def tenscore_correction(tenscores):
    n = len(tenscores)
    if n<=2: return [0.0]*n
    df = pd.DataFrame({"å¾—ç‚¹":tenscores})
    df["é †ä½"] = df["å¾—ç‚¹"].rank(ascending=False, method="min").astype(int)
    hi = min(n,8)
    baseline = df[df["é †ä½"].between(2,hi)]["å¾—ç‚¹"].mean()
    def corr(row):
        return round(abs(baseline-row["å¾—ç‚¹"])*0.03, 3) if row["é †ä½"] in [2,3,4] else 0.0
    return df.apply(corr, axis=1).tolist()

def wind_adjust(wind_dir, wind_speed, role, prof_escape):
    s = max(0.0, float(wind_speed))
    if s <= WIND_ZERO:
        base = 0.0
    elif s <= 5.0:
        base = 0.006 * (s - WIND_ZERO)
    elif s <= 8.0:
        base = 0.021 + 0.008 * (s - 5.0)
    else:
        base = 0.045 + 0.010 * min(s - 8.0, 4.0)
    pos = {'head':1.00,'second':0.85,'single':0.75,'thirdplus':0.65}.get(role, 0.75)
    prof = 0.35 + 0.65*float(prof_escape)
    val = base * pos * prof
    if (WIND_MODE == "directional") or (s >= 7.0 and st.session_state.get("track", "") in SPECIAL_DIRECTIONAL_VELODROMES):
        wd = WIND_COEFF.get(wind_dir, 0.0)
        dir_term = clamp(s * wd * (0.30 + 0.70*float(prof_escape)) * 0.6, -0.03, 0.03)
        val += dir_term
    val = (val * float(WIND_SIGN)) * float(WIND_GAIN)
    return round(clamp(val, -float(WIND_CAP), float(WIND_CAP)), 3)

def bank_character_bonus(bank_angle, straight_length, prof_escape, prof_sashi):
    straight_factor = (float(straight_length)-40.0)/10.0
    angle_factor = (float(bank_angle)-25.0)/5.0
    total = clamp(-0.1*straight_factor + 0.1*angle_factor, -0.05, 0.05)
    return round(total*prof_escape - 0.5*total*prof_sashi, 3)
def bank_length_adjust(bank_length, prof_oikomi):
    delta = clamp((float(bank_length)-411.0)/100.0, -0.05, 0.05)
    return round(delta*prof_oikomi, 3)

def compute_lineSB_bonus(line_def, S, B, line_factor=1.0, exclude=None, cap=0.06, enable=True):
    if not enable or not line_def:
        return {g:0.0 for g in line_def.keys()} if line_def else {}, {}
    w_pos_base = {'head':1.0,'second':0.4,'thirdplus':0.2,'single':0.7}
    Sg, Bg = {}, {}
    for g, mem in line_def.items():
        s=b=0.0
        for car in mem:
            if exclude is not None and car==exclude: continue
            w = w_pos_base[role_in_line(car, line_def)] * line_factor
            s += w*float(S.get(car,0)); b += w*float(B.get(car,0))
        Sg[g]=s; Bg[g]=b
    raw={}
    for g in line_def.keys():
        s, b = Sg[g], Bg[g]
        ratioS = s/(s+b+1e-6)
        raw[g] = (0.6*b + 0.4*s) * (0.6 + 0.4*ratioS)
    zz = zscore_list(list(raw.values())) if raw else []
    bonus={g: clamp(0.02*float(zz[i]), -cap, cap) for i,g in enumerate(raw.keys())}
    return bonus, raw

def input_float_text(label: str, key: str, placeholder: str = "") -> float | None:
    s = st.text_input(label, value=st.session_state.get(key, ""), key=key, placeholder=placeholder)
    ss = unicodedata.normalize("NFKC", str(s)).replace(",", "").strip()
    if ss == "": return None
    if not re.fullmatch(r"[+-]?\d+(\.\d+)?", ss):
        st.warning(f"{label} ã¯æ•°å€¤ã§å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆå…¥åŠ›å€¤: {s}ï¼‰")
        return None
    return float(ss)

# KO Utilities
def _role_of(car, mem):
    if len(mem)==1: return 'single'
    i = mem.index(car)
    return ['head','second','thirdplus'][i] if i<3 else 'thirdplus'
def _line_strength_raw(line_def, S, B, line_factor=1.0):
    if not line_def: return {}
    w_pos = {'head':1.0,'second':0.4,'thirdplus':0.2,'single':0.7}
    raw={}
    for g, mem in line_def.items():
        s=b=0.0
        for c in mem:
            w = w_pos[_role_of(c, mem)] * line_factor
            s += w*float(S.get(c,0)); b += w*float(B.get(c,0))
        ratioS = s/(s+b+1e-6)
        raw[g] = (0.6*b + 0.4*s) * (0.6 + 0.4*ratioS)
    return raw
def _top2_lines(line_def, S, B, line_factor=1.0):
    raw = _line_strength_raw(line_def, S, B, line_factor)
    order = sorted(raw.keys(), key=lambda g: raw[g], reverse=True)
    return (order[0], order[1]) if len(order)>=2 else (order[0], None) if order else (None, None)
def _extract_role_car(line_def, gid, role_name):
    if gid is None or gid not in line_def: return None
    mem = line_def[gid]
    if role_name=='head':    return mem[0] if len(mem)>=1 else None
    if role_name=='second':  return mem[1] if len(mem)>=2 else None
    return None
def _ko_order(v_base_map, line_def, S, B, line_factor=1.0, gap_delta=0.010):
    cars = list(v_base_map.keys())
    if not line_def or len(line_def)<1:
        return [c for c,_ in sorted(v_base_map.items(), key=lambda x:x[1], reverse=True)]
    g1, g2 = _top2_lines(line_def, S, B, line_factor)
    head1 = _extract_role_car(line_def, g1, 'head');  head2 = _extract_role_car(line_def, g2, 'head')
    sec1  = _extract_role_car(line_def, g1, 'second');sec2  = _extract_role_car(line_def, g2, 'second')
    others=[]
    if g1:
        mem = line_def[g1]
        if len(mem)>=3: others += mem[2:]
    if g2:
        mem = line_def[g2]
        if len(mem)>=3: others += mem[2:]
    for g, mem in line_def.items():
        if g not in {g1,g2}:
            others += mem
    order = []
    head_pair = [x for x in [head1, head2] if x is not None]
    order += sorted(head_pair, key=lambda c: v_base_map.get(c, -1e9), reverse=True)
    sec_pair = [x for x in [sec1, sec2] if x is not None]
    order += sorted(sec_pair, key=lambda c: v_base_map.get(c, -1e9), reverse=True)
    others = list(dict.fromkeys([c for c in others if c is not None]))
    others_sorted = sorted(others, key=lambda c: v_base_map.get(c, -1e9), reverse=True)
    order += [c for c in others_sorted if c not in order]
    for c in cars:
        if c not in order:
            order.append(c)
    def _same_group(a,b):
        if a is None or b is None: return False
        ga = next((g for g,mem in line_def.items() if a in mem), None)
        gb = next((g for g,mem in line_def.items() if b in mem), None)
        return ga is not None and ga==gb
    i=0
    while i < len(order)-2:
        a, b, c = order[i], order[i+1], order[i+2]
        if _same_group(a, b):
            vx = v_base_map.get(b,0.0) - v_base_map.get(c,0.0)
            if vx >= -gap_delta:
                order.pop(i+2)
                order.insert(i+1, b)
        i += 1
    return order

def _zone_from_p(p: float):
    needed = 1.0 / max(p, 1e-12)
    return needed, needed*(1.0+E_MIN), needed*(1.0+E_MAX)

def apply_anchor_line_bonus(score_raw: dict[int,float], line_of: dict[int,int], role_map: dict[int,str], anchor: int, tenkai: str) -> dict[int,float]:
    a_line = line_of.get(anchor, None)
    is_on = (tenkai in LINE_BONUS_ON_TENKAI) and (a_line is not None)
    score_adj: dict[int,float] = {}
    for i, s in score_raw.items():
        bonus = 0.0
        if is_on and line_of.get(i) == a_line and i != anchor:
            role = role_map.get(i, "single")
            bonus = min(max(0.0, LINE_BONUS.get(role, 0.0)), LINE_BONUS_CAP)
        score_adj[i] = s + bonus
    return score_adj

def format_rank_all(score_map: dict[int,float], P_floor_val: float | None = None) -> str:
    order = sorted(score_map.keys(), key=lambda k: (-score_map[k], k))
    rows = []
    for i in order:
        if P_floor_val is None:
            rows.append(f"{i}")
        else:
            rows.append(f"{i}" if score_map[i] >= P_floor_val else f"{i}(Pæœªæº€)")
    return " ".join(rows)

# ==============================
# é¢¨ã®è‡ªå‹•å–å¾—ï¼ˆOpen-Meteo / æ™‚åˆ»å›ºå®šï¼‰
# ==============================
def make_target_dt_naive(jst_date, race_slot: str):
    h = SESSION_HOUR.get(race_slot, 11)
    if isinstance(jst_date, datetime):
        jst_date = jst_date.date()
    try:
        y, m, d = jst_date.year, jst_date.month, jst_date.day
    except Exception:
        dt = pd.to_datetime(str(jst_date))
        y, m, d = dt.year, dt.month, dt.day
    return datetime(y, m, d, h, 0, 0)

def fetch_openmeteo_hour(lat, lon, target_dt_naive):
    import numpy as np
    d = target_dt_naive.strftime("%Y-%m-%d")
    base = "https://api.open-meteo.com/v1/forecast"
    urls = [
        (f"{base}?latitude={lat:.5f}&longitude={lon:.5f}"
         "&hourly=wind_speed_10m,wind_direction_10m"
         "&timezone=Asia%2FTokyo"
         f"&start_date={d}&end_date={d}", True),
        (f"{base}?latitude={lat:.5f}&longitude={lon:.5f}"
         "&hourly=wind_speed_10m"
         "&timezone=Asia%2FTokyo"
         f"&start_date={d}&end_date={d}", False),
        (f"{base}?latitude={lat:.5f}&longitude={lon:.5f}"
         "&hourly=wind_speed_10m,wind_direction_10m"
         "&timezone=Asia%2FTokyo&past_days=2&forecast_days=2", True),
        (f"{base}?latitude={lat:.5f}&longitude={lon:.5f}"
         "&hourly=wind_speed_10m"
         "&timezone=Asia%2FTokyo&past_days=2&forecast_days=2", False),
    ]
    last_err = None
    for url, with_dir in urls:
        try:
            r = requests.get(url, timeout=15)
            r.raise_for_status()
            j = r.json().get("hourly", {})
            times = [datetime.fromisoformat(t) for t in j.get("time", [])]
            if not times: raise RuntimeError("empty hourly times")
            diffs = [abs((t - target_dt_naive).total_seconds()) for t in times]
            k = int(np.argmin(diffs))
            sp = j.get("wind_speed_10m", [])
            di = j.get("wind_direction_10m", []) if with_dir else []
            speed = float(sp[k]) if k < len(sp) else float("nan")
            deg   = (float(di[k]) if with_dir and k < len(di) else None)
            return {"time": times[k], "speed_ms": speed, "deg": deg, "diff_min": diffs[k]/60.0}
        except Exception as e:
            last_err = e
            continue
    raise RuntimeError(f"Open-Meteoå–å¾—å¤±æ•—ï¼ˆæœ€å¾Œã®ã‚¨ãƒ©ãƒ¼: {last_err}ï¼‰")

# ==============================
# ã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼šé–‹å‚¬æƒ…å ± / ãƒãƒ³ã‚¯ãƒ»é¢¨ãƒ»é ­æ•°
# ==============================

# --- ä¼šå ´å·®åˆ†ï¼ˆå¾—æ„ä¼šå ´å¹³å‡ã‚’æ¨™æº–ï¼‰ãƒ˜ãƒ«ãƒ‘ãƒ¼ï¼ˆã“ã®ãƒ–ãƒ­ãƒƒã‚¯å†…ã«è‡ªå·±å®Œçµï¼‰
FAVORABLE_VENUES = ["åå¤å±‹","ã„ã‚ãå¹³","å‰æ©‹","ç«‹å·","å®‡éƒ½å®®","å²¸å’Œç”°","é«˜çŸ¥"]

def _std_from_venues(names):
    Ls = [KEIRIN_DATA[v]["straight_length"] for v in names if v in KEIRIN_DATA]
    Th = [KEIRIN_DATA[v]["bank_angle"]      for v in names if v in KEIRIN_DATA]
    Cs = [KEIRIN_DATA[v]["bank_length"]     for v in names if v in KEIRIN_DATA]
    return (float(np.mean(Th)), float(np.mean(Ls)), float(np.mean(Cs)))

TH_STD, L_STD, C_STD = _std_from_venues(FAVORABLE_VENUES)

_ALL_L = np.array([KEIRIN_DATA[k]["straight_length"] for k in KEIRIN_DATA], float)
_ALL_TH = np.array([KEIRIN_DATA[k]["bank_angle"]      for k in KEIRIN_DATA], float)
SIG_L  = float(np.std(_ALL_L)) if np.std(_ALL_L)>1e-9 else 1.0
SIG_TH = float(np.std(_ALL_TH)) if np.std(_ALL_TH)>1e-9 else 1.0

def venue_z_terms(straight_length: float, bank_angle: float, bank_length: float):
    zL  = (float(straight_length) - L_STD)  / SIG_L
    zTH = (float(bank_angle)      - TH_STD) / SIG_TH
    if bank_length >= 480: dC = +0.4
    elif bank_length >= 380: dC = 0.0
    else: dC = -0.4
    return zL, zTH, dC

def venue_mix(zL, zTH, dC):
    # ç›´ç·šé•·â†‘ï¼å·®ã—/æ²ã‚Šå¯„ã‚Š(âˆ’)ã€ã‚«ãƒ³ãƒˆâ†‘ï¼å…ˆè¡Œ/ã‚¹ãƒ”ãƒ¼ãƒ‰å‹è² (+)ã€333çŸ­å‘¨é•·ï¼ãƒ©ã‚¤ãƒ³å¯„ã‚Š(âˆ’)
    return float(clamp(0.50*zTH - 0.35*zL - 0.30*dC, -1.0, +1.0))


st.sidebar.header("é–‹å‚¬æƒ…å ± / ãƒãƒ³ã‚¯ãƒ»é¢¨ãƒ»é ­æ•°")
n_cars = st.sidebar.selectbox("å‡ºèµ°æ•°ï¼ˆ5ã€œ9ï¼‰", [5,6,7,8,9], index=2)
track_names = list(KEIRIN_DATA.keys())
track = st.sidebar.selectbox("ç«¶è¼ªå ´ï¼ˆãƒ—ãƒªã‚»ãƒƒãƒˆï¼‰", track_names, index=track_names.index("å·å´") if "å·å´" in track_names else 0)
info = KEIRIN_DATA[track]
st.session_state["track"] = track

race_time = st.sidebar.selectbox("é–‹å‚¬åŒºåˆ†", ["ãƒ¢ãƒ¼ãƒ‹ãƒ³ã‚°","ãƒ‡ã‚¤","ãƒŠã‚¤ã‚¿ãƒ¼","ãƒŸãƒƒãƒ‰ãƒŠã‚¤ãƒˆ"], 1)
race_day = st.sidebar.date_input("é–‹å‚¬æ—¥ï¼ˆé¢¨ã®å–å¾—åŸºæº–æ—¥ï¼‰", value=date.today())

wind_dir = st.sidebar.selectbox("é¢¨å‘", ["ç„¡é¢¨","å·¦ä¸Š","ä¸Š","å³ä¸Š","å·¦","å³","å·¦ä¸‹","ä¸‹","å³ä¸‹"], index=0, key="wind_dir_input")
wind_speed_default = st.session_state.get("wind_speed", 3.0)
wind_speed = st.sidebar.number_input("é¢¨é€Ÿ(m/s)", 0.0, 30.0, float(wind_speed_default), 0.1)

with st.sidebar.expander("ğŸŒ€ é¢¨ã‚’APIã§è‡ªå‹•å–å¾—ï¼ˆOpen-Meteoï¼‰", expanded=False):
    api_date = st.date_input("é–‹å‚¬æ—¥ï¼ˆé¢¨ã®å–å¾—åŸºæº–æ—¥ï¼‰", value=pd.to_datetime("today").date(), key="api_date")
    st.caption("åŸºæº–æ™‚åˆ»ï¼šãƒ¢=8æ™‚ / ãƒ‡=11æ™‚ / ãƒŠ=18æ™‚ / ãƒŸ=22æ™‚ï¼ˆJSTãƒ»tzãªã—ã§å–å¾—ï¼‰")
    if st.button("APIã§å–å¾—â†’é¢¨é€Ÿã«åæ˜ ", use_container_width=True):
        info_xy = VELODROME_MASTER.get(track)
        if not info_xy or info_xy.get("lat") is None or info_xy.get("lon") is None:
            st.error(f"{track} ã®åº§æ¨™ãŒæœªç™»éŒ²ã§ã™ï¼ˆVELODROME_MASTER ã« lat/lon ã‚’å…¥ã‚Œã¦ãã ã•ã„ï¼‰")
        else:
            try:
                target = make_target_dt_naive(api_date, race_time)
                data = fetch_openmeteo_hour(info_xy["lat"], info_xy["lon"], target)
                st.session_state["wind_speed"] = round(float(data["speed_ms"]), 2)
                st.success(f"{track} {target:%Y-%m-%d %H:%M} é¢¨é€Ÿ {st.session_state['wind_speed']:.1f} m/s ï¼ˆAPIå´ã¨{data['diff_min']:.0f}åˆ†ã‚ºãƒ¬ï¼‰")
                st.rerun()
            except Exception as e:
                st.error(f"å–å¾—ã«å¤±æ•—ï¼š{e}")

straight_length = st.sidebar.number_input("ã¿ãªã—ç›´ç·š(m)", 30.0, 80.0, float(info["straight_length"]), 0.1)
bank_angle = st.sidebar.number_input("ãƒãƒ³ã‚¯è§’(Â°)", 20.0, 45.0, float(info["bank_angle"]), 0.1)
bank_length = st.sidebar.number_input("å‘¨é•·(m)", 300.0, 500.0, float(info["bank_length"]), 0.1)

base_laps = st.sidebar.number_input("å‘¨å›ï¼ˆé€šå¸¸4ï¼‰", 1, 10, 4, 1)
day_label = st.sidebar.selectbox("é–‹å‚¬æ—¥", ["åˆæ—¥","2æ—¥ç›®","æœ€çµ‚æ—¥"], 0)
eff_laps = int(base_laps) + {"åˆæ—¥":1,"2æ—¥ç›®":2,"æœ€çµ‚æ—¥":3}[day_label]

race_class = st.sidebar.selectbox("ç´šåˆ¥", ["ï¼³ç´š","ï¼¡ç´š","ï¼¡ç´šãƒãƒ£ãƒ¬ãƒ³ã‚¸","ã‚¬ãƒ¼ãƒ«ã‚º"], 0)

# === ä¼šå ´styleã‚’ã€Œå¾—æ„ä¼šå ´å¹³å‡ã€ã‚’åŸºæº–ã«å†å®šç¾©
zL, zTH, dC = venue_z_terms(straight_length, bank_angle, bank_length)
style_raw = venue_mix(zL, zTH, dC)
override = st.sidebar.slider("ä¼šå ´ãƒã‚¤ã‚¢ã‚¹è£œæ­£ï¼ˆâˆ’2å·®ã— â†â†’ +2å…ˆè¡Œï¼‰", -2.0, 2.0, 0.0, 0.1)
style = clamp(style_raw + 0.25*override, -1.0, +1.0)

CLASS_FACTORS = {
    "ï¼³ç´š":           {"spread":1.00, "line":1.00},
    "ï¼¡ç´š":           {"spread":0.90, "line":0.85},
    "ï¼¡ç´šãƒãƒ£ãƒ¬ãƒ³ã‚¸": {"spread":0.80, "line":0.70},
    "ã‚¬ãƒ¼ãƒ«ã‚º":       {"spread":0.85, "line":1.00},
}
cf = CLASS_FACTORS[race_class]

# æ—§ï¼š
# DAY_FACTOR = {"åˆæ—¥":1.00, "2æ—¥ç›®":0.60, "æœ€çµ‚æ—¥":0.85}

# æ–°ï¼ˆã¾ãšã¯å®Œå…¨ãƒ•ãƒ©ãƒƒãƒˆï¼‰ï¼š
DAY_FACTOR = {"åˆæ—¥":1.00, "2æ—¥ç›®":1.00, "æœ€çµ‚æ—¥":1.00}
day_factor = DAY_FACTOR[day_label]

cap_base = clamp(0.06 + 0.02*style, 0.04, 0.08)
line_factor_eff = cf["line"] * day_factor
cap_SB_eff = cap_base * day_factor
if race_time == "ãƒŸãƒƒãƒ‰ãƒŠã‚¤ãƒˆ":
    line_factor_eff *= 0.95
    cap_SB_eff *= 0.95

# ===== æ—¥ç¨‹ãƒ»ç´šåˆ¥ãƒ»é ­æ•°ã§â€œå‘¨å›ç–²åŠ´ã®åŠ¹ãâ€ã‚’è–„ãã‚·ãƒ•ãƒˆï¼ˆå‡ºåŠ›ã«ã¯å‡ºã•ãªã„ï¼‰ =====
DAY_SHIFT = {"åˆæ—¥": -0.5, "2æ—¥ç›®": 0.0, "æœ€çµ‚æ—¥": +0.5}
CLASS_SHIFT = {"ï¼³ç´š": 0.0, "ï¼¡ç´š": +0.10, "ï¼¡ç´šãƒãƒ£ãƒ¬ãƒ³ã‚¸": +0.20, "ã‚¬ãƒ¼ãƒ«ã‚º": -0.10}
HEADCOUNT_SHIFT = {5: -0.20, 6: -0.10, 7: -0.05, 8: 0.0, 9: +0.10}

def fatigue_extra(eff_laps: int, day_label: str, n_cars: int, race_class: str) -> float:
    """
    æ—¢å­˜ã® extra = max(eff_laps - 2, 0) ã‚’ãƒ™ãƒ¼ã‚¹ã«ã€
    ãƒ»æ—¥ç¨‹ã‚·ãƒ•ãƒˆï¼šåˆæ—¥ -0.5ï¼2æ—¥ç›® 0ï¼æœ€çµ‚æ—¥ +0.5
    ãƒ»ç´šåˆ¥ã‚·ãƒ•ãƒˆï¼šAç´š/ãƒãƒ£ãƒ¬ãƒ³ã‚¸ã‚’ã‚„ã‚„é‡ã‚ã€ã‚¬ãƒ¼ãƒ«ã‚ºã¯ã‚„ã‚„è»½ã‚
    ãƒ»é ­æ•°ã‚·ãƒ•ãƒˆï¼š9è»Šã¯å°‘ã—é‡ãã€5ã€œ7è»Šã¯å°‘ã—è»½ã
    """
    d = float(DAY_SHIFT.get(day_label, 0.0))
    c = float(CLASS_SHIFT.get(race_class, 0.0))
    h = float(HEADCOUNT_SHIFT.get(int(n_cars), 0.0))
    x = (float(eff_laps) - 2.0) + d + c + h
    return max(0.0, x)


line_sb_enable = (race_class != "ã‚¬ãƒ¼ãƒ«ã‚º")

st.sidebar.caption(
    f"ä¼šå ´ã‚¹ã‚¿ã‚¤ãƒ«: {style:+.2f}ï¼ˆraw {style_raw:+.2f}ï¼‰ / "
    f"ç´šåˆ¥: spread={cf['spread']:.2f}, line={cf['line']:.2f} / "
    f"æ—¥ç¨‹ä¿‚æ•°(line)={day_factor:.2f} â†’ lineä¿‚æ•°={line_factor_eff:.2f}, SBcapÂ±{cap_SB_eff:.2f}"
)

# ==============================
# ãƒ¡ã‚¤ãƒ³ï¼šå…¥åŠ›
# ==============================
st.title("â­ ãƒ´ã‚§ãƒ­ãƒ“ï¼ˆç´šåˆ¥Ã—æ—¥ç¨‹ãƒ€ã‚¤ãƒŠãƒŸã‚¯ã‚¹ / 5ã€œ9è»Šãƒ»è²·ã„ç›®ä»˜ãï¼šçµ±åˆç‰ˆï¼‰â­")
st.caption(f"é¢¨è£œæ­£ãƒ¢ãƒ¼ãƒ‰: {WIND_MODE}ï¼ˆ'speed_only'=é¢¨é€Ÿã®ã¿ / 'directional'=å‘ãã‚‚è–„ãè€ƒæ…®ï¼‰")

st.subheader("ãƒ¬ãƒ¼ã‚¹ç•ªå·ï¼ˆç›´å‰ã«ã‚µã‚¯ãƒƒã¨å¤‰æ›´ï¼‰")
if "race_no_main" not in st.session_state:
    st.session_state["race_no_main"] = 1
c1, c2, c3 = st.columns([6,2,2])
with c1:
    race_no_input = st.number_input("R", min_value=1, max_value=12, step=1,
                                    value=int(st.session_state["race_no_main"]),
                                    key="race_no_input")
with c2:
    prev_clicked = st.button("â—€ å‰ã®R", use_container_width=True)
with c3:
    next_clicked = st.button("æ¬¡ã®R â–¶", use_container_width=True)
if prev_clicked:
    st.session_state["race_no_main"] = max(1, int(race_no_input) - 1); st.rerun()
elif next_clicked:
    st.session_state["race_no_main"] = min(12, int(race_no_input) + 1); st.rerun()
else:
    st.session_state["race_no_main"] = int(race_no_input)
race_no = int(st.session_state["race_no_main"])

st.subheader("ãƒ©ã‚¤ãƒ³æ§‹æˆï¼ˆæœ€å¤§7ï¼šå˜é¨ã‚‚1ãƒ©ã‚¤ãƒ³ï¼‰")
line_inputs = [
    st.text_input("ãƒ©ã‚¤ãƒ³1ï¼ˆä¾‹ï¼š317ï¼‰", key="line_1", max_chars=9),
    st.text_input("ãƒ©ã‚¤ãƒ³2ï¼ˆä¾‹ï¼š6ï¼‰", key="line_2", max_chars=9),
    st.text_input("ãƒ©ã‚¤ãƒ³3ï¼ˆä¾‹ï¼š425ï¼‰", key="line_3", max_chars=9),
    st.text_input("ãƒ©ã‚¤ãƒ³4ï¼ˆä»»æ„ï¼‰", key="line_4", max_chars=9),
    st.text_input("ãƒ©ã‚¤ãƒ³5ï¼ˆä»»æ„ï¼‰", key="line_5", max_chars=9),
    st.text_input("ãƒ©ã‚¤ãƒ³6ï¼ˆä»»æ„ï¼‰", key="line_6", max_chars=9),
    st.text_input("ãƒ©ã‚¤ãƒ³7ï¼ˆä»»æ„ï¼‰", key="line_7", max_chars=9),
]
n_cars = int(n_cars)
lines = [extract_car_list(x, n_cars) for x in line_inputs if str(x).strip()]
line_def, car_to_group = build_line_maps(lines)
active_cars = sorted({c for lst in lines for c in lst}) if lines else list(range(1, n_cars+1))

st.subheader("å€‹äººãƒ‡ãƒ¼ã‚¿ï¼ˆç›´è¿‘4ã‹æœˆï¼šå›æ•°ï¼‰")
cols = st.columns(n_cars)
ratings, S, B = {}, {}, {}
k_esc, k_mak, k_sashi, k_mark = {}, {}, {}, {}
x1, x2, x3, x_out = {}, {}, {}, {}

for i, no in enumerate(active_cars):
    with cols[i]:
        st.markdown(f"**{no}ç•ª**")
        ratings[no] = input_float_text("å¾—ç‚¹ï¼ˆç©ºæ¬„å¯ï¼‰", key=f"pt_{no}", placeholder="ä¾‹: 55.0")
        S[no] = st.number_input("S", 0, 99, 0, key=f"s_{no}")
        B[no] = st.number_input("B", 0, 99, 0, key=f"b_{no}")
        k_esc[no]   = st.number_input("é€ƒ", 0, 99, 0, key=f"ke_{no}")
        k_mak[no]   = st.number_input("æ²", 0, 99, 0, key=f"km_{no}")
        k_sashi[no] = st.number_input("å·®", 0, 99, 0, key=f"ks_{no}")
        k_mark[no]  = st.number_input("ãƒ", 0, 99, 0, key=f"kk_{no}")
        x1[no]  = st.number_input("1ç€", 0, 99, 0, key=f"x1_{no}")
        x2[no]  = st.number_input("2ç€", 0, 99, 0, key=f"x2_{no}")
        x3[no]  = st.number_input("3ç€", 0, 99, 0, key=f"x3_{no}")
        x_out[no]= st.number_input("ç€å¤–", 0, 99, 0, key=f"xo_{no}")

ratings_val = {no: (ratings[no] if ratings[no] is not None else 55.0) for no in active_cars}

# 1ç€ãƒ»2ç€ã®ç¸®ç´„ï¼ˆç´šåˆ¥Ã—ä¼šå ´ã®äº‹å‰åˆ†å¸ƒã‚’æ··ãœã‚‹ï¼‰
def prior_by_class(cls, style_adj):
    if "ã‚¬ãƒ¼ãƒ«" in cls: p1,p2 = 0.18,0.24
    elif "ï¼³ç´š" in cls: p1,p2 = 0.22,0.26
    elif "ãƒãƒ£ãƒ¬ãƒ³ã‚¸" in cls: p1,p2 = 0.18,0.22
    else: p1,p2 = 0.20,0.25
    p1 += 0.010*style_adj; p2 -= 0.005*style_adj
    return clamp(p1,0.05,0.60), clamp(p2,0.05,0.60)

def n0_by_n(n):
    if n<=6: return 12
    if n<=14: return 8
    if n<=29: return 5
    return 3

# ã“ã“ã¯å¾“æ¥é€šã‚Šã§OK
p1_eff, p2_eff = {}, {}
for no in active_cars:
    n = x1[no]+x2[no]+x3[no]+x_out[no]
    p1_prior, p2_prior = prior_by_class(race_class, style)
    n0 = n0_by_n(n)
    if n==0:
        p1_eff[no], p2_eff[no] = p1_prior, p2_prior
    else:
        p1_eff[no] = clamp((x1[no] + n0*p1_prior)/(n+n0), 0.0, 0.40)
        p2_eff[no] = clamp((x2[no] + n0*p2_prior)/(n+n0), 0.0, 0.50)

# â˜…è¿½åŠ ï¼šForm = å‹ç‡Ã—0.7 + é€£å¯¾ç‡Ã—0.3
Form = {no: 0.7*p1_eff[no] + 0.3*p2_eff[no] for no in active_cars}




# === Formï¼ˆå‹ç‡Ã—0.7 + é€£å¯¾ç‡Ã—0.3ï¼‰
Form = {no: 0.7*p1_eff[no] + 0.3*p2_eff[no] for no in active_cars}

# === Form åå·®å€¤åŒ–ï¼ˆå¹³å‡50, SD10ï¼‰
form_list = [Form[n] for n in active_cars]
form_T, mu_form, sd_form, _ = t_score_from_finite(np.array(form_list))
form_T_map = {n: float(form_T[i]) for i,n in enumerate(active_cars)}


# --- è„šè³ªãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ï¼ˆä¼šå ´é©æ€§ï¼šå¾—æ„ä¼šå ´å¹³å‡åŸºæº–ã®styleã‚’æ›ã‘ã‚‹ï¼‰
prof_base, prof_escape, prof_sashi, prof_oikomi = {}, {}, {}, {}
for no in active_cars:
    tot = k_esc[no]+k_mak[no]+k_sashi[no]+k_mark[no]
    if tot==0: esc=mak=sashi=mark = 0.25
    else:
        esc=k_esc[no]/tot; mak=k_mak[no]/tot; sashi=k_sashi[no]/tot; mark=k_mark[no]/tot
    prof_escape[no]=esc; prof_sashi[no]=sashi; prof_oikomi[no]=mark
    base = esc*BASE_BY_KAKU["é€ƒ"] + mak*BASE_BY_KAKU["æ²"] + sashi*BASE_BY_KAKU["å·®"] + mark*BASE_BY_KAKU["ãƒ"]
    vmix = style
    venue_bonus = 0.06 * vmix * ( +1.00*esc + 0.40*mak - 0.60*sashi - 0.25*mark )
    prof_base[no] = base + clamp(venue_bonus, -0.06, +0.06)

# ======== å€‹äººè£œæ­£ï¼ˆå¾—ç‚¹/è„šè³ªä¸Šä½/ç€é †åˆ†å¸ƒï¼‰ ========
ratings_sorted = sorted(active_cars, key=lambda n: ratings_val[n], reverse=True)
ratings_rank = {no: i+1 for i,no in enumerate(ratings_sorted)}
def tenscore_bonus(no):
    r = ratings_rank[no]
    top_n = min(3, len(active_cars))
    bottom_n = min(3, len(active_cars))
    if r <= top_n: return +0.03
    if r >= len(active_cars)-bottom_n+1: return -0.02
    return 0.0
def topk_bonus(k_dict, topn=3, val=0.02):
    order = sorted(k_dict.items(), key=lambda x:(x[1], -x[0]), reverse=True)
    grant = set([no for i,(no,v) in enumerate(order) if i<topn])
    return {no:(val if no in grant else 0.0) for no in k_dict}
esc_bonus   = topk_bonus(k_esc,   topn=3, val=0.02)
mak_bonus   = topk_bonus(k_mak,   topn=3, val=0.02)
sashi_bonus = topk_bonus(k_sashi, topn=3, val=0.015)
mark_bonus  = topk_bonus(k_mark,  topn=3, val=0.01)
def finish_bonus(no):
    tot = x1[no]+x2[no]+x3[no]+x_out[no]
    if tot == 0: return 0.0
    in3 = (x1[no]+x2[no]+x3[no]) / tot
    out = x_out[no] / tot
    bonus = 0.0
    if in3 > 0.50: bonus += 0.03
    if out > 0.70: bonus -= 0.03
    if out < 0.40: bonus += 0.02
    return bonus
extra_bonus = {}
for no in active_cars:
    total = (tenscore_bonus(no) +
             esc_bonus.get(no,0.0) + mak_bonus.get(no,0.0) +
             sashi_bonus.get(no,0.0) + mark_bonus.get(no,0.0) +
             finish_bonus(no))
    extra_bonus[no] = clamp(total, -0.10, +0.10)

# ===== ä¼šå ´å€‹æ€§ã‚’â€œå€‹äººã‚¹ã‚³ã‚¢â€ã«æµ¸é€ï¼šbankç³»è£œæ­£ã‚’å·®ã—æ›¿ãˆ =====
def bank_character_bonus(bank_angle, straight_length, prof_escape, prof_sashi):
    zL, zTH, dC = venue_z_terms(straight_length, bank_angle, bank_length)
    base = clamp(0.06*zTH - 0.05*zL - 0.03*dC, -0.08, +0.08)
    return round(base*float(prof_escape) - 0.5*base*float(prof_sashi), 3)

def bank_length_adjust(bank_length, prof_oikomi):
    dC = (+0.4 if bank_length>=480 else 0.0 if bank_length>=380 else -0.4)
    return round(0.03*(-dC)*float(prof_oikomi), 3)

# --- å®‰å®šåº¦ï¼ˆç€é †åˆ†å¸ƒï¼‰ã‚’Tæœ¬ä½“ã«å…¥ã‚Œã‚‹ãŸã‚ã®é‡ã¿ï¼ˆå¼·åŒ–ç‰ˆï¼‰ ---
STAB_W_IN3  = 0.18   # 3ç€å†…ã®å¯„ä¸
STAB_W_OUT  = 0.22   # ç€å¤–ã®ãƒšãƒŠãƒ«ãƒ†ã‚£
STAB_W_LOWN = 0.06   # ã‚µãƒ³ãƒ—ãƒ«ä¸è¶³ãƒšãƒŠãƒ«ãƒ†ã‚£
STAB_PRIOR_IN3 = 0.33
STAB_PRIOR_OUT = 0.45

def stability_score(no: int) -> float:
    n1 = x1.get(no, 0); n2 = x2.get(no, 0); n3 = x3.get(no, 0); nOut = x_out.get(no, 0)
    n  = n1 + n2 + n3 + nOut
    if n <= 0:
        return 0.0
    # å°‘ã‚µãƒ³ãƒ—ãƒ«ç¸®ç´„ï¼ˆã“ã®é–¢æ•°å†…ã§å®Œçµï¼‰
    if n <= 6:    n0 = 12
    elif n <= 14: n0 = 8
    elif n <= 29: n0 = 5
    else:         n0 = 3

    in3  = (n1 + n2 + n3 + n0*STAB_PRIOR_IN3) / (n + n0)
    out_ = (nOut          + n0*STAB_PRIOR_OUT) / (n + n0)

    bonus = 0.0
    bonus += STAB_W_IN3 * (in3 - STAB_PRIOR_IN3) * 2.0
    bonus -= STAB_W_OUT * (out_ - STAB_PRIOR_OUT) * 2.0

    if n < 10:
        bonus -= STAB_W_LOWN * (10 - n) / 10.0

    # ã‚­ãƒ£ãƒƒãƒ—ï¼šnã«å¿œã˜ã¦æ®µéšçš„ã«åºƒã’ã‚‹ï¼ˆÂ±0.35ã€œÂ±0.45ï¼‰
    cap = 0.35
    if n >= 15: cap = 0.45
    elif n >= 10: cap = 0.40

    return clamp(bonus, -cap, +cap)

# ===== SBãªã—åˆè¨ˆï¼ˆç’°å¢ƒè£œæ­£ + å¾—ç‚¹å¾®è£œæ­£ + å€‹äººè£œæ­£ + å‘¨å›ç–²åŠ´ + å®‰å®šåº¦ï¼‰ =====
tens_list = [ratings_val[no] for no in active_cars]
t_corr = tenscore_correction(tens_list) if active_cars else []
tens_corr = {no:t_corr[i] for i,no in enumerate(active_cars)} if active_cars else {}

rows = []
_wind_func = wind_adjust
eff_wind_dir   = globals().get("eff_wind_dir",   wind_dir)
eff_wind_speed = globals().get("eff_wind_speed", wind_speed)

for no in active_cars:
    role = role_in_line(no, line_def)

    # å‘¨å›ç–²åŠ´ï¼ˆDAYÃ—é ­æ•°Ã—ç´šåˆ¥ã‚’åæ˜ ï¼‰
    extra = fatigue_extra(eff_laps, day_label, n_cars, race_class)
    fatigue_scale = (1.0 if race_class == "ï¼³ç´š" else
                     1.1 if race_class == "ï¼¡ç´š" else
                     1.2 if race_class == "ï¼¡ç´šãƒãƒ£ãƒ¬ãƒ³ã‚¸" else
                     1.05)
    laps_adj = (
        -0.10 * extra * (1.0 if prof_escape[no] > 0.5 else 0.0)
        + 0.05 * extra * (1.0 if prof_oikomi[no] > 0.4 else 0.0)
    ) * fatigue_scale

    wind = _wind_func(eff_wind_dir, float(eff_wind_speed or 0.0), role, float(prof_escape[no]))
    bank_b   = bank_character_bonus(bank_angle, straight_length, prof_escape[no], prof_sashi[no])
    length_b = bank_length_adjust(bank_length, prof_oikomi[no])
    indiv = extra_bonus.get(no, 0.0)
    stab  = stability_score(no)  # å®‰å®šåº¦

    total_raw = (prof_base[no] + wind + cf["spread"] * tens_corr.get(no, 0.0)
                 + bank_b + length_b + laps_adj + indiv + stab)

    rows.append([int(no), role, round(prof_base[no],3), round(wind,3),
                 round(cf["spread"] * tens_corr.get(no, 0.0),3),
                 round(bank_b,3), round(length_b,3), round(laps_adj,3),
                 round(indiv,3), round(stab,3), total_raw])


df = pd.DataFrame(rows, columns=[
    "è»Šç•ª","å½¹å‰²","è„šè³ªåŸºæº–(ä¼šå ´)","é¢¨è£œæ­£","å¾—ç‚¹è£œæ­£","ãƒãƒ³ã‚¯è£œæ­£",
    "å‘¨é•·è£œæ­£","å‘¨å›è£œæ­£","å€‹äººè£œæ­£","å®‰å®šåº¦","åˆè¨ˆ_SBãªã—_raw",
])
mu = float(df["åˆè¨ˆ_SBãªã—_raw"].mean()) if not df.empty else 0.0
df["åˆè¨ˆ_SBãªã—"] = mu + 1.0 * (df["åˆè¨ˆ_SBãªã—_raw"] - mu)

# ===== KOæ–¹å¼ï¼ˆå°ã«æ··ãœãšï¼šå±•é–‹ãƒ»ã‚±ãƒ³ã§åˆ©ç”¨ï¼‰ =====
v_wo = {int(k): float(v) for k, v in zip(df["è»Šç•ª"].astype(int), df["åˆè¨ˆ_SBãªã—"].astype(float))}
_is_girls = (race_class == "ã‚¬ãƒ¼ãƒ«ã‚º")
head_scale = KO_HEADCOUNT_SCALE.get(int(n_cars), 1.0)
ko_scale_raw = (KO_GIRLS_SCALE if _is_girls else 1.0) * head_scale
KO_SCALE_MAX = 0.45
ko_scale = min(ko_scale_raw, KO_SCALE_MAX)

if ko_scale > 0.0 and line_def and len(line_def) >= 1:
    ko_order = _ko_order(v_wo, line_def, S, B,
                         line_factor=line_factor_eff,
                         gap_delta=KO_GAP_DELTA)
    vals = [v_wo[c] for c in v_wo.keys()]
    mu0  = float(np.mean(vals)); sd0 = float(np.std(vals) + 1e-12)
    KO_STEP_SIGMA_LOCAL = max(0.25, KO_STEP_SIGMA * 0.7)
    step = KO_STEP_SIGMA_LOCAL * sd0

    new_scores = {}
    for rank, car in enumerate(ko_order, start=1):
        rank_adjust = step * (len(ko_order) - rank)
        blended = (1.0 - ko_scale) * v_wo[car] + ko_scale * (
            mu0 + rank_adjust - (len(ko_order)/2.0 - 0.5)*step
        )
        new_scores[car] = blended
    v_final = {int(k): float(v) for k, v in new_scores.items()}
else:
    if v_wo:
        ko_order = sorted(v_wo.keys(), key=lambda c: v_wo[c], reverse=True)
        v_final = {int(c): float(v_wo[c]) for c in ko_order}
    else:
        ko_order = []
        v_final = {}

# --- ç´”SBãªã—ãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼ˆKOã¾ã§ï¼æ ¼ä¸Šã’å‰ï¼‰
df_sorted_pure = pd.DataFrame({
    "è»Šç•ª": list(v_final.keys()),
    "åˆè¨ˆ_SBãªã—": [round(float(v_final[c]), 6) for c in v_final.keys()]
}).sort_values("åˆè¨ˆ_SBãªã—", ascending=False).reset_index(drop=True)

# ===== å°ç”¨ï¼ˆæ—¢å­˜ã®å®‰å…¨å¼ã‚’ç¶­æŒï¼‰
FINISH_WEIGHT   = globals().get("FINISH_WEIGHT", 6.0)
FINISH_WEIGHT_G = globals().get("FINISH_WEIGHT_G", 3.0)
POS_BONUS  = globals().get("POS_BONUS", {0: 0.0, 1: -0.6, 2: -0.9, 3: -1.2, 4: -1.4})
POS_WEIGHT = globals().get("POS_WEIGHT", 1.0)
SMALL_Z_RATING = globals().get("SMALL_Z_RATING", 0.01)
FINISH_CLIP = globals().get("FINISH_CLIP", 4.0)
TIE_EPSILON  = globals().get("TIE_EPSILON", 0.8)

p2_list = [float(p2_eff.get(n, 0.0)) for n in active_cars]
if len(p2_list) >= 1:
    mu_p2  = float(np.mean(p2_list))
    sd_p2  = float(np.std(p2_list) + 1e-12)
else:
    mu_p2, sd_p2 = 0.0, 1.0
p2z_map = {n: (float(p2_eff.get(n, 0.0)) - mu_p2) / sd_p2 for n in active_cars}
p1_eff_safe = {n: float(p1_eff.get(n, 0.0)) if 'p1_eff' in globals() and p1_eff is not None else 0.0 for n in active_cars}
p2only_map = {n: max(0.0, float(p2_eff.get(n, 0.0)) - float(p1_eff_safe.get(n, 0.0))) for n in active_cars}
zt = zscore_list([ratings_val[n] for n in active_cars]) if active_cars else []
zt_map = {n: float(zt[i]) for i, n in enumerate(active_cars)} if active_cars else {}

def _pos_idx(no:int) -> int:
    g = car_to_group.get(no, None)
    if g is None or g not in line_def:
        return 0
    grp = line_def[g]
    try:
        return max(0, int(grp.index(no)))
    except Exception:
        return 0

bonus_init,_ = compute_lineSB_bonus(line_def, S, B, line_factor=line_factor_eff, exclude=None, cap=cap_SB_eff, enable=line_sb_enable)

def anchor_score(no:int) -> float:
    base = float(v_final.get(no, -1e9))
    role = role_in_line(no, line_def)
    sb = float(bonus_init.get(car_to_group.get(no, None), 0.0) *
               (pos_coeff(role, 1.0) if line_sb_enable else 0.0))
    pos_term = POS_WEIGHT * POS_BONUS.get(_pos_idx(no), 0.0)

    # â˜…ã“ã“ã‚’å·®ã—æ›¿ãˆ
    raw_finish = (form_T_map.get(no, 50.0) - 50.0) / 10.0
    if _is_girls:
        finish_term = FINISH_WEIGHT_G * raw_finish
    else:
        finish_term = FINISH_WEIGHT * raw_finish

    finish_term = max(-FINISH_CLIP, min(FINISH_CLIP, finish_term))
    return base + sb + pos_term + finish_term + SMALL_Z_RATING * zt_map.get(no, 0.0)


# ===== â—å€™è£œæŠ½å‡ºï¼ˆæ—¢å­˜ãƒ­ã‚¸ãƒƒã‚¯ç¶­æŒï¼‰
cand_sorted = sorted(active_cars, key=lambda n: anchor_score(n), reverse=True)
C = cand_sorted[:min(3, len(cand_sorted))]
ratings_sorted2 = sorted(active_cars, key=lambda n: ratings_val[n], reverse=True)
ratings_rank2 = {n: i+1 for i,n in enumerate(ratings_sorted2)}
ALLOWED_MAX_RANK = globals().get("ALLOWED_MAX_RANK", 5)

guarantee_top_rating = True
if guarantee_top_rating and (race_class == "ã‚¬ãƒ¼ãƒ«ã‚º") and len(ratings_sorted2) >= 1:
    top_rating_car = ratings_sorted2[0]
    if top_rating_car not in C:
        C = [top_rating_car] + [c for c in C if c != top_rating_car]
        C = C[:min(3, len(cand_sorted))]

ANCHOR_CAND_SB_TOPK   = globals().get("ANCHOR_CAND_SB_TOPK", 5)
ANCHOR_REQUIRE_TOP_SB = globals().get("ANCHOR_REQUIRE_TOP_SB", 3)
rank_pure = {int(df_sorted_pure.loc[i, "è»Šç•ª"]): i+1 for i in range(len(df_sorted_pure))}
cand_pool = [c for c in C if rank_pure.get(c, 999) <= ANCHOR_CAND_SB_TOPK]
if not cand_pool:
    cand_pool = [int(df_sorted_pure.loc[i, "è»Šç•ª"]) for i in range(min(ANCHOR_CAND_SB_TOPK, len(df_sorted_pure)))]
anchor_no_pre = max(cand_pool, key=lambda x: anchor_score(x)) if cand_pool else int(df_sorted_pure.loc[0, "è»Šç•ª"])
anchor_no = anchor_no_pre
top2 = sorted(cand_pool, key=lambda x: anchor_score(x), reverse=True)[:2]
if len(top2) >= 2:
    s1 = anchor_score(top2[0]); s2 = anchor_score(top2[1])
    if (s1 - s2) < TIE_EPSILON:
        better_by_rating = min(top2, key=lambda x: ratings_rank2.get(x, 999))
        anchor_no = better_by_rating
if rank_pure.get(anchor_no, 999) > ANCHOR_REQUIRE_TOP_SB:
    pool = [c for c in cand_pool if rank_pure.get(c, 999) <= ANCHOR_REQUIRE_TOP_SB]
    if pool:
        anchor_no = max(pool, key=lambda x: anchor_score(x))
    else:
        anchor_no = int(df_sorted_pure.loc[0, "è»Šç•ª"])
    st.caption(f"â€» â—ã¯ã€SBãªã— ä¸Šä½{ANCHOR_REQUIRE_TOP_SB}ä½ä»¥å†…ã€ç¸›ã‚Šã§ {anchor_no_pre}â†’{anchor_no} ã«èª¿æ•´ã€‚")

role_map = {no: role_in_line(no, line_def) for no in active_cars}
cand_scores = [anchor_score(no) for no in C] if len(C) >= 2 else [0, 0]
cand_scores_sorted = sorted(cand_scores, reverse=True)
conf_gap = cand_scores_sorted[0] - cand_scores_sorted[1] if len(cand_scores_sorted) >= 2 else 0.0
spread = float(np.std(list(v_final.values()))) if len(v_final) >= 2 else 0.0
norm = conf_gap / (spread if spread > 1e-6 else 1.0)
confidence = "å„ªä½" if norm >= 1.0 else ("äº’è§’" if norm >= 0.5 else "æ··æˆ¦")

score_adj_map = apply_anchor_line_bonus(v_final, car_to_group, role_map, anchor_no, confidence)

df_sorted_wo = pd.DataFrame({
    "è»Šç•ª": active_cars,
    "åˆè¨ˆ_SBãªã—": [round(float(score_adj_map.get(int(c), v_final.get(int(c), float("-inf")))), 6) for c in active_cars]
}).sort_values("åˆè¨ˆ_SBãªã—", ascending=False).reset_index(drop=True)

velobi_wo = list(zip(df_sorted_wo["è»Šç•ª"].astype(int).tolist(),
                     df_sorted_wo["åˆè¨ˆ_SBãªã—"].round(3).tolist()))

# ==============================
# â˜… ãƒ¬ãƒ¼ã‚¹å†…Tåå·®å€¤ â†’ å° â†’ è²·ã„ç›® â†’ noteå‡ºåŠ›ï¼ˆ2è»Šç³»å¯¾å¿œï¼‹ä¼šå ´å€‹æ€§æµ¸é€ç‰ˆï¼‰
# ==============================
import math
import numpy as np
import pandas as pd
import streamlit as st
from itertools import combinations

# ===== ã—ãã„å€¤ï¼ˆSï¼åå·®å€¤Tã®åˆç®—ï¼‰ =====
S_TRIO_MIN_WIDE  = 158.0   # ä¸‰é€£è¤‡ï¼šæ‰‹åºƒã
S_TRIO_MIN_CORE  = 163.0   # ä¸‰é€£è¤‡ï¼šåŸºæº–ã‚¯ãƒªã‚¢ï¼ˆã“ã‚ŒãŒâ€œæœ¬ç·šâ€ï¼‰
S_QN_MIN         = 122.0
S_WIDE_MIN       = 116.0

# ä¸‰é€£å˜ã¯â€œåŸºæº–ã‚¯ãƒªã‚¢â€å´ã«åˆã‚ã›ã¦é‹ç”¨ï¼ˆç›¸è«‡ã©ãŠã‚Š164ï¼‰
S_TRIFECTA_MIN   = 164.0

# ç›®æ¨™å›åç‡ï¼ˆæ®ãˆç½®ãï¼‰
TARGET_ROI = {"trio":1.20, "qn":1.10, "wide":1.05}
ODDS_FLOOR_QN   = 8.0
ODDS_FLOOR_WIDE = 4.0
HEN_DEC_PLACES = 1
EPS = 1e-12


# ====== ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ ======
def coerce_score_map(d, n_cars: int) -> dict[int, float]:
    out: dict[int, float] = {}
    t = str(type(d)).lower()
    if "pandas.core.frame" in t:
        df_ = d
        car_col = "è»Šç•ª" if "è»Šç•ª" in df_.columns else None
        if car_col is None:
            for c in df_.columns:
                if np.issubdtype(df_[c].dtype, np.integer):
                    car_col = c; break
        score_col = None
        for cand in ["åˆè¨ˆ_SBãªã—","SBãªã—","ã‚¹ã‚³ã‚¢","score","SB_wo","SB"]:
            if cand in df_.columns:
                score_col = cand; break
        if score_col is None:
            for c in df_.columns:
                if c == car_col: continue
                if np.issubdtype(df_[c].dtype, np.number):
                    score_col = c; break
        if car_col is not None and score_col is not None:
            for _, r in df_.iterrows():
                try:
                    i = int(r[car_col]); x = float(r[score_col])
                except Exception:
                    continue
                out[i] = x
    elif "pandas.core.series" in t:
        for k, v in d.to_dict().items():
            try:
                i = int(k); x = float(v)
            except Exception:
                continue
            out[i] = x
    elif hasattr(d, "items"):
        for k, v in d.items():
            try:
                i = int(k); x = float(v)
            except Exception:
                continue
            out[i] = x
    elif isinstance(d, (list, tuple, np.ndarray)):
        arr = list(d)
        if len(arr) == n_cars and all(not isinstance(x,(list,tuple,dict)) for x in arr):
            for idx, v in enumerate(arr, start=1):
                try: out[idx] = float(v)
                except Exception: out[idx] = np.nan
        else:
            for it in arr:
                if isinstance(it,(list,tuple)) and len(it) >= 2:
                    try:
                        i = int(it[0]); x = float(it[1])
                        out[i] = x
                    except Exception:
                        continue
    for i in range(1, int(n_cars)+1):
        out.setdefault(i, np.nan)
    return out

def t_score_from_finite(values: np.ndarray, eps: float = 1e-9):
    v = values.astype(float, copy=True)
    finite = np.isfinite(v)
    k = int(finite.sum())
    if k < 2:
        return np.full_like(v, 50.0), (float("nan") if k==0 else float(v[finite][0])), 0.0, k
    mu = float(np.mean(v[finite]))
    sd = float(np.std(v[finite], ddof=0))
    if (not np.isfinite(sd)) or sd < eps:
        return np.full_like(v, 50.0), mu, 0.0, k
    T = 50.0 + 10.0 * ((v - mu) / sd)
    T[~finite] = 50.0
    return T, mu, sd, k


# â˜…ã“ã“ã«è¿½åŠ ï¼ˆForm ã®åå·®å€¤åŒ–ï¼‰
form_list = [Form[n] for n in active_cars]
form_T, mu_form, sd_form, _ = t_score_from_finite(np.array(form_list))
form_T_map = {n: float(form_T[i]) for i, n in enumerate(active_cars)}





def _format_rank_from_array(ids, arr):
    pairs = [(i, float(arr[idx])) for idx, i in enumerate(ids)]
    pairs.sort(key=lambda kv: ((1,0) if not np.isfinite(kv[1]) else (0,-kv[1]), kv[0]))
    return " ".join(str(i) for i,_ in pairs)

# ====== ã“ã“ã‹ã‚‰å‡¦ç†æœ¬ä½“ ======

# 1) æ¯é›†å›£è»Šç•ª
try:
    USED_IDS = sorted(int(i) for i in (active_cars if active_cars else range(1, n_cars+1)))
except Exception:
    USED_IDS = list(range(1, int(n_cars)+1))
M = len(USED_IDS)

# 2) SBãªã—ã®ã‚½ãƒ¼ã‚¹ï¼ˆdfå„ªå…ˆâ†’velobi_woï¼‰
score_map_from_df = coerce_score_map(globals().get("df_sorted_wo", None), n_cars)
score_map_vwo     = coerce_score_map(globals().get("velobi_wo", None),   n_cars)
SB_BASE_MAP = score_map_from_df if any(np.isfinite(list(score_map_from_df.values()))) else score_map_vwo

# 3) ã‚¹ã‚³ã‚¢é…åˆ—ï¼ˆã‚¹ã‚³ã‚¢é †è¡¨ç¤ºã¨åå·®å€¤æ¯é›†å›£ã‚’å…±ç”¨ï¼‰
xs_base_raw = np.array([SB_BASE_MAP.get(i, np.nan) for i in USED_IDS], dtype=float)

# 4) åå·®å€¤Tï¼ˆãƒ¬ãƒ¼ã‚¹å†…ï¼šå¹³å‡50ãƒ»SD10ã€NaNâ†’50ï¼‰
xs_race_t, mu_sb, sd_sb, k_finite = t_score_from_finite(xs_base_raw)




missing = ~np.isfinite(xs_base_raw)
if missing.any():
    sb_for_sort = {i: SB_BASE_MAP.get(i, -1e18) for i in USED_IDS}
    idxs = np.where(missing)[0].tolist()
    idxs.sort(key=lambda ii: (-float(sb_for_sort.get(USED_IDS[ii], -1e18)), USED_IDS[ii]))
    k = len(idxs); delta = 0.12; center = (k - 1)/2.0 if k > 1 else 0.0
    for r, ii in enumerate(idxs):
        xs_race_t[ii] = 50.0 + delta * (center - r)

# 5) dictåŒ–ãƒ»è¡¨ç¤ºç”¨
race_t = {USED_IDS[idx]: float(round(xs_race_t[idx], HEN_DEC_PLACES)) for idx in range(M)}

# === 5.5) ã‚¯ãƒ©ã‚¹åˆ¥ãƒ©ã‚¤ãƒ³åå·®å€¤ãƒœãƒ¼ãƒŠã‚¹ï¼ˆãƒ©ã‚¤ãƒ³é–“â†’ãƒ©ã‚¤ãƒ³å†…ï¼šä½Tå„ªå…ˆ 3:2:1ï¼‰ ===
# ã‚¯ãƒ©ã‚¹åˆ¥ã®ç·ãƒã‚¤ãƒ³ãƒˆï¼ˆGirlsã¯ç„¡åŠ¹ï¼‰
CLASS_LINE_POOL = {
    "ï¼³ç´š":           21.0,
    "ï¼¡ç´š":           15.0,
    "ï¼¡ç´šãƒãƒ£ãƒ¬ãƒ³ã‚¸":  9.0,
    "ã‚¬ãƒ¼ãƒ«ã‚º":        0.0,
}
pool_total = float(CLASS_LINE_POOL.get(race_class, 0.0))

def _line_rank_weights(n_lines: int) -> list[float]:
    # 2æœ¬: 3:2 / 3æœ¬: 5:4:3 / 4æœ¬ä»¥ä¸Š: 6,5,4,3,2,1...
    if n_lines <= 1: return [1.0]
    if n_lines == 2: return [3.0, 2.0]
    if n_lines == 3: return [5.0, 4.0, 3.0]
    base = [6.0, 5.0, 4.0, 3.0, 2.0, 1.0]
    if n_lines <= len(base): return base[:n_lines]
    ext = base[:]
    while len(ext) < n_lines:
        ext.append(max(1.0, ext[-1]-1.0))
    return ext[:n_lines]

def _in_line_weights(members_sorted_lowT_first: list[int]) -> dict[int, float]:
    # ãƒ©ã‚¤ãƒ³å†…ã¯ã€Œä½Tå„ªå…ˆã§ 3:2:1ã€4äººç›®ä»¥é™0ã€â†’åˆè¨ˆ1ã«æ­£è¦åŒ–
    raw = [3.0, 2.0, 1.0]
    w = {}
    for i, car in enumerate(members_sorted_lowT_first):
        w[int(car)] = (raw[i] if i < len(raw) else 0.0)
    s = sum(w.values())
    return {k: (v/s if s > 0 else 0.0) for k, v in w.items()}

_lines = list((globals().get("line_def") or {}).values())
if pool_total > 0.0 and _lines:
    # ãƒ©ã‚¤ãƒ³å¼·åº¦ï¼ãã®ãƒ©ã‚¤ãƒ³ã® race_t å¹³å‡
    line_scores = []
    for mem in _lines:
        if not mem: 
            continue
        avg_t = float(np.mean([race_t.get(int(c), 50.0) for c in mem]))
        line_scores.append((tuple(mem), avg_t))
    # å¼·ã„é †ã«ä¸¦ã¹ã¦ãƒ©ã‚¤ãƒ³é–“ãƒã‚¤ãƒ³ãƒˆé…åˆ†
    line_scores.sort(key=lambda x: (-x[1], x[0]))
    rank_w = _line_rank_weights(len(line_scores))
    sum_rank_w = float(sum(rank_w)) if rank_w else 1.0
    line_share = {}
    for (mem, _avg), wr in zip(line_scores, rank_w):
        line_share[mem] = pool_total * (float(wr) / sum_rank_w)

    # å„ãƒ©ã‚¤ãƒ³ã®é…åˆ†ã‚’ã€Œä½Tâ†’é«˜Tã€ã®é †ã« 3:2:1 ã§å‰²ã‚ŠæŒ¯ã‚Š
    bonus_map = {int(i): 0.0 for i in USED_IDS}
    for mem, share in line_share.items():
        mem = list(mem)
        mem_sorted_lowT = sorted(mem, key=lambda c: (race_t.get(int(c), 50.0), int(c)))
        w_in = _in_line_weights(mem_sorted_lowT)  # åˆè¨ˆ1
        for car in mem_sorted_lowT:
            bonus_map[int(car)] += share * w_in[int(car)]

    # åå·®å€¤ã«åŠ ç®—ï¼ˆxs_race_tãŒè¨ˆç®—æœ¬ä½“ã€‚race_tã¯è¡¨ç¤ºç”¨ã«ä¸¸ã‚ç›´ã™ï¼‰
    for idx, car in enumerate(USED_IDS):
        add = float(bonus_map.get(int(car), 0.0))
        xs_race_t[idx] = float(xs_race_t[idx]) + add
        race_t[int(car)] = float(round(xs_race_t[idx], HEN_DEC_PLACES))
# â† ã“ã®å¾Œã«æ—¢å­˜ã® race_z è¨ˆç®—ãŒç¶šã


race_z = (xs_race_t - 50.0) / 10.0

hen_df = pd.DataFrame({
    "è»Š": USED_IDS,
    "SBãªã—(æ¯é›†å›£)": [None if not np.isfinite(x) else float(x) for x in xs_base_raw],
    "åå·®å€¤T(ãƒ¬ãƒ¼ã‚¹å†…)": [race_t[i] for i in USED_IDS],
}).sort_values(["åå·®å€¤T(ãƒ¬ãƒ¼ã‚¹å†…)","è»Š"], ascending=[False, True]).reset_index(drop=True)

st.markdown("### åå·®å€¤ï¼ˆãƒ¬ãƒ¼ã‚¹å†…Tï¼å¹³å‡50ãƒ»SD10ï½œSBãªã—ã¨åŒä¸€æ¯é›†å›£ï¼‰")
st.caption(f"Î¼={mu_sb if np.isfinite(mu_sb) else 'nan'} / Ïƒ={sd_sb:.6f} / æœ‰åŠ¹ä»¶æ•°k={k_finite}")
st.dataframe(hen_df, use_container_width=True)

# 6) PLç”¨é‡ã¿ï¼ˆè³¼å…¥è¨ˆç®—ã«ä½¿ç”¨ï¼šæ—¢å­˜è¿‘ä¼¼ï¼‰
tau = 1.0
w   = np.exp(race_z * tau)
S_w = float(np.sum(w))
w_idx = {USED_IDS[idx]: float(w[idx]) for idx in range(M)}

def prob_top2_pair_pl(i: int, j: int) -> float:
    wi, wj = w_idx[i], w_idx[j]
    d_i = max(S_w - wi, EPS); d_j = max(S_w - wj, EPS)
    return (wi / S_w) * (wj / d_i) + (wj / S_w) * (wi / d_j)

def prob_top3_triple_pl(i: int, j: int, k: int) -> float:
    a, b, c = w_idx[i], w_idx[j], w_idx[k]
    total = 0.0
    for x, y, z in ((a,b,c),(a,c,b),(b,a,c),(b,c,a),(c,a,b),(c,b,a)):
        d1 = max(S_w - x, EPS)
        d2 = max(S_w - x - y, EPS)
        total += (x / S_w) * (y / d1) * (z / d2)
    return total

def prob_wide_pair_pl(i: int, j: int) -> float:
    total = 0.0
    for k in USED_IDS:
        if k == i or k == j: continue
        total += prob_top3_triple_pl(i, j, k)
    return total

# 7) å°ï¼ˆâ—ã€‡â–²ï¼‰ï¼ Tâ†“ â†’ SBãªã—â†“ â†’ è»Šç•ªâ†‘ï¼ˆÎ²ã¯é™¤å¤–ï¼‰
if "select_beta" not in globals():
    def select_beta(cars): return None
if "enforce_alpha_eligibility" not in globals():
    def enforce_alpha_eligibility(m): return m

# ===== Î²ãƒ©ãƒ™ãƒ«ä»˜ä¸ï¼ˆå˜ãªã‚‹é †ä½ãƒ©ãƒ™ãƒ«ï¼‰ =====
def assign_beta_label(result_marks: dict[str,int], used_ids: list[int], df_sorted) -> dict[str,int]:
    marks = dict(result_marks)
    # 6è»Šä»¥ä¸‹ã¯å‡ºã•ãªã„ï¼ˆé›†è¨ˆä»•æ§˜ï¼‰
    if len(used_ids) <= 6:
        return marks
    # æ—¢ã«Î²ãŒã‚ã‚Œã°ä½•ã‚‚ã—ãªã„
    if "Î²" in marks:
        return marks
    try:
        last_car = int(df_sorted.loc[len(df_sorted)-1, "è»Šç•ª"])
        if last_car not in marks.values():
            marks["Î²"] = last_car
    except Exception:
        pass
    return marks


try:
    beta_id = beta_id if ('beta_id' in globals() and beta_id is not None) else select_beta(list(USED_IDS))
except Exception:
    beta_id = None

result_marks = {}
reasons = {}

if beta_id is not None:
    result_marks["Î²"] = int(beta_id)
    reasons[beta_id] = reasons.get(beta_id, "Î²ï¼ˆæ¥ãªã„æ ï¼šé¸åˆ¥ãƒ­ã‚¸ãƒƒã‚¯ï¼‰")

sb_base = {USED_IDS[idx]: float(xs_base_raw[idx]) if np.isfinite(xs_base_raw[idx]) else float("-inf") for idx in range(M)}

def _race_t_val(i: int) -> float:
    try: return float(race_t.get(int(i), 50.0))
    except Exception: return 50.0

seed_pool = [i for i in USED_IDS if i != result_marks.get("Î²")]
order_by_T = sorted(seed_pool, key=lambda i: (-_race_t_val(i), -sb_base.get(i, float("-inf")), i))
for mk, car in zip(["â—","ã€‡","â–²"], order_by_T):
    result_marks[mk] = car

line_def     = globals().get("line_def", {}) or {}
car_to_group = globals().get("car_to_group", {}) or {}

anchor_no = result_marks.get("â—", None)
mates_sorted = []
if anchor_no is not None:
    a_gid = car_to_group.get(anchor_no, None)
    if a_gid is not None and a_gid in line_def:
        used_now = set(result_marks.values())
        mates_sorted = sorted(
            [c for c in line_def[a_gid] if c not in used_now and c != result_marks.get("Î²")],
            key=lambda x: (-sb_base.get(x, float("-inf")), x)
        )

used = set(result_marks.values())
overall_rest = [c for c in USED_IDS if c not in used]
overall_rest = sorted(overall_rest, key=lambda x: (-sb_base.get(x, float("-inf")), x))
tail_priority = mates_sorted + [c for c in overall_rest if c not in mates_sorted]

for mk in ["â–³","Ã—","Î±"]:
    if mk in result_marks: continue
    if not tail_priority: break
    no = tail_priority.pop(0)
    result_marks[mk] = no
    reasons[no] = f"{mk}ï¼ˆâ—ãƒ©ã‚¤ãƒ³å„ªå…ˆâ†’æ®‹ã‚Šã‚¹ã‚³ã‚¢é †ï¼‰"

result_marks = enforce_alpha_eligibility(result_marks)

result_marks = assign_beta_label(result_marks, USED_IDS, df_sorted_wo)


if "Î±" not in result_marks:
    used_now = set(result_marks.values())
    pool = [i for i in USED_IDS if (i not in used_now and i != beta_id)]
    if pool:
        alpha_pick = pool[-1]
        result_marks["Î±"] = alpha_pick
        reasons[alpha_pick] = reasons.get(alpha_pick, "Î±ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šç¦æ­¢æ¡ä»¶å…¨æ»…â†’æœ€å¼±ã‚’æ¡ç”¨ï¼‰")

# -*- coding: utf-8 -*-
import streamlit as st
import numpy as np
import pandas as pd
import math
from statistics import mean, pstdev
from itertools import combinations


# ===== åŸºæœ¬ãƒ‡ãƒ¼ã‚¿ =====
S_TRIFECTA_MIN = globals().get("S_TRIFECTA_MIN", 164.0)  # ä¸‰é€£å˜åŸºæº–

# ===== å¯å¤‰ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ =====
TRIO_SIG_DIV   = float(globals().get("TRIO_SIG_DIV", 3.0))     # ä¸‰é€£è¤‡ã—ãã„å€¤: Î¼ + Ïƒ/TRIO_SIG_DIV
TRIO_L3_MIN    = float(globals().get("TRIO_L3_MIN", 160.0))    # â˜…L3å€™è£œã®å›ºå®šã—ãã„å€¤ï¼ˆåå·®å€¤Såˆè¨ˆï¼‰
S_TRIFECTA_MIN = float(globals().get("S_TRIFECTA_MIN", 164.0)) # ä¸‰é€£å˜ã®åŸºæº–ï¼ˆå¾“æ¥ã©ãŠã‚Šï¼‰

from statistics import mean, pstdev
from itertools import product, combinations

# ===== ã‚¹ã‚³ã‚¢ï¼ˆåå·®å€¤Tåˆè¨ˆï¼‰ =====
S_BASE_MAP = {int(i): float(race_t.get(int(i), 50.0)) for i in USED_IDS}
def _pair_score(a, b):   return S_BASE_MAP.get(a, 0.0) + S_BASE_MAP.get(b, 0.0)
def _trio_score(a, b, c): return S_BASE_MAP.get(a, 0.0) + S_BASE_MAP.get(b, 0.0) + S_BASE_MAP.get(c, 0.0)

def _top_k_unique(seq, k):
    out, seen = [], set()
    for x in seq:
        if x in seen: continue
        seen.add(x); out.append(x)
        if len(out) >= k: break
    return out

# ---------- L1/L2ï¼ˆNã‚²ãƒ¼ãƒˆï¼‹Tã‚²ãƒ¼ãƒˆã®åˆæµï¼‰ ----------
# Nã‚²ãƒ¼ãƒˆï¼šäºŒè»Šå˜ rows_nitan ã‹ã‚‰ 1ç€/2ç€ã®é †ã«å€™è£œã‚’æŠ½å‡º
n1_list, n2_list = [], []
for k,_s in (rows_nitan if 'rows_nitan' in globals() and rows_nitan else []):
    try:
        a,b = map(int, k.split("-"))
        n1_list.append(a); n2_list.append(b)
    except Exception:
        pass
L1N = _top_k_unique(n1_list, 3)
L2N = _top_k_unique(n2_list, 4)

# Tã‚²ãƒ¼ãƒˆï¼šåå·®å€¤Tä¸Šä½ï¼ˆâ—ãƒ»ã€‡ã‚’ç¨®ã«åŠ ãˆã‚‹ï¼‰
T_sorted = sorted(USED_IDS, key=lambda i: (-S_BASE_MAP.get(i,50.0), i))
L1T_seed = [result_marks.get("â—")] if result_marks.get("â—") is not None else []
L2T_seed = [result_marks.get("ã€‡")] if result_marks.get("ã€‡") is not None else []
L1T = _top_k_unique(L1T_seed + T_sorted, 3)
L2T = _top_k_unique(L2T_seed + [i for i in T_sorted if i not in L1T], 4)

# åˆæµ
L1 = sorted(set(L1N) | set(L1T))
L2 = sorted(set(L2N) | set(L2T))

# ---------- L3ï¼ˆ3åˆ—ç›®å€™è£œï¼‰ ----------
# æ—¢å­˜ã®ä¸‰é€£å˜ rows_trifecta ãŒã‚ã‚Œã°ã€ãã®3åˆ—ç›®ã®ã¿ã‚’æ¡ç”¨
def _collect_l3_from_trifecta(rows):
    s = set()
    for k,_sv in rows:
        try:
            a,b,c = map(int, k.split("-"))
            s.add(c)
        except Exception:
            pass
    return s

trifecta_ok = bool(('rows_trifecta' in globals()) and rows_trifecta)
L3_from_tri = _collect_l3_from_trifecta(rows_trifecta) if trifecta_ok else set()

# â˜…ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šL1Ã—L2 ã¨ä»»æ„ã® c ã§ S â‰¥ TRIO_L3_MIN ã‚’æº€ãŸã™ c ã‚’æŠ½å‡ºï¼ˆé‡è¤‡æ’é™¤ï¼‰
L3_from_160 = set()
for a in L1:
    for b in L2:
        if a == b: continue
        for c in USED_IDS:
            if c in (a,b): continue
            if _trio_score(a,b,c) >= TRIO_L3_MIN:
                L3_from_160.add(int(c))

# æœ€çµ‚L3ã¯ã€Œä¸‰å˜ç”±æ¥ âˆª 160ã—ãã„å€¤ã€ã®å’Œé›†åˆ
L3 = sorted(L3_from_tri | L3_from_160)

# ---------- ãƒ•ã‚©ãƒ¼ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆå¸¸æ™‚è¡¨ç¤ºï¼‰ ----------
def _fmt_form(col): 
    return "".join(str(x) for x in col) if col else "â€”"
form_L1 = _fmt_form(L1)
form_L2 = _fmt_form(L2)
form_L3 = _fmt_form(L3)
formation_label = f"{form_L1}-{form_L2}-{form_L3}"
st.markdown(f"**ãƒ•ã‚©ãƒ¼ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³**ï¼š{formation_label}")

# ---------- ä¸‰é€£è¤‡ï¼ˆæ–°æ–¹å¼ï¼šL1Ã—L2Ã—L3 â†’ Î¼+Ïƒ/TRIO_SIG_DIVï¼‰ ----------
trios_filtered_display, cutoff_trio = [], 0.0
if L1 and L2 and L3:
    trio_keys = set()
    for a,b,c in product(L1, L2, L3):
        if len({a,b,c}) != 3: 
            continue
        trio_keys.add(tuple(sorted((a,b,c))))
    trios_from_cols = [(a,b,c,_trio_score(a,b,c)) for (a,b,c) in sorted(trio_keys)]
    if trios_from_cols:
        xs = [s for (*_,s) in trios_from_cols]
        mu, sig = mean(xs), pstdev(xs)
        cutoff_trio = mu + (sig/float(TRIO_SIG_DIV) if sig > 0 else 0.0)
        trios_filtered_display = [(a,b,c,s) for (a,b,c,s) in trios_from_cols if s >= cutoff_trio]

def _df_trio(rows, anchor_no):
    out = []
    for (a,b,c,s) in rows:
        k = [a,b,c]; k.sort()
        label = "-".join(map(str,k))
        if anchor_no in k: label += "â˜†"
        out.append({"è²·ã„ç›®": label, "åå·®å€¤S": round(s,1)})
    out.sort(key=lambda x: (-x["åå·®å€¤S"], x["è²·ã„ç›®"]))
    return pd.DataFrame(out)

# ---------- äºŒè»Šè¤‡ï¼ˆL1Ã—L2ï½œÎ¼+Ïƒ/3ï¼‰ï¼äºŒè»Šå˜ï¼ˆL1â†’L2ï½œS1â‰¥124ï¼‰ ----------
if 'hensachi_top2' not in globals():
    # é€£å¯¾åå·®å€¤ãŒæœªè¨ˆç®—ãªã‚‰ race_t ã‚’ä»£ç”¨
    hensachi_top2 = {i: float(race_t.get(i, 50.0)) for i in USED_IDS}

pairs_all_L12 = {}
for a in L1:
    for b in L2:
        if a == b: continue
        key = tuple(sorted((int(a), int(b))))
        if key in pairs_all_L12: continue
        s2 = float(hensachi_top2.get(a,50.0)) + float(hensachi_top2.get(b,50.0))
        pairs_all_L12[key] = round(s2, 1)

pairs_qn2_kept, qn2_cutoff = [], 0.0
if pairs_all_L12:
    sc = list(pairs_all_L12.values())
    mu2, sig2 = mean(sc), pstdev(sc)
    qn2_cutoff = mu2 + (sig2/3.0 if sig2 > 0 else 0.0)
    pairs_qn2_kept = [(a,b,s) for (a,b), s in pairs_all_L12.items() if s >= qn2_cutoff]
    pairs_qn2_kept.sort(key=lambda x:(-x[2], x[0], x[1]))

rows_nitan_L12 = []
if 'rows_nitan' in globals() and rows_nitan:
    for k, s1 in rows_nitan:
        try:
            a,b = map(int, k.split("-"))
        except Exception:
            continue
        if (a in L1) and (b in L2) and (a != b):
            rows_nitan_L12.append((k, float(round(s1,1))))
rows_nitan_L12.sort(key=lambda x:(-x[1], x[0]))

# ---------- ã‚»ã‚¯ã‚·ãƒ§ãƒ³å‡ºåŠ›ï¼ˆ3é€£ç³»å„ªå…ˆã€‚å‡ºã‚Œã°äºŒè»Šç³»ã¯éè¡¨ç¤ºï¼‰ ----------
has_trio = bool(trios_filtered_display)
has_tri  = bool(rows_trifecta) if trifecta_ok else False
has_qn   = bool(pairs_qn2_kept)
has_nit  = bool(rows_nitan_L12)

# ä¸‰é€£è¤‡
st.markdown(f"#### ä¸‰é€£è¤‡ï¼ˆæ–°æ–¹å¼ï½œã—ãã„å€¤ {cutoff_trio:.1f}ç‚¹ï¼‰")
st.caption(f"ãƒ•ã‚©ãƒ¼ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ï¼š{formation_label}ï¼ˆL3åŸºæº–={TRIO_L3_MIN:.1f}ï¼‰")
if has_trio:
    st.dataframe(_df_trio(trios_filtered_display, result_marks.get('â—')), use_container_width=True)
else:
    st.markdown("å¯¾è±¡å¤–")

# ä¸‰é€£å˜
if has_tri:
    st.markdown(f"#### ä¸‰é€£å˜ï¼ˆ**äºŒè»Šå˜ï¼‹ä¸‰é€£è¤‡** é€£å‹•ãƒ»Sâ‰¥{S_TRIFECTA_MIN}ï¼‰")
    st.dataframe(pd.DataFrame([{"è²·ã„ç›®": k, "å‚è€ƒS(ä¸‰é€£è¤‡S)": v} for (k,v) in rows_trifecta]),
                 use_container_width=True)
else:
    st.markdown("#### ä¸‰é€£å˜ï¼ˆç¾è¡Œæ–¹å¼ï¼‰\nå¯¾è±¡å¤–")

# äºŒè»Šç³»ã¯ã€Œä¸‰é€£è¤‡ or ä¸‰é€£å˜ã€ãŒå‡ºãŸã‚‰éè¡¨ç¤ºï¼ˆãƒã‚¤ã‚ºé˜²æ­¢ï¼‰
if not (has_trio or has_tri):
    st.markdown(f"#### äºŒè»Šè¤‡ï¼ˆL1Ã—L2ï½œã—ãã„å€¤ {qn2_cutoff:.1f}ç‚¹ï¼‰")
    st.caption(f"åŸºæº–ãƒ•ã‚©ãƒ¼ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ï¼š{form_L1} Ã— {form_L2}")
    if has_qn:
        st.dataframe(pd.DataFrame(
            [{"è²·ã„ç›®": f"{a}-{b}", "S2(é€£å¯¾åå·®å€¤åˆè¨ˆ)": s} for (a,b,s) in pairs_qn2_kept]
        ), use_container_width=True)
    else:
        st.markdown("å¯¾è±¡å¤–")

    st.markdown("â€ƒâ€ƒäºŒè»Šå˜ï¼ˆL1Ã—L2ï½œS1â‰¥124ï¼‰")
    if has_nit:
        st.dataframe(pd.DataFrame(
            [{"è²·ã„ç›®": k, "S1(å‹ç‡åå·®å€¤åˆè¨ˆ)": v} for (k,v) in rows_nitan_L12]
        ), use_container_width=True)
    else:
        st.markdown("â€ƒâ€ƒå¯¾è±¡å¤–")

# ---------- note å‡ºåŠ›ï¼ˆç”»é¢ã¨åŒã˜æ’ä»–ãƒ­ã‚¸ãƒƒã‚¯ï¼‰ ----------
def _fmt_hen_lines(ts_map: dict, ids: list[int]) -> str:
    lines = []
    for n in ids:
        v = ts_map.get(n, "â€”")
        lines.append(f"{n}: {float(v):.1f}" if isinstance(v,(int,float)) else f"{n}: â€”")
    return "\n".join(lines)

note_sections = []
note_sections.append(f"{track}{race_no}R")
note_sections.append(f"å±•é–‹è©•ä¾¡ï¼š{confidence}\n")

# æ¨å¥¨å¸¯
if   has_trio and has_tri: note_sections.append("æ¨å¥¨ã€€ä¸‰é€£è¤‡ï¼†ä¸‰é€£å˜\n")
elif has_trio:             note_sections.append("æ¨å¥¨ã€€ä¸‰é€£è¤‡\n")
elif has_tri:              note_sections.append("æ¨å¥¨ã€€ä¸‰é€£å˜\n")
elif has_qn and has_nit:   note_sections.append("æ¨å¥¨ã€€ï¼’è»Šè¤‡ï¼†äºŒè»Šå˜\n")
elif has_qn:               note_sections.append("æ¨å¥¨ã€€ï¼’è»Šè¤‡\n")
elif has_nit:              note_sections.append("æ¨å¥¨ã€€äºŒè»Šå˜\n")
else:                      note_sections.append("æ¨å¥¨ã€€ã‚±ãƒ³\n")

note_sections.append(f"{race_time}ã€€{race_class}")
note_sections.append(f"ãƒ©ã‚¤ãƒ³ã€€{'ã€€'.join([x for x in globals().get('line_inputs', []) if str(x).strip()])}")
note_sections.append(f"ã‚¹ã‚³ã‚¢é †ï¼ˆSBãªã—ï¼‰ã€€{_format_rank_from_array(USED_IDS, xs_base_raw)}")
note_sections.append(' '.join(f'{m}{result_marks[m]}' for m in ['â—','ã€‡','â–²','â–³','Ã—','Î±','Î²'] if m in result_marks))
note_sections.append("\nåå·®å€¤ï¼ˆé¢¨ãƒ»ãƒ©ã‚¤ãƒ³è¾¼ã¿ï¼‰")
note_sections.append(_fmt_hen_lines(race_t, USED_IDS))
note_sections.append(f"\nãƒ•ã‚©ãƒ¼ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ï¼š{formation_label}")

# ä¸‰é€£è¤‡ æ˜ç´°
if has_trio:
    triolist = "\n".join([
        f"{a}-{b}-{c}{('â˜†' if result_marks.get('â—') in (a,b,c) else '')}ï¼ˆS={s:.1f}ï¼‰"
        for (a,b,c,s) in sorted(trios_filtered_display, key=lambda x:(-x[3], x[0], x[1], x[2]))
    ])
    note_sections.append(f"\nä¸‰é€£è¤‡ï¼ˆæ–°æ–¹å¼ï½œã—ãã„å€¤ {cutoff_trio:.1f}ç‚¹ï¼L3åŸºæº– {TRIO_L3_MIN:.1f}ï¼‰\n{triolist}")
else:
    note_sections.append("\nä¸‰é€£è¤‡ï¼ˆæ–°æ–¹å¼ï¼‰\nå¯¾è±¡å¤–")

# ä¸‰é€£å˜ æ˜ç´°
if has_tri:
    trifectalist = "\n".join([f"{k}ï¼ˆå‚è€ƒS={v:.1f}ï¼‰" for (k,v) in rows_trifecta])
    note_sections.append(f"\nä¸‰é€£å˜ï¼ˆç¾è¡Œæ–¹å¼ï¼‰\n{trifectalist}")
else:
    note_sections.append("\nä¸‰é€£å˜ï¼ˆç¾è¡Œæ–¹å¼ï¼‰\nå¯¾è±¡å¤–")

# äºŒè»Šç³»ï¼ˆæ’ä»–ï¼‰
if not (has_trio or has_tri):
    if has_qn:
        qnlist = "\n".join([f"{a}-{b}ï¼ˆS2={s:.1f}ï¼‰" for (a,b,s) in pairs_qn2_kept])
        note_sections.append(f"\näºŒè»Šè¤‡ï¼ˆL1Ã—L2ï½œã—ãã„å€¤ {qn2_cutoff:.1f}ç‚¹ï¼‰\n{qnlist}")
    else:
        note_sections.append("\näºŒè»Šè¤‡ï¼ˆL1Ã—L2ï¼‰\nå¯¾è±¡å¤–")
    if has_nit:
        nitanlist = "\n".join([f"{k}ï¼ˆS1={v:.1f}ï¼‰" for (k,v) in rows_nitan_L12])
        note_sections.append(f"\näºŒè»Šå˜ï¼ˆL1Ã—L2ï½œS1â‰¥124ï¼‰\n{nitanlist}")
    else:
        note_sections.append("\näºŒè»Šå˜ï¼ˆL1Ã—L2ï¼‰\nå¯¾è±¡å¤–")

note_text = "\n".join(note_sections)
st.markdown("### ğŸ“‹ noteç”¨ï¼ˆã‚³ãƒ”ãƒ¼ã‚¨ãƒªã‚¢ï¼‰")
st.text_area("ã“ã“ã‚’é¸æŠã—ã¦ã‚³ãƒ”ãƒ¼", note_text, height=560)

# ===== ãƒ‡ãƒãƒƒã‚°è¡¨ç¤ºï¼ˆå¿…è¦ãªã‚‰ï¼‰ =====
st.caption(
    f"[DBG] L1={L1} / L2={L2} / L3={L3} | "
    f"triout={len(trios_filtered_display)} (cut={cutoff_trio:.1f}) / "
    f"trifecta={'Yes' if has_tri else 'No'} / "
    f"QN_pairs={len(pairs_qn2_kept)} (cut={qn2_cutoff:.1f})"
)
