# -*- coding: utf-8 -*-
import streamlit as st
import pandas as pd
import numpy as np
import unicodedata, re
import math, random, json, itertools

# ==============================
# ãƒšãƒ¼ã‚¸è¨­å®š
# ==============================
st.set_page_config(page_title="ãƒ´ã‚§ãƒ­ãƒ“ï¼šç´šåˆ¥Ã—æ—¥ç¨‹ãƒ€ã‚¤ãƒŠãƒŸã‚¯ã‚¹ï¼ˆ5ã€œ9è»Šãƒ»è²·ã„ç›®ä»˜ãï¼‰", layout="wide")

# ==============================
# å®šæ•°
# ==============================
WIND_COEFF = {
    "å·¦ä¸Š": -0.03, "ä¸Š": -0.05, "å³ä¸Š": -0.035,
    "å·¦": +0.05,  "å³": -0.05,
    "å·¦ä¸‹": +0.035, "ä¸‹": +0.05, "å³ä¸‹": +0.035,
    "ç„¡é¢¨": 0.0
}
BASE_BY_KAKU = {"é€ƒ":1.58, "æ²":1.65, "å·®":1.79, "ãƒ":1.45}

KEIRIN_DATA = {
    "å‡½é¤¨":{"bank_angle":30.6,"straight_length":51.3,"bank_length":400},
    "é’æ£®":{"bank_angle":32.3,"straight_length":58.9,"bank_length":400},
    "ã„ã‚ãå¹³":{"bank_angle":32.9,"straight_length":62.7,"bank_length":400},
    "å¼¥å½¦":{"bank_angle":32.4,"straight_length":63.1,"bank_length":400},
    "å‰æ©‹":{"bank_angle":36.0,"straight_length":46.7,"bank_length":335},
    "å–æ‰‹":{"bank_angle":31.5,"straight_length":54.8,"bank_length":400},
    "å®‡éƒ½å®®":{"bank_angle":25.8,"straight_length":63.3,"bank_length":500},
    "å¤§å®®":{"bank_angle":26.3,"straight_length":66.7,"bank_length":500},
    "è¥¿æ­¦åœ’":{"bank_angle":29.4,"straight_length":47.6,"bank_length":400},
    "äº¬ç‹é–£":{"bank_angle":32.2,"straight_length":51.5,"bank_length":400},
    "ç«‹å·":{"bank_angle":31.2,"straight_length":58.0,"bank_length":400},
    "æ¾æˆ¸":{"bank_angle":29.8,"straight_length":38.2,"bank_length":333},
    "å·å´":{"bank_angle":32.2,"straight_length":58.0,"bank_length":400},
    "å¹³å¡š":{"bank_angle":31.5,"straight_length":54.2,"bank_length":400},
    "å°ç”°åŸ":{"bank_angle":35.6,"straight_length":36.1,"bank_length":333},
    "ä¼Šæ±":{"bank_angle":34.7,"straight_length":46.6,"bank_length":333},
    "é™å²¡":{"bank_angle":30.7,"straight_length":56.4,"bank_length":400},
    "åå¤å±‹":{"bank_angle":34.0,"straight_length":58.8,"bank_length":400},
    "å²é˜œ":{"bank_angle":32.3,"straight_length":59.3,"bank_length":400},
    "å¤§å£":{"bank_angle":30.6,"straight_length":56.0,"bank_length":400},
    "è±Šæ©‹":{"bank_angle":33.8,"straight_length":60.3,"bank_length":400},
    "å¯Œå±±":{"bank_angle":33.7,"straight_length":43.0,"bank_length":333},
    "æ¾å‚":{"bank_angle":34.4,"straight_length":61.5,"bank_length":400},
    "å››æ—¥å¸‚":{"bank_angle":32.3,"straight_length":62.4,"bank_length":400},
    "ç¦äº•":{"bank_angle":31.5,"straight_length":52.8,"bank_length":400},
    "å¥ˆè‰¯":{"bank_angle":33.4,"straight_length":38.0,"bank_length":333},
    "å‘æ—¥ç”º":{"bank_angle":30.5,"straight_length":47.3,"bank_length":400},
    "å’Œæ­Œå±±":{"bank_angle":32.3,"straight_length":59.9,"bank_length":400},
    "å²¸å’Œç”°":{"bank_angle":30.9,"straight_length":56.7,"bank_length":400},
    "ç‰é‡":{"bank_angle":30.6,"straight_length":47.9,"bank_length":400},
    "åºƒå³¶":{"bank_angle":30.8,"straight_length":57.9,"bank_length":400},
    "é˜²åºœ":{"bank_angle":34.7,"straight_length":42.5,"bank_length":333},
    "é«˜æ¾":{"bank_angle":33.3,"straight_length":54.8,"bank_length":400},
    "å°æ¾å³¶":{"bank_angle":29.8,"straight_length":55.5,"bank_length":400},
    "é«˜çŸ¥":{"bank_angle":24.5,"straight_length":52.0,"bank_length":500},
    "æ¾å±±":{"bank_angle":34.0,"straight_length":58.6,"bank_length":400},
    "å°å€‰":{"bank_angle":34.0,"straight_length":56.9,"bank_length":400},
    "ä¹…ç•™ç±³":{"bank_angle":31.5,"straight_length":50.7,"bank_length":400},
    "æ­¦é›„":{"bank_angle":32.0,"straight_length":64.4,"bank_length":400},
    "ä½ä¸–ä¿":{"bank_angle":31.5,"straight_length":40.2,"bank_length":400},
    "åˆ¥åºœ":{"bank_angle":33.7,"straight_length":59.9,"bank_length":400},
    "ç†Šæœ¬":{"bank_angle":34.3,"straight_length":60.3,"bank_length":400},
    "æ‰‹å…¥åŠ›":{"bank_angle":30.0,"straight_length":52.0,"bank_length":400},
}

# ç›´è¿‘é›†è¨ˆï¼šå°åˆ¥ã®å®Ÿæ¸¬ç‡ï¼ˆ%â†’å°æ•°ï¼‰
RANK_STATS = {
    "â—": {"p1": 0.200, "pTop2": 0.480, "pTop3": 0.610},
    "ã€‡": {"p1": 0.200, "pTop2": 0.390, "pTop3": 0.470},
    "â–²": {"p1": 0.100, "pTop2": 0.260, "pTop3": 0.430},
    "â–³": {"p1": 0.130, "pTop2": 0.240, "pTop3": 0.400},
    "Ã—": {"p1": 0.190, "pTop2": 0.240, "pTop3": 0.410},
    "Î±": {"p1": 0.133, "pTop2": 0.184, "pTop3": 0.347},
    "Î²": {"p1": 0.108, "pTop2": 0.269, "pTop3": 0.409},
}
RANK_FALLBACK_MARK = "Î±"

# æœŸå¾…å€¤ãƒ«ãƒ¼ãƒ«ï¼ˆå›ºå®šï¼‰
P_FLOOR = {"sanpuku": 0.06, "nifuku": 0.12, "wide": 0.25, "nitan": 0.07, "santan": 0.03}
E_MIN, E_MAX = 0.10, 0.60

# --- KO(å‹ã¡ä¸ŠãŒã‚Š) ä¿‚æ•°ï¼ˆç”·å­ã®ã¿æœ‰åŠ¹ï¼ã‚¬ãƒ¼ãƒ«ã‚ºã¯ç„¡åŠ¹åŒ–ï¼‰ ---
KO_GIRLS_SCALE = 0.0               # ã‚¬ãƒ¼ãƒ«ã‚ºã¯0.0=ç„¡åŠ¹
KO_HEADCOUNT_SCALE = {5:0.6, 6:0.8, 7:1.0, 8:1.0, 9:1.0}
KO_GAP_DELTA = 0.010               # åŒãƒ©ã‚¤ãƒ³é€£çµã®â€œéš™é–“â€é–¾å€¤
KO_STEP_SIGMA = 0.4                # KOãƒ©ãƒ³ã‚¯ã‚’ã‚¹ã‚³ã‚¢ã«å†™ã™ã¨ãã®æ®µå·®å¹…(Ïƒå€ç‡)

# === â—ãƒ©ã‚¤ãƒ³æ ¼ä¸Šã’ï¼ˆAæ–¹å¼ï¼šã‚¹ã‚³ã‚¢åŠ ç‚¹ï¼‰ ==============================
LINE_BONUS_ON_TENKAI = {"å„ªä½"}   # å±•é–‹ãŒã“ã®é›†åˆã®ã¨ãã ã‘ç™ºç«
LINE_BONUS = {"second": 0.08, "thirdplus": 0.04}  # å½¹å‰²åˆ¥ãƒœãƒ¼ãƒŠã‚¹ï¼ˆç•ªæ‰‹/ä¸‰ç•ªæ‰‹ï¼‰
LINE_BONUS_CAP = 0.10

# === ï¼ˆä»»æ„ï¼‰ç¢ºç‡ä¹—æ•°ï¼ˆBæ–¹å¼ï¼šãƒ‡ãƒ•ã‚©ãƒ«ãƒˆç„¡åŠ¹=0.0ï¼‰ ===================
PROB_U = {"second": 0.00, "thirdplus": 0.00}

# ==============================
# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
# ==============================
def clamp(x,a,b): 
    return max(a, min(b, x))

def zscore_list(arr):
    arr = np.array(arr, dtype=float)
    m, s = float(np.mean(arr)), float(np.std(arr))
    return np.zeros_like(arr) if s==0 else (arr-m)/s

def zscore_val(x, xs):
    xs = np.array(xs, dtype=float)
    m, s = float(np.mean(xs)), float(np.std(xs))
    return 0.0 if s==0 else (float(x)-m)/s

def extract_car_list(s, nmax):
    s = str(s or "").strip()
    return [int(c) for c in s if c.isdigit() and 1 <= int(c) <= nmax]

def build_line_maps(lines):
    labels = "ABCDEFG"
    line_def = {labels[i]: lst for i,lst in enumerate(lines) if lst}
    car_to_group = {c:g for g,mem in line_def.items() for c in mem}
    return line_def, car_to_group

def role_in_line(car, line_def):
    for g, mem in line_def.items():
        if car in mem:
            if len(mem)==1: 
                return 'single'
            idx = mem.index(car)
            return ['head','second','thirdplus'][idx] if idx<3 else 'thirdplus'
    return 'single'

def pos_coeff(role, line_factor):
    base = {'head':1.0,'second':0.7,'thirdplus':0.5,'single':0.9}.get(role,0.9)
    return base * line_factor

def tenscore_correction(tenscores):
    n = len(tenscores)
    if n<=2: return [0.0]*n
    df = pd.DataFrame({"å¾—ç‚¹":tenscores})
    df["é †ä½"] = df["å¾—ç‚¹"].rank(ascending=False, method="min").astype(int)
    hi = min(n,8)
    baseline = df[df["é †ä½"].between(2,hi)]["å¾—ç‚¹"].mean()
    def corr(row): 
        return round(abs(baseline-row["å¾—ç‚¹"])*0.03, 3) if row["é †ä½"] in [2,3,4] else 0.0
    return df.apply(corr, axis=1).tolist()

def wind_adjust(wind_dir, wind_speed, role, prof_escape):
    if wind_dir=="ç„¡é¢¨" or wind_speed==0: 
        return 0.0
    wd = WIND_COEFF.get(wind_dir,0.0)
    pos_multi = {'head':0.32,'second':0.30,'thirdplus':0.25,'single':0.30}.get(role,0.30)
    coeff = 0.4 + 0.6*prof_escape
    val = wind_speed * wd * pos_multi * coeff
    return round(clamp(val, -0.05, 0.05), 3)

def bank_character_bonus(bank_angle, straight_length, prof_escape, prof_sashi):
    straight_factor = (float(straight_length)-40.0)/10.0
    angle_factor = (float(bank_angle)-25.0)/5.0
    total = clamp(-0.1*straight_factor + 0.1*angle_factor, -0.05, 0.05)
    return round(total*prof_escape - 0.5*total*prof_sashi, 3)

def bank_length_adjust(bank_length, prof_oikomi):
    delta = clamp((float(bank_length)-411.0)/100.0, -0.05, 0.05)
    return round(delta*prof_oikomi, 3)

def compute_lineSB_bonus(line_def, S, B, line_factor=1.0, exclude=None, cap=0.06, enable=True):
    if not enable or not line_def:
        return {g:0.0 for g in line_def.keys()} if line_def else {}, {}
    w_pos_base = {'head':1.0,'second':0.4,'thirdplus':0.2,'single':0.7}
    Sg, Bg = {}, {}
    for g, mem in line_def.items():
        s=b=0.0
        for car in mem:
            if exclude is not None and car==exclude: 
                continue
            w = w_pos_base[role_in_line(car, line_def)] * line_factor
            s += w*float(S.get(car,0)); b += w*float(B.get(car,0))
        Sg[g]=s; Bg[g]=b
    raw={}
    for g in line_def.keys():
        s, b = Sg[g], Bg[g]
        ratioS = s/(s+b+1e-6)
        raw[g] = (0.6*b + 0.4*s) * (0.6 + 0.4*ratioS)
    zz = zscore_list(list(raw.values())) if raw else []
    bonus={g: clamp(0.02*float(zz[i]), -cap, cap) for i,g in enumerate(raw.keys())}
    return bonus, raw

def input_float_text(label: str, key: str, placeholder: str = "") -> float | None:
    s = st.text_input(label, value=st.session_state.get(key, ""), key=key, placeholder=placeholder)
    ss = unicodedata.normalize("NFKC", str(s)).replace(",", "").strip()
    if ss == "": 
        return None
    if not re.fullmatch(r"[+-]?\d+(\.\d+)?", ss):
        st.warning(f"{label} ã¯æ•°å€¤ã§å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆå…¥åŠ›å€¤: {s}ï¼‰")
        return None
    return float(ss)

# --- KOãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ï¼ˆãƒ©ã‚¤ãƒ³å¯¾ãƒ©ã‚¤ãƒ³ã®å‹ã¡ä¸ŠãŒã‚Šã‚·ãƒ¼ãƒ‰ï¼‰ ---
def _role_of(car, mem):
    if len(mem)==1: return 'single'
    i = mem.index(car)
    return ['head','second','thirdplus'][i] if i<3 else 'thirdplus'

def _line_strength_raw(line_def, S, B, line_factor=1.0):
    if not line_def: return {}
    w_pos = {'head':1.0,'second':0.4,'thirdplus':0.2,'single':0.7}
    raw={}
    for g, mem in line_def.items():
        s=b=0.0
        for c in mem:
            w = w_pos[_role_of(c, mem)] * line_factor
            s += w*float(S.get(c,0)); b += w*float(B.get(c,0))
        ratioS = s/(s+b+1e-6)
        raw[g] = (0.6*b + 0.4*s) * (0.6 + 0.4*ratioS)
    return raw

def _top2_lines(line_def, S, B, line_factor=1.0):
    raw = _line_strength_raw(line_def, S, B, line_factor)
    order = sorted(raw.keys(), key=lambda g: raw[g], reverse=True)
    return (order[0], order[1]) if len(order)>=2 else (order[0], None) if order else (None, None)

def _extract_role_car(line_def, gid, role_name):
    if gid is None or gid not in line_def: return None
    mem = line_def[gid]
    if role_name=='head':    return mem[0] if len(mem)>=1 else None
    if role_name=='second':  return mem[1] if len(mem)>=2 else None
    return None  # third+ ã¯ KO ã® others ãƒ—ãƒ¼ãƒ«ã¸

def _ko_order(v_base_map, line_def, S, B, line_factor=1.0, gap_delta=0.010):
    cars = list(v_base_map.keys())
    if not line_def or len(line_def)<1:
        return [c for c,_ in sorted(v_base_map.items(), key=lambda x:x[1], reverse=True)]

    g1, g2 = _top2_lines(line_def, S, B, line_factor)
    head1 = _extract_role_car(line_def, g1, 'head')
    head2 = _extract_role_car(line_def, g2, 'head')
    sec1  = _extract_role_car(line_def, g1, 'second')
    sec2  = _extract_role_car(line_def, g2, 'second')

    others=[]
    if g1:
        mem = line_def[g1]
        if len(mem)>=3: others += mem[2:]
    if g2:
        mem = line_def[g2]
        if len(mem)>=3: others += mem[2:]
    for g, mem in line_def.items():
        if g not in {g1,g2}:
            others += mem

    order = []
    head_pair = [x for x in [head1, head2] if x is not None]
    order += sorted(head_pair, key=lambda c: v_base_map.get(c, -1e9), reverse=True)
    sec_pair = [x for x in [sec1, sec2] if x is not None]
    order += sorted(sec_pair, key=lambda c: v_base_map.get(c, -1e9), reverse=True)

    others = list(dict.fromkeys([c for c in others if c is not None]))
    others_sorted = sorted(others, key=lambda c: v_base_map.get(c, -1e9), reverse=True)
    order += [c for c in others_sorted if c not in order]

    for c in cars:
        if c not in order:
            order.append(c)

    def _same_group(a,b):
        if a is None or b is None: return False
        ga = next((g for g,mem in line_def.items() if a in mem), None)
        gb = next((g for g,mem in line_def.items() if b in mem), None)
        return ga is not None and ga==gb

    i=0
    while i < len(order)-2:
        a, b, c = order[i], order[i+1], order[i+2]
        if _same_group(a, b):
            vx = v_base_map.get(b,0.0) - v_base_map.get(c,0.0)
            if vx >= -gap_delta:
                order.pop(i+2)
                order.insert(i+1, b)
        i += 1

    return order

# --- ãƒ˜ãƒ«ãƒ‘ãƒ¼ï¼šã‚ªãƒƒã‚ºå¸¯ ---
def _zone_from_p(p: float):
    needed = 1.0 / max(p, 1e-12)
    return needed, needed*(1.0+E_MIN), needed*(1.0+E_MAX)

def _format_line_zone(name: str, bet_type: str, p: float) -> str | None:
    floor = P_FLOOR[bet_type]
    if p < floor:
        return None
    _, low, high = _zone_from_p(p)
    return f"{name}ï¼š{low:.1f}ã€œ{high:.1f}å€ãªã‚‰è²·ã„"

# --- ä¸¦ã¹æ›¿ãˆã‚­ãƒ¼ï¼ˆçµ±ä¸€ç‰ˆï¼‰ ---
def _sort_key_by_numbers(name: str) -> list[int]:
    return list(map(int, re.findall(r"\d+", str(name))))

# === â—ãƒ©ã‚¤ãƒ³æ ¼ä¸Šã’ã®ä¸­æ ¸ ===
def apply_anchor_line_bonus(score_raw: dict[int,float],
                            line_of: dict[int,int],
                            role_map: dict[int,str],
                            anchor: int,
                            tenkai: str) -> dict[int,float]:
    a_line = line_of.get(anchor, None)
    is_on = (tenkai in LINE_BONUS_ON_TENKAI) and (a_line is not None)
    score_adj: dict[int,float] = {}
    for i, s in score_raw.items():
        bonus = 0.0
        if is_on and line_of.get(i) == a_line and i != anchor:
            role = role_map.get(i, "single")
            bonus = min(max(0.0, LINE_BONUS.get(role, 0.0)), LINE_BONUS_CAP)
        score_adj[i] = s + bonus
    return score_adj

def format_rank_all(score_map: dict[int,float], P_floor_val: float | None = None) -> str:
    order = sorted(score_map.keys(), key=lambda k: (-score_map[k], k))
    rows = []
    for i in order:
        if P_floor_val is None:
            rows.append(f"{i}")
        else:
            rows.append(f"{i}" if score_map[i] >= P_floor_val else f"{i}(Pæœªæº€)")
    return " ".join(rows)

# ==============================
# ã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼šé–‹å‚¬æƒ…å ± / ãƒãƒ³ã‚¯ãƒ»é¢¨ãƒ»é ­æ•°
# ==============================
st.sidebar.header("é–‹å‚¬æƒ…å ± / ãƒãƒ³ã‚¯ãƒ»é¢¨ãƒ»é ­æ•°")
n_cars = st.sidebar.selectbox("å‡ºèµ°æ•°ï¼ˆ5ã€œ9ï¼‰", [5,6,7,8,9], index=2)

track_names = list(KEIRIN_DATA.keys())
track = st.sidebar.selectbox("ç«¶è¼ªå ´ï¼ˆãƒ—ãƒªã‚»ãƒƒãƒˆï¼‰", track_names, index=track_names.index("å·å´") if "å·å´" in track_names else 0)
info = KEIRIN_DATA[track]

wind_dir = st.sidebar.selectbox("é¢¨å‘", ["ç„¡é¢¨","å·¦ä¸Š","ä¸Š","å³ä¸Š","å·¦","å³","å·¦ä¸‹","ä¸‹","å³ä¸‹"], 0)
wind_speed = st.sidebar.number_input("é¢¨é€Ÿ(m/s)", 0.0, 30.0, 3.0, 0.1)
straight_length = st.sidebar.number_input("ã¿ãªã—ç›´ç·š(m)", 30.0, 80.0, float(info["straight_length"]), 0.1)
bank_angle = st.sidebar.number_input("ãƒãƒ³ã‚¯è§’(Â°)", 20.0, 45.0, float(info["bank_angle"]), 0.1)
bank_length = st.sidebar.number_input("å‘¨é•·(m)", 300.0, 500.0, float(info["bank_length"]), 0.1)

base_laps = st.sidebar.number_input("å‘¨å›ï¼ˆé€šå¸¸4ï¼‰", 1, 10, 4, 1)
day_label = st.sidebar.selectbox("é–‹å‚¬æ—¥", ["åˆæ—¥","2æ—¥ç›®","æœ€çµ‚æ—¥"], 0)
eff_laps = int(base_laps) + {"åˆæ—¥":1,"2æ—¥ç›®":2,"æœ€çµ‚æ—¥":3}[day_label]

race_time = st.sidebar.selectbox("é–‹å‚¬åŒºåˆ†", ["ãƒ¢ãƒ¼ãƒ‹ãƒ³ã‚°","ãƒ‡ã‚¤","ãƒŠã‚¤ã‚¿ãƒ¼","ãƒŸãƒƒãƒ‰ãƒŠã‚¤ãƒˆ"], 1)
race_class = st.sidebar.selectbox("ç´šåˆ¥", ["ï¼³ç´š","ï¼¡ç´š","ï¼¡ç´šãƒãƒ£ãƒ¬ãƒ³ã‚¸","ã‚¬ãƒ¼ãƒ«ã‚º"], 0)

angles = [KEIRIN_DATA[k]["bank_angle"] for k in KEIRIN_DATA]
straights = [KEIRIN_DATA[k]["straight_length"] for k in KEIRIN_DATA]
lengths = [KEIRIN_DATA[k]["bank_length"] for k in KEIRIN_DATA]
angle_z = zscore_val(bank_angle, angles)
straight_z = zscore_val(straight_length, straights)
length_z = zscore_val(bank_length, lengths)
style_raw = clamp(0.50*angle_z - 0.35*straight_z - 0.30*length_z, -1.0, +1.0)

override = st.sidebar.slider("ä¼šå ´ãƒã‚¤ã‚¢ã‚¹è£œæ­£ï¼ˆâˆ’2å·®ã— â†â†’ +2å…ˆè¡Œï¼‰", -2.0, 2.0, 0.0, 0.1)
style = clamp(style_raw + 0.25*override, -1.0, +1.0)

CLASS_FACTORS = {
    "ï¼³ç´š":           {"spread":1.00, "line":1.00},
    "ï¼¡ç´š":           {"spread":0.90, "line":0.85},
    "ï¼¡ç´šãƒãƒ£ãƒ¬ãƒ³ã‚¸": {"spread":0.80, "line":0.70},
    "ã‚¬ãƒ¼ãƒ«ã‚º":       {"spread":0.85, "line":1.00},
}
cf = CLASS_FACTORS[race_class]

DAY_FACTOR = {"åˆæ—¥":1.00, "2æ—¥ç›®":0.60, "æœ€çµ‚æ—¥":0.85}
day_factor = DAY_FACTOR[day_label]

cap_base = clamp(0.06 + 0.02*style, 0.04, 0.08)
line_factor_eff = cf["line"] * day_factor
cap_SB_eff = cap_base * day_factor
if race_time == "ãƒŸãƒƒãƒ‰ãƒŠã‚¤ãƒˆ":
    line_factor_eff *= 0.95
    cap_SB_eff *= 0.95

line_sb_enable = (race_class != "ã‚¬ãƒ¼ãƒ«ã‚º")

st.sidebar.caption(
    f"ä¼šå ´ã‚¹ã‚¿ã‚¤ãƒ«: {style:+.2f}ï¼ˆraw {style_raw:+.2f}ï¼‰ / "
    f"ç´šåˆ¥: spread={cf['spread']:.2f}, line={cf['line']:.2f} / "
    f"æ—¥ç¨‹ä¿‚æ•°(line)={day_factor:.2f} â†’ lineä¿‚æ•°={line_factor_eff:.2f}, SBcapÂ±{cap_SB_eff:.2f}"
)

# ==============================
# ãƒ¡ã‚¤ãƒ³
# ==============================
st.title("â­ ãƒ´ã‚§ãƒ­ãƒ“ï¼ˆç´šåˆ¥Ã—æ—¥ç¨‹ãƒ€ã‚¤ãƒŠãƒŸã‚¯ã‚¹ / 5ã€œ9è»Šãƒ»è²·ã„ç›®ä»˜ãï¼‰â­")

# ãƒ¬ãƒ¼ã‚¹ç•ªå·
st.subheader("ãƒ¬ãƒ¼ã‚¹ç•ªå·ï¼ˆç›´å‰ã«ã‚µã‚¯ãƒƒã¨å¤‰æ›´ï¼‰")
if "race_no_main" not in st.session_state:
    st.session_state["race_no_main"] = 1
c1, c2, c3 = st.columns([6,2,2])
with c1:
    race_no_input = st.number_input("R", min_value=1, max_value=12, step=1,
                                    value=int(st.session_state["race_no_main"]),
                                    key="race_no_input")
with c2:
    prev_clicked = st.button("â—€ å‰ã®R", use_container_width=True)
with c3:
    next_clicked = st.button("æ¬¡ã®R â–¶", use_container_width=True)
if prev_clicked:
    st.session_state["race_no_main"] = max(1, int(race_no_input) - 1); st.rerun()
elif next_clicked:
    st.session_state["race_no_main"] = min(12, int(race_no_input) + 1); st.rerun()
else:
    st.session_state["race_no_main"] = int(race_no_input)
race_no = int(st.session_state["race_no_main"])

# ãƒ©ã‚¤ãƒ³å…¥åŠ›
st.subheader("ãƒ©ã‚¤ãƒ³æ§‹æˆï¼ˆæœ€å¤§7ï¼šå˜é¨ã‚‚1ãƒ©ã‚¤ãƒ³ï¼‰")
line_inputs = [
    st.text_input("ãƒ©ã‚¤ãƒ³1ï¼ˆä¾‹ï¼š317ï¼‰", key="line_1", max_chars=9),
    st.text_input("ãƒ©ã‚¤ãƒ³2ï¼ˆä¾‹ï¼š6ï¼‰", key="line_2", max_chars=9),
    st.text_input("ãƒ©ã‚¤ãƒ³3ï¼ˆä¾‹ï¼š425ï¼‰", key="line_3", max_chars=9),
    st.text_input("ãƒ©ã‚¤ãƒ³4ï¼ˆä»»æ„ï¼‰", key="line_4", max_chars=9),
    st.text_input("ãƒ©ã‚¤ãƒ³5ï¼ˆä»»æ„ï¼‰", key="line_5", max_chars=9),
    st.text_input("ãƒ©ã‚¤ãƒ³6ï¼ˆä»»æ„ï¼‰", key="line_6", max_chars=9),
    st.text_input("ãƒ©ã‚¤ãƒ³7ï¼ˆä»»æ„ï¼‰", key="line_7", max_chars=9),
]
lines = [extract_car_list(x, n_cars) for x in line_inputs if str(x).strip()]
line_def, car_to_group = build_line_maps(lines)
active_cars = sorted({c for lst in lines for c in lst}) if lines else list(range(1, n_cars+1))

# å€‹äººãƒ‡ãƒ¼ã‚¿
st.subheader("å€‹äººãƒ‡ãƒ¼ã‚¿ï¼ˆç›´è¿‘4ã‹æœˆï¼šå›æ•°ï¼‰")
cols = st.columns(n_cars)
ratings, S, B = {}, {}, {}
k_esc, k_mak, k_sashi, k_mark = {}, {}, {}, {}
x1, x2, x3, x_out = {}, {}, {}, {}

for i, no in enumerate(active_cars):
    with cols[i]:
        st.markdown(f"**{no}ç•ª**")
        ratings[no] = input_float_text("å¾—ç‚¹ï¼ˆç©ºæ¬„å¯ï¼‰", key=f"pt_{no}", placeholder="ä¾‹: 55.0")
        S[no] = st.number_input("S", 0, 99, 0, key=f"s_{no}")
        B[no] = st.number_input("B", 0, 99, 0, key=f"b_{no}")
        k_esc[no]   = st.number_input("é€ƒ", 0, 99, 0, key=f"ke_{no}")
        k_mak[no]   = st.number_input("æ²", 0, 99, 0, key=f"km_{no}")
        k_sashi[no] = st.number_input("å·®", 0, 99, 0, key=f"ks_{no}")
        k_mark[no]  = st.number_input("ãƒ", 0, 99, 0, key=f"kk_{no}")
        x1[no]  = st.number_input("1ç€", 0, 99, 0, key=f"x1_{no}")
        x2[no]  = st.number_input("2ç€", 0, 99, 0, key=f"x2_{no}")
        x3[no]  = st.number_input("3ç€", 0, 99, 0, key=f"x3_{no}")
        x_out[no]= st.number_input("ç€å¤–", 0, 99, 0, key=f"xo_{no}")

ratings_val = {no: (ratings[no] if ratings[no] is not None else 55.0) for no in active_cars}

# 1ç€ãƒ»2ç€ã®ç¸®ç´„ï¼ˆç´šåˆ¥Ã—ä¼šå ´ã®äº‹å‰åˆ†å¸ƒã‚’æ··ãœã‚‹ï¼‰
def prior_by_class(cls, style_adj):
    if "ã‚¬ãƒ¼ãƒ«" in cls: p1,p2 = 0.18,0.24
    elif "ï¼³ç´š" in cls: p1,p2 = 0.22,0.26
    elif "ãƒãƒ£ãƒ¬ãƒ³ã‚¸" in cls: p1,p2 = 0.18,0.22
    else: p1,p2 = 0.20,0.25
    p1 += 0.010*style_adj; p2 -= 0.005*style_adj
    return clamp(p1,0.05,0.60), clamp(p2,0.05,0.60)

def n0_by_n(n):
    if n<=6: return 12
    if n<=14: return 8
    if n<=29: return 5
    return 3

p1_eff, p2_eff = {}, {}
for no in active_cars:
    n = x1[no]+x2[no]+x3[no]+x_out[no]
    p1_prior, p2_prior = prior_by_class(race_class, style)
    n0 = n0_by_n(n)
    if n==0:
        p1_eff[no], p2_eff[no] = p1_prior, p2_prior
    else:
        p1_eff[no] = clamp((x1[no] + n0*p1_prior)/(n+n0), 0.0, 0.40)
        p2_eff[no] = clamp((x2[no] + n0*p2_prior)/(n+n0), 0.0, 0.50)

Form = {no: 0.7*p1_eff[no] + 0.3*p2_eff[no] for no in active_cars}

# è„šè³ªãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ï¼ˆä¼šå ´é©æ€§ï¼‰
prof_base, prof_escape, prof_sashi, prof_oikomi = {}, {}, {}, {}
for no in active_cars:
    tot = k_esc[no]+k_mak[no]+k_sashi[no]+k_mark[no]
    if tot==0: esc=mak=sashi=mark = 0.25
    else:
        esc=k_esc[no]/tot; mak=k_mak[no]/tot; sashi=k_sashi[no]/tot; mark=k_mark[no]/tot
    prof_escape[no]=esc; prof_sashi[no]=sashi; prof_oikomi[no]=mark
    base = esc*BASE_BY_KAKU["é€ƒ"] + mak*BASE_BY_KAKU["æ²"] + sashi*BASE_BY_KAKU["å·®"] + mark*BASE_BY_KAKU["ãƒ"]
    k = 0.06
    venue_bonus = k * style * ( +1.00*esc +0.40*mak -0.60*sashi -0.25*mark )
    prof_base[no] = base + clamp(venue_bonus, -0.06, +0.06)

# ======== å€‹äººè£œæ­£ï¼ˆå¾—ç‚¹/è„šè³ªä¸Šä½/ç€é †åˆ†å¸ƒï¼‰ ========
ratings_sorted = sorted(active_cars, key=lambda n: ratings_val[n], reverse=True)
ratings_rank = {no: i+1 for i,no in enumerate(ratings_sorted)}

def tenscore_bonus(no):
    r = ratings_rank[no]
    top_n = min(3, len(active_cars))
    bottom_n = min(3, len(active_cars))
    if r <= top_n: return +0.03
    if r >= len(active_cars)-bottom_n+1: return -0.02
    return 0.0

def topk_bonus(k_dict, topn=3, val=0.02):
    order = sorted(k_dict.items(), key=lambda x:(x[1], -x[0]), reverse=True)
    grant = set([no for i,(no,v) in enumerate(order) if i<topn])
    return {no:(val if no in grant else 0.0) for no in k_dict}

esc_bonus   = topk_bonus(k_esc,   topn=3, val=0.02)
mak_bonus   = topk_bonus(k_mak,   topn=3, val=0.02)
sashi_bonus = topk_bonus(k_sashi, topn=3, val=0.015)
mark_bonus  = topk_bonus(k_mark,  topn=3, val=0.01)

def finish_bonus(no):
    tot = x1[no]+x2[no]+x3[no]+x_out[no]
    if tot == 0: return 0.0
    in3 = (x1[no]+x2[no]+x3[no]) / tot
    out = x_out[no] / tot
    bonus = 0.0
    if in3 > 0.50: bonus += 0.03
    if out > 0.70: bonus -= 0.03
    if out < 0.40: bonus += 0.02
    return bonus

extra_bonus = {}
for no in active_cars:
    total = (tenscore_bonus(no) +
             esc_bonus.get(no,0.0) + mak_bonus.get(no,0.0) +
             sashi_bonus.get(no,0.0) + mark_bonus.get(no,0.0) +
             finish_bonus(no))
    extra_bonus[no] = clamp(total, -0.10, +0.10)

# SBãªã—åˆè¨ˆï¼ˆç’°å¢ƒè£œæ­£ + å¾—ç‚¹å¾®è£œæ­£ + å€‹äººè£œæ­£ï¼‰
tens_list = [ratings_val[no] for no in active_cars]
t_corr = tenscore_correction(tens_list) if active_cars else []
tens_corr = {no:t_corr[i] for i,no in enumerate(active_cars)} if active_cars else {}

rows=[]
for no in active_cars:
    role = role_in_line(no, line_def)
    wind = wind_adjust(wind_dir, wind_speed, role, prof_escape[no])
    extra = max(eff_laps-2, 0)
    fatigue_scale = 1.0 if race_class=="ï¼³ç´š" else (1.1 if race_class=="ï¼¡ç´š" else (1.2 if race_class=="ï¼¡ç´šãƒãƒ£ãƒ¬ãƒ³ã‚¸" else 1.05))
    laps_adj = (-0.10*extra*(1.0 if prof_escape[no]>0.5 else 0.0) + 0.05*extra*(1.0 if prof_oikomi[no]>0.4 else 0.0)) * fatigue_scale
    bank_b = bank_character_bonus(bank_angle, straight_length, prof_escape[no], prof_sashi[no])
    length_b = bank_length_adjust(bank_length, prof_oikomi[no])
    indiv = extra_bonus.get(no, 0.0)

    total_raw = (prof_base[no] + wind + cf["spread"]*tens_corr.get(no,0.0) + bank_b + length_b + laps_adj + indiv)
    rows.append([no, role, round(prof_base[no],3), wind, round(cf["spread"]*tens_corr.get(no,0.0),3),
                 round(bank_b,3), round(length_b,3), round(laps_adj,3), round(indiv,3), total_raw])

df = pd.DataFrame(rows, columns=["è»Šç•ª","å½¹å‰²","è„šè³ªåŸºæº–(ä¼šå ´)","é¢¨è£œæ­£","å¾—ç‚¹è£œæ­£","ãƒãƒ³ã‚¯è£œæ­£","å‘¨é•·è£œæ­£","å‘¨å›è£œæ­£","å€‹äººè£œæ­£","åˆè¨ˆ_SBãªã—_raw"])
mu = float(df["åˆè¨ˆ_SBãªã—_raw"].mean()) if not df.empty else 0.0
df["åˆè¨ˆ_SBãªã—"] = mu + 1.0*(df["åˆè¨ˆ_SBãªã—_raw"] - mu)

# ===== KOæ–¹å¼ï¼šæœ€çµ‚ä¸¦ã³ã®åæ˜ ï¼ˆç”·å­ã®ã¿ï¼ã‚¬ãƒ¼ãƒ«ã‚ºã¯ç„¡åŠ¹ï¼‰ =====
# ã‚­ãƒ¼å‹ä¸ä¸€è‡´å¯¾ç­–ï¼šå¿…ãš int ã‚­ãƒ¼ / float å€¤ã«çµ±ä¸€
v_wo = {
    int(k): float(v)
    for k, v in zip(df["è»Šç•ª"].astype(int), df["åˆè¨ˆ_SBãªã—"].astype(float))
}

_is_girls = (race_class == "ã‚¬ãƒ¼ãƒ«ã‚º")
head_scale = KO_HEADCOUNT_SCALE.get(int(n_cars), 1.0)
ko_scale = (KO_GIRLS_SCALE if _is_girls else 1.0) * head_scale  # ã‚¬ãƒ¼ãƒ«ã‚ºã¯0.0ã§ç„¡åŠ¹

if ko_scale > 0.0 and line_def and len(line_def) >= 1:
    ko_order = _ko_order(v_wo, line_def, S, B, line_factor=line_factor_eff, gap_delta=KO_GAP_DELTA)
    vals = [v_wo[c] for c in v_wo.keys()]
    mu0  = float(np.mean(vals)); sd0 = float(np.std(vals) + 1e-12)
    step = KO_STEP_SIGMA * sd0
    new_scores = {}
    for rank, car in enumerate(ko_order, start=1):
        rank_adjust = step * (len(ko_order) - rank)
        blended = (1.0 - ko_scale) * v_wo[car] + ko_scale * (mu0 + rank_adjust - (len(ko_order)/2.0 - 0.5)*step)
        new_scores[car] = blended
    # ã“ã“ã§ã‚‚å¿…ãš int/float ã«çµ±ä¸€
    v_final = {int(k): float(v) for k, v in new_scores.items()}
else:
    v_final = {int(k): float(v) for k, v in v_wo.items()}

# --- ç´”SBãªã—ãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼ˆKOã¾ã§ï¼æ ¼ä¸Šã’å‰ï¼‰---
df_sorted_pure = pd.DataFrame({
    "è»Šç•ª": list(v_final.keys()),
    "åˆè¨ˆ_SBãªã—": [round(float(v_final[c]), 6) for c in v_final.keys()]
}).sort_values("åˆè¨ˆ_SBãªã—", ascending=False).reset_index(drop=True)

# --- ä¸€æ—¦ã®ãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼ˆâ—é¸å‡ºã®å†…éƒ¨å‚ç…§ç”¨ãƒ»è¡¨ç¤ºã¯å¾Œã§æ ¼ä¸Šã’ç‰ˆã§ä¸Šæ›¸ãï¼‰ ---
df_sorted_wo_tmp = pd.DataFrame({
    "è»Šç•ª": active_cars,
    "åˆè¨ˆ_SBãªã—": [round(float(v_final.get(int(c), float("-inf"))), 6) for c in active_cars]
}).sort_values("åˆè¨ˆ_SBãªã—", ascending=False).reset_index(drop=True)


# ===== ã“ã“ã‹ã‚‰ï¼ˆå°é¸å®šâ†’â—ç¢ºå®šï¼‰ =====
# å€™è£œCï¼ˆå¾—ç‚¹Ã—2ç€ç‡ãƒ–ãƒ¬ãƒ³ãƒ‰ ä¸Šä½3ï¼‰
blend = {no: (ratings_val[no] + min(50.0, p2_eff[no]*100.0))/2.0 for no in active_cars}
C = [kv[0] for kv in sorted(blend.items(), key=lambda x:x[1], reverse=True)[:min(3,len(blend))]]

# ãƒ©ã‚¤ãƒ³SBï¼ˆâ—é¸å‡ºç”¨ï¼‰
bonus_init,_ = compute_lineSB_bonus(line_def, S, B, line_factor=line_factor_eff, exclude=None, cap=cap_SB_eff, enable=line_sb_enable)

def anchor_score(no):
    g = car_to_group.get(no, None); role = role_in_line(no, line_def)
    sb = bonus_init.get(g,0.0) * (pos_coeff(role, 1.0) if line_sb_enable else 0.0)
    zt = zscore_list([ratings_val[n] for n in active_cars]) if active_cars else []
    zt_map = {n:float(zt[i]) for i,n in enumerate(active_cars)} if active_cars else {}
    return v_final.get(no, -1e9) + sb + 0.01*zt_map.get(no, 0.0)

anchor_no_pre = max(C, key=lambda x: anchor_score(x)) if C else int(df_sorted_wo_tmp.loc[0,"è»Šç•ª"])

ratings_sorted2 = sorted(active_cars, key=lambda n: ratings_val[n], reverse=True)
ratings_rank2 = {no: i+1 for i, no in enumerate(ratings_sorted2)}
ALLOWED_MAX_RANK = 4
C_hard = [no for no in C if ratings_rank2.get(no, 999) <= ALLOWED_MAX_RANK]
C_use = C_hard if C_hard else ratings_sorted2[:ALLOWED_MAX_RANK]
anchor_no = max(C_use, key=lambda x: anchor_score(x))

if anchor_no != anchor_no_pre:
    st.caption(f"â€» â—ã¯ã€ç«¶èµ°å¾—ç‚¹ ä¸Šä½{ALLOWED_MAX_RANK}ä½ä»¥å†…ã€ç¸›ã‚Šã«ã‚ˆã‚Š {anchor_no_pre}â†’{anchor_no} ã«èª¿æ•´ã—ã¦ã„ã¾ã™ã€‚")

# --- â—ãƒ©ã‚¤ãƒ³æ ¼ä¸Šã’ï¼ˆAæ–¹å¼ï¼‰é©ç”¨ï¼šè¡¨ç¤ºç”¨ã‚¹ã‚³ã‚¢ã‚’ä¸Šæ›¸ã ---
role_map = {no: role_in_line(no, line_def) for no in active_cars}
confidence = None  # ä¸‹ã§è¨ˆç®—

# ä»®ã®ä¿¡é ¼åº¦ã‚’å…ˆã«ç®—å‡ºï¼ˆå¾“æ¥ãƒ­ã‚¸ãƒƒã‚¯ï¼‰
cand_scores = [anchor_score(no) for no in C] if len(C)>=2 else [0,0]
cand_scores_sorted = sorted(cand_scores, reverse=True)
conf_gap = cand_scores_sorted[0]-cand_scores_sorted[1] if len(cand_scores_sorted)>=2 else 0.0
spread = float(np.std(list(v_final.values()))) if len(v_final)>=2 else 0.0
norm = conf_gap / (spread if spread>1e-6 else 1.0)
confidence = "å„ªä½" if norm>=1.0 else ("äº’è§’" if norm>=0.5 else "æ··æˆ¦")

score_adj_map = apply_anchor_line_bonus(
    score_raw=v_final,
    line_of=car_to_group,
    role_map=role_map,
    anchor=anchor_no,
    tenkai=confidence
)

# è¡¨ç¤ºãƒ»noteãƒ»è²·ã„ç›®ã®â€œSBãªã—ãƒ©ãƒ³ã‚­ãƒ³ã‚°â€ã¯æ ¼ä¸Šã’å¾Œã§çµ±ä¸€ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã« -1e9 ã¯ä½¿ã‚ãªã„ï¼‰
df_sorted_wo = pd.DataFrame({
    "è»Šç•ª": active_cars,
    "åˆè¨ˆ_SBãªã—": [round(float(score_adj_map.get(int(c), v_final.get(int(c), float("-inf")))), 6) for c in active_cars]
}).sort_values("åˆè¨ˆ_SBãªã—", ascending=False).reset_index(drop=True)

velobi_wo = list(zip(df_sorted_wo["è»Šç•ª"].astype(int).tolist(),
                     df_sorted_wo["åˆè¨ˆ_SBãªã—"].round(3).tolist()))

# å°é›†ç´„ï¼ˆâ—ãƒ©ã‚¤ãƒ³å„ªå…ˆï¼šåŒãƒ©ã‚¤ãƒ³ã‚’ä¸Šã‹ã‚‰é †ã«æ¡ç”¨ï¼‰
rank_wo = {int(df_sorted_wo.loc[i, "è»Šç•ª"]): i+1 for i in range(len(df_sorted_wo))}
result_marks, reasons = {}, {}
result_marks["â—"] = anchor_no
reasons[anchor_no] = "æœ¬å‘½(Cä¸Šä½3â†’å¾—ç‚¹4ä½ä»¥å†…ã‚²ãƒ¼ãƒˆâ†’ãƒ©ã‚¤ãƒ³SBé‡è¦–ï¼‹KOä¸¦ã³)"

# ã‚¹ã‚³ã‚¢è¾æ›¸ï¼ˆæ ¼ä¸Šã’å¾Œï¼‰
score_map = {int(df_sorted_wo.loc[i, "è»Šç•ª"]): float(df_sorted_wo.loc[i, "åˆè¨ˆ_SBãªã—"])
             for i in range(len(df_sorted_wo))}

# å…¨ä½“ä¸¦ã³ï¼ˆâ—é™¤å¤–ï¼‰
overall_rest = [int(df_sorted_wo.loc[i, "è»Šç•ª"])
                for i in range(len(df_sorted_wo))
                if int(df_sorted_wo.loc[i, "è»Šç•ª"]) != anchor_no]

# â—ã®ãƒ©ã‚¤ãƒ³ãƒ¡ãƒ³ãƒãƒ¼ï¼ˆâ—ã‚’é™¤å¤–ï¼‰ã‚’ã‚¹ã‚³ã‚¢é™é †ã«
a_gid = car_to_group.get(anchor_no, None)
mates_sorted = []
if a_gid is not None and a_gid in line_def:
    mates_sorted = sorted(
        [c for c in line_def[a_gid] if c != anchor_no],
        key=lambda x: (-score_map.get(x, -1e9), x)
    )

# ã€‡ï¼šå…¨ä½“ãƒˆãƒƒãƒ—ï¼ˆâ—é™¤å¤–ï¼‰
if overall_rest:
    result_marks["ã€‡"] = overall_rest[0]
    reasons[overall_rest[0]] = "å¯¾æŠ—ï¼ˆæ ¼ä¸Šã’å¾ŒSBãªã—ã‚¹ã‚³ã‚¢é †ï¼‰"

used = set(result_marks.values())

# â–²ï¼šâ—ãƒ©ã‚¤ãƒ³ã‹ã‚‰æœ€ä¸Šä½ã‚’â€œå¼·åˆ¶â€æ¡ç”¨ï¼ˆã€‡ãŒåŒãƒ©ã‚¤ãƒ³ãªã‚‰æ¬¡ç‚¹ï¼‰
mate_candidates = [c for c in mates_sorted if c not in used]
if mate_candidates:
    pick = mate_candidates[0]
    result_marks["â–²"] = pick
    reasons[pick] = "å˜ç©´ï¼ˆâ—ãƒ©ã‚¤ãƒ³å„ªå…ˆï¼šåŒãƒ©ã‚¤ãƒ³æœ€ä¸Šä½ã‚’æ¡ç”¨ï¼‰"
else:
    # åŒãƒ©ã‚¤ãƒ³ã«å€™è£œãŒç„¡ã„ï¼ˆå˜é¨ãªã©ï¼‰ã®ã¨ãã¯å…¨ä½“æ¬¡ç‚¹
    rest_global = [c for c in overall_rest if c not in used]
    if rest_global:
        pick = rest_global[0]
        result_marks["â–²"] = pick
        reasons[pick] = "å˜ç©´ï¼ˆæ ¼ä¸Šã’å¾ŒSBãªã—ã‚¹ã‚³ã‚¢é †ï¼‰"

used = set(result_marks.values())

# æ®‹ã‚Šå°ï¼ˆâ–³ â†’ Ã— â†’ Î± â†’ Î²ï¼‰ã¯â€œâ—ãƒ©ã‚¤ãƒ³æ®‹ãƒ¡ãƒ³ãƒãƒ¼ã‚’å…ˆã«æ¶ˆåŒ–â€ã€ãã®å¾Œã«å…¨ä½“æ®‹ã‚Š
tail_priority = [c for c in mates_sorted if c not in used]
tail_priority += [c for c in overall_rest if c not in used and c not in tail_priority]

for mk in ["â–³","Ã—","Î±","Î²"]:
    if mk in result_marks:
        continue
    if not tail_priority:
        break
    no = tail_priority.pop(0)
    result_marks[mk] = no
    reasons[no] = f"{mk}ï¼ˆâ—ãƒ©ã‚¤ãƒ³å„ªå…ˆâ†’æ®‹ã‚Šã‚¹ã‚³ã‚¢é †ï¼‰"

# å‡ºåŠ›ï¼ˆSBãªã—ãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼‰
st.markdown("### ãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼†å°ï¼ˆâ—ãƒ©ã‚¤ãƒ³æ ¼ä¸Šã’åæ˜ æ¸ˆã¿ï¼‰")
rows_out=[]
for r,(no,sc) in enumerate(velobi_wo, start=1):
    mark = "".join([m for m,v in result_marks.items() if v==no])
    n_tot = x1.get(no,0)+x2.get(no,0)+x3.get(no,0)+x_out.get(no,0)
    p1 = (x1.get(no,0)/(n_tot+1e-9))*100
    p2 = (x2.get(no,0)/(n_tot+1e-9))*100
    rows_out.append({
        "é †(SBãªã—)": r, "å°": mark, "è»Š": no,
        "SBãªã—ã‚¹ã‚³ã‚¢": sc,
        "å¾—ç‚¹": ratings_val.get(no, None),
        "1ç€å›": x1.get(no,0), "2ç€å›": x2.get(no,0), "3ç€å›": x3.get(no,0), "ç€å¤–": x_out.get(no,0),
        "1ç€%": round(p1,1), "2ç€%": round(p2,1),
        "ãƒ©ã‚¤ãƒ³": car_to_group.get(no,"-")
    })
st.dataframe(pd.DataFrame(rows_out), use_container_width=True)

st.markdown("#### è£œæ­£å†…è¨³ï¼ˆSBãªã—ï¼‰")
show=[]
for no,_ in velobi_wo:
    rec = df[df["è»Šç•ª"]==no].iloc[0]
    show.append({
        "è»Š":int(no),"ãƒ©ã‚¤ãƒ³":car_to_group.get(int(no),"-"),
        "è„šè³ªåŸºæº–(ä¼šå ´)":round(rec["è„šè³ªåŸºæº–(ä¼šå ´)"],3),
        "é¢¨è£œæ­£":rec["é¢¨è£œæ­£"],"å¾—ç‚¹è£œæ­£":rec["å¾—ç‚¹è£œæ­£"],
        "ãƒãƒ³ã‚¯è£œæ­£":rec["ãƒãƒ³ã‚¯è£œæ­£"],"å‘¨é•·è£œæ­£":rec["å‘¨é•·è£œæ­£"],
        "å‘¨å›è£œæ­£":rec["å‘¨å›è£œæ­£"],"å€‹äººè£œæ­£":rec["å€‹äººè£œæ­£"],
        "åˆè¨ˆ_SBãªã—_raw":round(rec["åˆè¨ˆ_SBãªã—_raw"],3),
        "åˆè¨ˆ_SBãªã—":round(rec["åˆè¨ˆ_SBãªã—"],3)
    })
st.dataframe(pd.DataFrame(show), use_container_width=True)

# ã€Œã‚¹ã‚³ã‚¢é †ï¼ˆSBãªã—ï¼‰ã€ã®noteè¡¨è¨˜ç”¨ï¼ˆæ ¼ä¸Šã’å‰ï¼KOã¾ã§ï¼‰
score_order_text = format_rank_all(
    {int(r["è»Šç•ª"]): float(r["åˆè¨ˆ_SBãªã—"]) for _, r in df_sorted_pure.iterrows()},
    P_floor_val=None
)


st.caption(
    f"ç«¶è¼ªå ´ã€€{track}{race_no}R / {race_time}ã€€{race_class} / "
    f"é–‹å‚¬æ—¥ï¼š{day_label}ï¼ˆlineä¿‚æ•°={line_factor_eff:.2f}, SBcapÂ±{cap_SB_eff:.2f}ï¼‰ / "
    f"ä¼šå ´ã‚¹ã‚¿ã‚¤ãƒ«:{style:+.2f} / é¢¨:{wind_dir} / æœ‰åŠ¹å‘¨å›={eff_laps} / å±•é–‹è©•ä¾¡ï¼š**{confidence}**ï¼ˆNorm={norm:.2f})"
)

# ==============================
# è²·ã„ç›®ï¼ˆæƒ³å®šçš„ä¸­ç‡ â†’ å¿…è¦ã‚ªãƒƒã‚º=1/pï¼‰
# ==============================
st.markdown("### ğŸ¯ è²·ã„ç›®ï¼ˆæƒ³å®šçš„ä¸­ç‡ â†’ å¿…è¦ã‚ªãƒƒã‚º=1/pï¼‰")

one = result_marks.get("â—", None)
two = result_marks.get("ã€‡", None)
three = result_marks.get("â–²", None)

if one is None:
    st.warning("â—æœªæ±ºå®šã®ãŸã‚è²·ã„ç›®ã¯ã‚¹ã‚­ãƒƒãƒ—")
    trioC_df = wide_df = qn_df = ex_df = santan_df = None
else:
    # baseï¼šæ ¼ä¸Šã’å¾Œã‚¹ã‚³ã‚¢ â†’ softmax
    strength_map = dict(velobi_wo)
    xs = np.array([strength_map.get(i, 0.0) for i in range(1, n_cars+1)], dtype=float)
    if xs.std() < 1e-12:
        base = np.ones_like(xs)/len(xs)
    else:
        z = (xs - xs.mean())/(xs.std()+1e-12)
        base = np.exp(z); base = base/base.sum()

    mark_by_car = {car: None for car in range(1, n_cars+1)}
    for mk, car in result_marks.items():
        if car is not None and 1 <= car <= n_cars:
            mark_by_car[car] = mk

    # â˜…ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å¼±ä½“åŒ–ï¼ˆå›ºå®šåŒ–é˜²æ­¢ï¼‹â€œ1.0å€åœ°ç„â€å›é¿ï¼‰
    def calibrate_probs(base_vec: np.ndarray, stat_key: str) -> np.ndarray:
        base_norm = base_vec / max(base_vec.sum(), 1e-12)
        m = np.ones(n_cars, dtype=float)
        expo_map = {"å„ªä½": 0.60, "äº’è§’": 0.80, "æ··æˆ¦": 1.00}
        expo_eff = expo_map.get(confidence, 0.80)
        for idx, car in enumerate(range(1, n_cars+1)):
            mk = mark_by_car.get(car)
            if mk not in RANK_STATS:
                mk = RANK_FALLBACK_MARK
            tgt = float(RANK_STATS[mk][stat_key])
            ratio = tgt / max(float(base_norm[idx]), 1e-9)
            m[idx] = float(np.clip(ratio ** expo_eff, 0.70, 1.50))
        probs = base_norm * m
        probs = probs / max(probs.sum(), 1e-12)
        # ã•ã‚‰ã«ãƒ•ãƒ©ãƒƒãƒˆåŒ–ï¼ˆå›ºå®šãƒ¡ã‚¿é˜²æ­¢ï¼‰
        alpha = 0.15
        probs = (1.0 - alpha) * probs + alpha * (np.ones_like(probs) / len(probs))
        return probs

    probs_p3 = calibrate_probs(base, "pTop3")
    probs_p2 = calibrate_probs(base, "pTop2")
    probs_p1 = calibrate_probs(base, "p1")

    rng = np.random.default_rng(20250830)
    trials = st.slider("ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³è©¦è¡Œå›æ•°", 1000, 20000, 8000, 1000)

    # â˜…ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã®æ¸©åº¦ä»˜ã‘ï¼ˆåºåˆ—ã®ç¡¬ç›´å›é¿ï¼‰
    def sample_order_from_probs(pvec: np.ndarray, tau: float = 1.6) -> list[int]:
        logits = np.log(np.clip(pvec, 1e-12, 1.0)) / tau
        g = -np.log(-np.log(np.clip(rng.random(len(pvec)), 1e-12, 1-1e-12)))
        score = logits + g
        return (np.argsort(-score)+1).tolist()

    mates = [x for x in [two, three] if x is not None]
    all_others = [i for i in range(1, n_cars+1) if i != one]

    trioC_counts = {}
    wide_counts = {k:0 for k in all_others}
    qn_counts   = {k:0 for k in all_others}
    ex_counts   = {k:0 for k in all_others}
    st3_counts  = {}

    trioC_list = []
    if len(mates) > 0:
        for a in all_others:
            for b in all_others:
                if a >= b: continue
                if (a in mates) or (b in mates):
                    t = tuple(sorted([a, b, one]))
                    trioC_list.append(t)
        trioC_list = sorted(set(trioC_list))

    for _ in range(trials):
        order_p3 = sample_order_from_probs(probs_p3)
        top3_p3 = set(order_p3[:3])

        if one in top3_p3:
            for k in wide_counts.keys():
                if k in top3_p3:
                    wide_counts[k] += 1
            if len(trioC_list) > 0:
                others = list(top3_p3 - {one})
                if len(others) == 2:
                    a, b = sorted(others)
                    if (a in mates) or (b in mates):
                        t = tuple(sorted([a, b, one]))
                        if t in trioC_list:
                            trioC_counts[t] = trioC_counts.get(t, 0) + 1

        order_p2 = sample_order_from_probs(probs_p2)
        top2_p2 = set(order_p2[:2])
        if one in top2_p2:
            for k in qn_counts.keys():
                if k in top2_p2:
                    qn_counts[k] += 1

        order_p1 = sample_order_from_probs(probs_p1)
        if order_p1[0] == one:
            k2 = order_p1[1]
            if k2 in ex_counts:
                ex_counts[k2] += 1
            if len(mates) > 0 and len(order_p1) >= 3:
                k3 = order_p1[2]
                if (k2 in mates) and (k3 not in (one, k2)):
                    st3_counts[(k2, k3)] = st3_counts.get((k2, k3), 0) + 1

    # ï¼ˆä»»æ„ï¼‰Bæ–¹å¼ã®å¾®å°ãƒ–ãƒ¼ã‚¹ãƒˆ
    if any(v > 0 for v in PROB_U.values()):
        a_line = car_to_group.get(one, None)
        def role_of(i): return role_in_line(i, line_def)
        # ãƒ¯ã‚¤ãƒ‰
        for k in list(wide_counts.keys()):
            if a_line is not None and car_to_group.get(k) == a_line and k != one:
                u = PROB_U.get(role_of(k), 0.0)
                if u > 0.0:
                    wide_counts[k] = int(round(wide_counts[k] * (1.0 + u)))
        # ä¸‰é€£è¤‡C
        new_trioC_counts = {}
        for t, cnt in trioC_counts.items():
            factor = 1.0
            for x in t:
                if x == one: 
                    continue
                if a_line is not None and car_to_group.get(x) == a_line:
                    u = PROB_U.get(role_of(x), 0.0)
                    factor *= (1.0 + u)
            new_trioC_counts[t] = int(round(cnt * factor))
        trioC_counts = new_trioC_counts

    # Pãƒ•ãƒ­ã‚¢ã¨EVå¸¯ï¼ˆé–‹å‚¬ã®æ··ç·šåº¦ã§å¾®èª¿æ•´ï¼‰
    P_FLOOR = globals().get("P_FLOOR", {"wide": 0.060, "sanpuku": 0.040, "nifuku": 0.050, "nitan": 0.040, "santan": 0.030})
    scale = 1.00
    if confidence == "å„ªä½":   scale = 0.90
    elif confidence == "æ··æˆ¦": scale = 1.10
    for k in ("wide","sanpuku","nifuku"):
        P_FLOOR[k] *= scale

    E_MIN = globals().get("E_MIN", 0.00)
    E_MAX = globals().get("E_MAX", 0.50)

    # ===== ä¸‰é€£è¤‡C =====
    if len(trioC_list) > 0:
        rows = []
        for t in trioC_list:
            cnt = int(trioC_counts.get(t, 0) or 0)
            p = cnt / float(trials)
            rows.append({
                "è²·ã„ç›®": f"{t[0]}-{t[1]}-{t[2]}",
                "p(æƒ³å®šçš„ä¸­ç‡)": round(p, 4),
                "å¿…è¦ã‚ªãƒƒã‚º(=1/p)": "-" if cnt==0 else round(1.0/max(p,1e-12), 2)
            })
        trioC_df = pd.DataFrame(rows)
        st.markdown("#### ä¸‰é€£è¤‡Cï¼ˆâ—-[ç›¸æ‰‹]-å…¨ï¼‰â€»è»Šç•ªé †")
        def _key_nums_tri(s): return list(map(int, re.findall(r"\d+", s)))
        trioC_df = trioC_df.sort_values(by="è²·ã„ç›®", key=lambda s: s.map(_key_nums_tri)).reset_index(drop=True)
        st.dataframe(trioC_df, use_container_width=True)
    else:
        trioC_df = None
        st.info("ä¸‰é€£è¤‡Cï¼šç›¸æ‰‹ï¼ˆã€‡/â–²ï¼‰ãŒæœªè¨­å®šã®ãŸã‚è¡¨ç¤ºãªã—")

    # ä¸‰é€£è¤‡ãƒã‚¹ã‚±ãƒƒãƒˆåˆæˆã‚ªãƒƒã‚ºã¨ç›¸æ‰‹é›†åˆS
    Sset = set()
    O_combo = None
    if trioC_df is not None and len(trioC_df) > 0:
        need_list = []
        for _, r in trioC_df.iterrows():
            name = str(r["è²·ã„ç›®"])
            nums = list(map(int, re.findall(r"\d+", name)))
            others = [x for x in nums if x != one]
            Sset.update(others)
            need_val = r.get("å¿…è¦ã‚ªãƒƒã‚º(=1/p)")
            if isinstance(need_val, (int, float)) and float(need_val) > 0:
                need_list.append(float(need_val))
        if need_list:
            denom = sum(1.0/x for x in need_list if x > 0)
            if denom > 0:
                O_combo = float(f"{(1.0 / denom):.2f}")

    # ===== ãƒ¯ã‚¤ãƒ‰ï¼ˆâ—-å…¨ï¼‰ =====
    rows = []
    for k in sorted([i for i in range(1, n_cars+1) if i != one]):
        cnt = int(wide_counts.get(k, 0) or 0)
        p = cnt / float(trials)
        if p < float(P_FLOOR.get("wide", 0.06)):  # Pãƒ•ãƒ­ã‚¢ï¼ˆå‘½ï¼‰
            continue
        if cnt <= 0:
            continue
        need = 1.0 / max(p, 1e-12)  # EVä¸‹é™
        # ä¸‰é€£è¤‡ã®ç›¸æ‰‹é›†åˆSã«è©²å½“ã™ã‚‹å ´åˆã¯ã€Œåˆæˆã‚ªãƒƒã‚ºã€ã‚‚ä¸‹é™ã«åŠ ãˆã‚‹
        if (O_combo is not None) and (k in Sset):
            need = max(need, float(O_combo))
            rule_note = f"ä¸‰è¤‡è¢«ã‚Šâ†’åˆæˆ{float(O_combo):.2f}å€ä»¥ä¸Š"
        else:
            rule_note = "å¿…è¦ã‚ªãƒƒã‚ºä»¥ä¸Š"
        if not np.isfinite(need) or need <= 0:
            continue
        rows.append({
            "è²·ã„ç›®": f"{one}-{k}",
            "p(æƒ³å®šçš„ä¸­ç‡)": round(p, 4),
            "å¿…è¦ã‚ªãƒƒã‚º(=1/p)": round(need, 2),
            "ãƒ«ãƒ¼ãƒ«": rule_note
        })
    wide_df = pd.DataFrame(rows)
    st.markdown("#### ãƒ¯ã‚¤ãƒ‰ï¼ˆâ—-å…¨ï¼‰â€»è»Šç•ªé †")
    if len(wide_df) > 0:
        wide_df = wide_df.sort_values(by="è²·ã„ç›®", key=lambda s: s.map(_sort_key_by_numbers)).reset_index(drop=True)
        st.dataframe(wide_df, use_container_width=True)
        if O_combo is not None:
            st.caption("â€»ä¸‰é€£è¤‡ã§ä½¿ç”¨ã—ãŸç›¸æ‰‹ï¼ˆSå´ï¼‰ã¯ **max(å¿…è¦ã‚ªãƒƒã‚º, åˆæˆã‚ªãƒƒã‚º)** ä»¥ä¸Šã§æ¡ç”¨ã€‚Så¤–ã¯ **å¿…è¦ã‚ªãƒƒã‚ºä»¥ä¸Š**ã§æ¡ç”¨ã€‚")
        else:
            st.caption("â€»ãƒ¯ã‚¤ãƒ‰ã¯ **å¿…è¦ã‚ªãƒƒã‚º(=1/p)ä»¥ä¸Š**ã§æ¡ç”¨ï¼ˆä¸Šé™æ’¤å»ƒï¼‰ã€‚")
    else:
        st.info("ãƒ¯ã‚¤ãƒ‰ï¼šå¯¾è±¡å¤–ï¼ˆPãƒ•ãƒ­ã‚¢æœªæº€ã€ã¾ãŸã¯åˆæˆã‚ªãƒƒã‚ºåŸºæº–ã§é™¤å¤–ï¼‰")

    # ===== äºŒè»Šè¤‡ =====
    rows = []
    for k in sorted([i for i in range(1, n_cars+1) if i != one]):
        cnt = int(qn_counts.get(k, 0) or 0)
        p = cnt / float(trials)
        if p < float(P_FLOOR.get("nifuku", 0.05)):  # Pãƒ•ãƒ­ã‚¢ï¼ˆå‘½ï¼‰
            continue
        if cnt <= 0:
            continue
        need = 1.0 / max(p, 1e-12)  # EVä¸‹é™
        low, high = need*(1.0+E_MIN), need*(1.0+E_MAX)
        rows.append({
            "è²·ã„ç›®": f"{one}-{k}",
            "p(æƒ³å®šçš„ä¸­ç‡)": round(p, 4),
            "è²·ãˆã‚‹å¸¯": f"{low:.1f}ã€œ{high:.1f}å€ãªã‚‰è²·ã„"
        })
    qn_df = pd.DataFrame(rows)
    st.markdown("#### äºŒè»Šè¤‡ï¼ˆâ—-å…¨ï¼‰â€»è»Šç•ªé †")
    if len(qn_df) > 0:
        def _key_nums_qn(s): return list(map(int, re.findall(r"\d+", s)))
        qn_df = qn_df.sort_values(by="è²·ã„ç›®", key=lambda s: s.map(_key_nums_qn)).reset_index(drop=True)
        st.dataframe(qn_df, use_container_width=True)
    else:
        st.info("äºŒè»Šè¤‡ï¼šå¯¾è±¡å¤–")

    # ===== äºŒè»Šå˜ =====
    rows = []
    for k in sorted([i for i in range(1, n_cars+1) if i != one]):
        cnt = int(ex_counts.get(k, 0) or 0)
        p = cnt / float(trials)
        if p < float(P_FLOOR.get("nitan", 0.04)):  # Pãƒ•ãƒ­ã‚¢ï¼ˆå‘½ï¼‰
            continue
        if cnt <= 0:
            continue
        need = 1.0 / max(p, 1e-12)  # EVä¸‹é™
        low, high = need*(1.0+E_MIN), need*(1.0+E_MAX)
        rows.append({
            "è²·ã„ç›®": f"{one}->{k}",
            "p(æƒ³å®šçš„ä¸­ç‡)": round(p, 4),
            "è²·ãˆã‚‹å¸¯": f"{low:.1f}ã€œ{high:.1f}å€ãªã‚‰è²·ã„"
        })
    ex_df = pd.DataFrame(rows)
    st.markdown("#### äºŒè»Šå˜ï¼ˆâ—â†’å…¨ï¼‰â€»è»Šç•ªé †")
    if len(ex_df) > 0:
        def _key_nums_ex(s): return list(map(int, re.findall(r"\d+", s)))
        ex_df = ex_df.sort_values(by="è²·ã„ç›®", key=lambda s: s.map(_key_nums_ex)).reset_index(drop=True)
        st.dataframe(ex_df, use_container_width=True)
    else:
        st.info("äºŒè»Šå˜ï¼šå¯¾è±¡å¤–")

    # ===== ä¸‰é€£å˜ï¼ˆâ—â†’[ç›¸æ‰‹]â†’å…¨ï¼‰ =====
    rows = []
    p_floor_santan = float(P_FLOOR.get("santan", 0.03))
    for (sec, thr), cnt in st3_counts.items():
        cnt = int(cnt or 0)
        if cnt <= 0:
            continue
        p = cnt / float(trials)
        if p < p_floor_santan:  # Pãƒ•ãƒ­ã‚¢ï¼ˆå‘½ï¼‰
            continue
        need = 1.0 / max(p, 1e-12)  # EVä¸‹é™
        low, high = need*(1.0+E_MIN), need*(1.0+E_MAX)
        rows.append({
            "è²·ã„ç›®": f"{one}->{sec}->{thr}",
            "p(æƒ³å®šçš„ä¸­ç‡)": round(p, 5),
            "è²·ãˆã‚‹å¸¯": f"{low:.1f}ã€œ{high:.1f}å€ãªã‚‰è²·ã„"
        })
    if rows:
        santan_df = pd.DataFrame(rows)
        def _key_nums_st(s): return list(map(int, re.findall(r"\d+", s)))
        santan_df = santan_df.sort_values(by="è²·ã„ç›®", key=lambda s: s.map(_key_nums_st)).reset_index(drop=True)
        st.markdown("#### ä¸‰é€£å˜ï¼ˆâ—â†’[ç›¸æ‰‹]â†’å…¨ï¼‰â€»è»Šç•ªé †")
        st.dataframe(santan_df, use_container_width=True)
    else:
        santan_df = None
        st.info("ä¸‰é€£å˜ï¼šå¯¾è±¡å¤–ï¼ˆPãƒ•ãƒ­ã‚¢æœªæº€ãƒ»ç›¸æ‰‹æœªè¨­å®šãƒ»è©²å½“ãªã—ï¼‰")

# ==============================
# noteç”¨ï¼šãƒ˜ãƒƒãƒ€ãƒ¼ã€œå±•é–‹è©•ä¾¡ï¼‹â€œè²·ãˆã‚‹ã‚ªãƒƒã‚ºå¸¯â€
# ==============================
st.markdown("### ğŸ“‹ noteç”¨ï¼ˆãƒ˜ãƒƒãƒ€ãƒ¼ã€œå±•é–‹è©•ä¾¡ï¼‹â€œè²·ãˆã‚‹ã‚ªãƒƒã‚ºå¸¯â€ï¼‰")

def _zone_lines_from_df(df: pd.DataFrame | None, bet_type_key: str) -> list[str]:
    """
    DataFrame ã‹ã‚‰ note å‡ºåŠ›ç”¨ã®ã€Œè²·ãˆã‚‹å¸¯ã€è¡Œã‚’å®‰å…¨ã«ä½œã‚‹ã€‚
    - 'è²·ãˆã‚‹å¸¯' ãŒã‚ã‚Œã°ãã‚Œã‚’å„ªå…ˆ
    - ç„¡ã‘ã‚Œã° 'å¿…è¦ã‚ªãƒƒã‚º(=1/p)' ã‹ã‚‰å¸¯ã‚’ä½œã‚‹ï¼ˆwide ã¯ 'ä»¥ä¸Šã§è²·ã„'ã€ãã®ä»–ã¯ EV å¸¯ï¼‰
    - ã„ãšã‚Œã‚‚ç„¡ã‘ã‚Œã°ã‚¹ã‚­ãƒƒãƒ—
    è¿”ã‚Šå€¤ã¯ 'è²·ã„ç›®ï¼šãƒ†ã‚­ã‚¹ãƒˆ' ã®å®Œå…¨ãªè¡Œã®é…åˆ—
    """
    if df is None or len(df) == 0 or ("è²·ã„ç›®" not in df.columns):
        return []

    out_rows: list[tuple[str, str]] = []  # (name, line_text)
    for _, r in df.iterrows():
        name = str(r.get("è²·ã„ç›®", "")).strip()
        if not name:
            continue

        # 1) æ—¢ã«ã€Œè²·ãˆã‚‹å¸¯ã€ãŒã‚ã‚‹ãªã‚‰ãã‚Œã‚’ä½¿ã†
        line_txt = None
        if "è²·ãˆã‚‹å¸¯" in r and pd.notna(r["è²·ãˆã‚‹å¸¯"]):
            s = str(r["è²·ãˆã‚‹å¸¯"]).strip()
            if s:
                line_txt = f"{name}ï¼š{s}"

        # 2) ç„¡ã‘ã‚Œã°ã€Œå¿…è¦ã‚ªãƒƒã‚º(=1/p)ã€ã‹ã‚‰ä½œã‚‹
        if line_txt is None:
            need_val = r.get("å¿…è¦ã‚ªãƒƒã‚º(=1/p)")
            if need_val is not None and need_val != "-" and str(need_val).strip() != "":
                try:
                    need = float(need_val)
                    if np.isfinite(need) and need > 0:
                        if bet_type_key == "wide":
                            line_txt = f"{name}ï¼š{need:.1f}å€ä»¥ä¸Šã§è²·ã„"
                        else:
                            low, high = need*(1.0+E_MIN), need*(1.0+E_MAX)
                            line_txt = f"{name}ï¼š{low:.1f}ã€œ{high:.1f}å€ãªã‚‰è²·ã„"
                except Exception:
                    pass  # å¤‰æ›å¤±æ•—ã¯ç„¡è¦–

        if line_txt:
            out_rows.append((name, line_txt))

    # è²·ã„ç›®ã®æ•°å­—é †ã«ä¸¦ã¹æ›¿ãˆ
    out_rows_sorted = sorted(out_rows, key=lambda x: _sort_key_by_numbers(x[0]))
    # ã“ã“ã§å®Œæˆãƒ†ã‚­ã‚¹ãƒˆã ã‘è¿”ã™ï¼ˆsplitã¯ä½¿ã‚ãªã„ï¼‰
    return [t for _, t in out_rows_sorted]


def _section_text(title: str, lines: list[str]) -> str:
    if not lines: return f"{title}\nå¯¾è±¡å¤–"
    return f"{title}\n" + "\n".join(lines)

line_text = "ã€€".join([x for x in line_inputs if str(x).strip()])
# ã‚¹ã‚³ã‚¢é †ï¼ˆSBãªã—ï¼‰ã¯æ ¼ä¸Šã’é©ç”¨å¾Œã® df_sorted_wo ã‹ã‚‰å¿…ãšä½œã‚‹
score_map_for_note = {int(r["è»Šç•ª"]): float(r["åˆè¨ˆ_SBãªã—"]) for _, r in df_sorted_wo.iterrows()}
score_order_text = format_rank_all(score_map_for_note, P_floor_val=None)
marks_line = " ".join(f"{m}{result_marks[m]}" for m in ["â—","ã€‡","â–²","â–³","Ã—","Î±","Î²"] if m in result_marks)

txt_trioC = _section_text("ä¸‰é€£è¤‡Cï¼ˆâ—-[ç›¸æ‰‹]-å…¨ï¼‰",
                          _zone_lines_from_df(trioC_df, "sanpuku") if one is not None else [])
txt_st    = _section_text("ä¸‰é€£å˜ï¼ˆâ—â†’[ç›¸æ‰‹]â†’å…¨ï¼‰",
                          _zone_lines_from_df(santan_df, "santan") if one is not None else [])
txt_wide  = _section_text("ãƒ¯ã‚¤ãƒ‰ï¼ˆâ—-å…¨ï¼‰",
                          _zone_lines_from_df(wide_df, "wide") if one is not None else [])
txt_qn    = _section_text("äºŒè»Šè¤‡ï¼ˆâ—-å…¨ï¼‰",
                          _zone_lines_from_df(qn_df, "nifuku") if one is not None else [])
txt_ex    = _section_text("äºŒè»Šå˜ï¼ˆâ—â†’å…¨ï¼‰",
                          _zone_lines_from_df(ex_df, "nitan") if one is not None else [])

wide_rule_note = "ï¼ˆãƒ¯ã‚¤ãƒ‰ã¯ä¸Šé™æ’¤å»ƒï¼šä¸‰é€£è¤‡ã§ä½¿ç”¨ã—ãŸç›¸æ‰‹ã¯åˆæˆã‚ªãƒƒã‚ºä»¥ä¸Šï¼ä¸‰é€£è¤‡ã‹ã‚‰æ¼ã‚ŒãŸç›¸æ‰‹ã¯å¿…è¦ã‚ªãƒƒã‚ºä»¥ä¸Šã§è²·ã„ï¼‰"

note_text = (
    f"ç«¶è¼ªå ´ã€€{track}{race_no}R\n"
    f"å±•é–‹è©•ä¾¡ï¼š{confidence}\n"
    f"{race_time}ã€€{race_class}\n"
    f"ãƒ©ã‚¤ãƒ³ã€€{line_text}\n"
    f"ã‚¹ã‚³ã‚¢é †ï¼ˆSBãªã—ï¼‰ã€€{score_order_text}\n"
    f"{marks_line}\n"
    f"\n"
    f"{txt_trioC}\n\n"
    f"{txt_st}\n\n"
    f"{txt_wide}\n\n"
    f"{txt_qn}\n\n"
    f"{txt_ex}\n"
    f"\nï¼ˆâ€»â€œå¯¾è±¡å¤–â€ï¼Pãƒ•ãƒ­ã‚¢æœªæº€ã€‚ã©ã‚“ãªã‚ªãƒƒã‚ºã§ã‚‚è²·ã‚ãªã„ï¼‰\n"
    f"{wide_rule_note}"
)

st.text_area("ã“ã“ã‚’é¸æŠã—ã¦ã‚³ãƒ”ãƒ¼", note_text, height=380)
