    # -*- coding: utf-8 -*-
import streamlit as st
import pandas as pd
import numpy as np   # â† ã“ã“ï¼NumPy ã‚’ np ã«ã™ã‚‹
import unicodedata, re
import math, json, requests
from statistics import mean, pstdev
from itertools import combinations
from datetime import datetime, date, time, timedelta, timezone

# ==============================
# ãƒšãƒ¼ã‚¸è¨­å®š
# ==============================
st.set_page_config(page_title="ãƒ´ã‚§ãƒ­ãƒ“ï¼šç´šåˆ¥Ã—æ—¥ç¨‹ãƒ€ã‚¤ãƒŠãƒŸã‚¯ã‚¹ï¼ˆ5ã€œ9è»Šãƒ»è²·ã„ç›®ä»˜ã / çµ±åˆç‰ˆï¼‰", layout="wide")

# ==============================
# â˜… æ–°è¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆåå·®å€¤ï¼†æ¨å¥¨ãƒ­ã‚¸ãƒƒã‚¯ï¼‰
# ==============================
HEN_W_SB   = 0.20   # SBé‡ã¿
HEN_W_PROF = 0.30   # è„šè³ªé‡ã¿
HEN_W_IN   = 0.50   # å…¥ç€é‡ã¿ï¼ˆç¸®ç´„3ç€å†…ç‡ï¼‰
HEN_DEC_PLACES = 1  # åå·®å€¤ å°æ•°ä¸€æ¡

HEN_THRESHOLD = 55.0     # åå·®å€¤ã‚¯ãƒªã‚¢é–¾å€¤
HEN_STRONG_ONE = 60.0    # å˜ç‹¬å¼·è€…ã®ç›®å®‰

MAX_TICKETS = 6          # è²·ã„ç›®æœ€å¤§ç‚¹æ•°

# æ¨å¥¨ãƒ©ãƒ™ãƒ«åˆ¤å®šç”¨ï¼ˆã‚¯ãƒªã‚¢å°æ•°â†’æ–¹é‡ï¼‰
# k>=5:ã€Œ2è»Šè¤‡ãƒ»ãƒ¯ã‚¤ãƒ‰ã€ä¸­å¿ƒï¼ˆåºƒãï¼‰ / k=3,4:ã€Œ3é€£è¤‡ã€ / k=1,2:ã€ŒçŠ¶æ³æ¬¡ç¬¬ï¼ˆè»¸æµã—å¯„ã‚Šï¼‰ã€ / k=0:ã‚±ãƒ³
LABEL_MAP = {
    "wide_qn": lambda k: k >= 5,
    "trio":    lambda k: 3 <= k <= 4,
    "axis":    lambda k: k in (1,2),
    "ken":     lambda k: k == 0,
}

# æœŸå¾…å€¤ãƒ¬ãƒ³ã‚¸ï¼ˆå†…éƒ¨åŸºæº–ã§ä½¿ç”¨å¯ã€‚ç”»é¢éè¡¨ç¤ºï¼‰
P_FLOOR = {"sanpuku": 0.06, "nifuku": 0.12, "wide": 0.25, "nitan": 0.07, "santan": 0.03}
E_MIN, E_MAX = 0.10, 0.60

# ==============================
# æ—¢å­˜ï¼šé¢¨ãƒ»ä¼šå ´ãƒ»ãƒã‚¹ã‚¿
# ==============================
WIND_COEFF = {
    "å·¦ä¸Š": -0.03, "ä¸Š": -0.05, "å³ä¸Š": -0.035,
    "å·¦": +0.05,  "å³": -0.05,
    "å·¦ä¸‹": +0.035, "ä¸‹": +0.05, "å³ä¸‹": +0.035,
    "ç„¡é¢¨": 0.0
}
WIND_MODE = "speed_only"
WIND_SIGN = -1
WIND_GAIN = 3.0
WIND_CAP  = 0.10
WIND_ZERO = 1.5
SPECIAL_DIRECTIONAL_VELODROMES = {"å¼¥å½¦", "å‰æ©‹"}

SESSION_HOUR = {"ãƒ¢ãƒ¼ãƒ‹ãƒ³ã‚°": 8, "ãƒ‡ã‚¤": 11, "ãƒŠã‚¤ã‚¿ãƒ¼": 18, "ãƒŸãƒƒãƒ‰ãƒŠã‚¤ãƒˆ": 22}
JST = timezone(timedelta(hours=9))

BASE_BY_KAKU = {"é€ƒ":1.58, "æ²":1.65, "å·®":1.79, "ãƒ":1.45}

KEIRIN_DATA = {
    "å‡½é¤¨":{"bank_angle":30.6,"straight_length":51.3,"bank_length":400},
    "é’æ£®":{"bank_angle":32.3,"straight_length":58.9,"bank_length":400},
    "ã„ã‚ãå¹³":{"bank_angle":32.9,"straight_length":62.7,"bank_length":400},
    "å¼¥å½¦":{"bank_angle":32.4,"straight_length":63.1,"bank_length":400},
    "å‰æ©‹":{"bank_angle":36.0,"straight_length":46.7,"bank_length":335},
    "å–æ‰‹":{"bank_angle":31.5,"straight_length":54.8,"bank_length":400},
    "å®‡éƒ½å®®":{"bank_angle":25.8,"straight_length":63.3,"bank_length":500},
    "å¤§å®®":{"bank_angle":26.3,"straight_length":66.7,"bank_length":500},
    "è¥¿æ­¦åœ’":{"bank_angle":29.4,"straight_length":47.6,"bank_length":400},
    "äº¬ç‹é–£":{"bank_angle":32.2,"straight_length":51.5,"bank_length":400},
    "ç«‹å·":{"bank_angle":31.2,"straight_length":58.0,"bank_length":400},
    "æ¾æˆ¸":{"bank_angle":29.8,"straight_length":38.2,"bank_length":333},
    "å·å´":{"bank_angle":32.2,"straight_length":58.0,"bank_length":400},
    "å¹³å¡š":{"bank_angle":31.5,"straight_length":54.2,"bank_length":400},
    "å°ç”°åŸ":{"bank_angle":35.6,"straight_length":36.1,"bank_length":333},
    "ä¼Šæ±":{"bank_angle":34.7,"straight_length":46.6,"bank_length":333},
    "é™å²¡":{"bank_angle":30.7,"straight_length":56.4,"bank_length":400},
    "åå¤å±‹":{"bank_angle":34.0,"straight_length":58.8,"bank_length":400},
    "å²é˜œ":{"bank_angle":32.3,"straight_length":59.3,"bank_length":400},
    "å¤§å£":{"bank_angle":30.6,"straight_length":56.0,"bank_length":400},
    "è±Šæ©‹":{"bank_angle":33.8,"straight_length":60.3,"bank_length":400},
    "å¯Œå±±":{"bank_angle":33.7,"straight_length":43.0,"bank_length":333},
    "æ¾å‚":{"bank_angle":34.4,"straight_length":61.5,"bank_length":400},
    "å››æ—¥å¸‚":{"bank_angle":32.3,"straight_length":62.4,"bank_length":400},
    "ç¦äº•":{"bank_angle":31.5,"straight_length":52.8,"bank_length":400},
    "å¥ˆè‰¯":{"bank_angle":33.4,"straight_length":38.0,"bank_length":333},
    "å‘æ—¥ç”º":{"bank_angle":30.5,"straight_length":47.3,"bank_length":400},
    "å’Œæ­Œå±±":{"bank_angle":32.3,"straight_length":59.9,"bank_length":400},
    "å²¸å’Œç”°":{"bank_angle":30.9,"straight_length":56.7,"bank_length":400},
    "ç‰é‡":{"bank_angle":30.6,"straight_length":47.9,"bank_length":400},
    "åºƒå³¶":{"bank_angle":30.8,"straight_length":57.9,"bank_length":400},
    "é˜²åºœ":{"bank_angle":34.7,"straight_length":42.5,"bank_length":333},
    "é«˜æ¾":{"bank_angle":33.3,"straight_length":54.8,"bank_length":400},
    "å°æ¾å³¶":{"bank_angle":29.8,"straight_length":55.5,"bank_length":400},
    "é«˜çŸ¥":{"bank_angle":24.5,"straight_length":52.0,"bank_length":500},
    "æ¾å±±":{"bank_angle":34.0,"straight_length":58.6,"bank_length":400},
    "å°å€‰":{"bank_angle":34.0,"straight_length":56.9,"bank_length":400},
    "ä¹…ç•™ç±³":{"bank_angle":31.5,"straight_length":50.7,"bank_length":400},
    "æ­¦é›„":{"bank_angle":32.0,"straight_length":64.4,"bank_length":400},
    "ä½ä¸–ä¿":{"bank_angle":31.5,"straight_length":40.2,"bank_length":400},
    "åˆ¥åºœ":{"bank_angle":33.7,"straight_length":59.9,"bank_length":400},
    "ç†Šæœ¬":{"bank_angle":34.3,"straight_length":60.3,"bank_length":400},
    "æ‰‹å…¥åŠ›":{"bank_angle":30.0,"straight_length":52.0,"bank_length":400},
}
VELODROME_MASTER = {
    "å‡½é¤¨":{"lat":41.77694,"lon":140.76283,"home_azimuth":None},
    "é’æ£®":{"lat":40.79717,"lon":140.66469,"home_azimuth":None},
    "ã„ã‚ãå¹³":{"lat":37.04533,"lon":140.89150,"home_azimuth":None},
    "å¼¥å½¦":{"lat":37.70778,"lon":138.82886,"home_azimuth":None},
    "å‰æ©‹":{"lat":36.39728,"lon":139.05778,"home_azimuth":None},
    "å–æ‰‹":{"lat":35.90175,"lon":140.05631,"home_azimuth":None},
    "å®‡éƒ½å®®":{"lat":36.57197,"lon":139.88281,"home_azimuth":None},
    "å¤§å®®":{"lat":35.91962,"lon":139.63417,"home_azimuth":None},
    "è¥¿æ­¦åœ’":{"lat":35.76983,"lon":139.44686,"home_azimuth":None},
    "äº¬ç‹é–£":{"lat":35.64294,"lon":139.53372,"home_azimuth":None},
    "ç«‹å·":{"lat":35.70214,"lon":139.42300,"home_azimuth":None},
    "æ¾æˆ¸":{"lat":35.80417,"lon":139.91119,"home_azimuth":None},
    "å·å´":{"lat":35.52844,"lon":139.70944,"home_azimuth":None},
    "å¹³å¡š":{"lat":35.32547,"lon":139.36342,"home_azimuth":None},
    "å°ç”°åŸ":{"lat":35.25089,"lon":139.14947,"home_azimuth":None},
    "ä¼Šæ±":{"lat":34.954667,"lon":139.092639,"home_azimuth":None},
    "é™å²¡":{"lat":34.973722,"lon":138.419417,"home_azimuth":None},
    "åå¤å±‹":{"lat":35.175560,"lon":136.854028,"home_azimuth":None},
    "å²é˜œ":{"lat":35.414194,"lon":136.783917,"home_azimuth":None},
    "å¤§å£":{"lat":35.361389,"lon":136.628444,"home_azimuth":None},
    "è±Šæ©‹":{"lat":34.770167,"lon":137.417250,"home_azimuth":None},
    "å¯Œå±±":{"lat":36.757250,"lon":137.234833,"home_azimuth":None},
    "æ¾å‚":{"lat":34.564611,"lon":136.533833,"home_azimuth":None},
    "å››æ—¥å¸‚":{"lat":34.965389,"lon":136.634500,"home_azimuth":None},
    "ç¦äº•":{"lat":36.066889,"lon":136.253722,"home_azimuth":None},
    "å¥ˆè‰¯":{"lat":34.681111,"lon":135.823083,"home_azimuth":None},
    "å‘æ—¥ç”º":{"lat":34.949222,"lon":135.708389,"home_azimuth":None},
    "å’Œæ­Œå±±":{"lat":34.228694,"lon":135.171833,"home_azimuth":None},
    "å²¸å’Œç”°":{"lat":34.477500,"lon":135.369389,"home_azimuth":None},
    "ç‰é‡":{"lat":34.497333,"lon":133.961389,"home_azimuth":None},
    "åºƒå³¶":{"lat":34.359778,"lon":132.502889,"home_azimuth":None},
    "é˜²åºœ":{"lat":34.048778,"lon":131.568611,"home_azimuth":None},
    "é«˜æ¾":{"lat":34.345936,"lon":134.061994,"home_azimuth":None},
    "å°æ¾å³¶":{"lat":34.005667,"lon":134.594556,"home_azimuth":None},
    "é«˜çŸ¥":{"lat":33.566694,"lon":133.526083,"home_azimuth":None},
    "æ¾å±±":{"lat":33.808889,"lon":132.742333,"home_azimuth":None},
    "å°å€‰":{"lat":33.885722,"lon":130.883167,"home_azimuth":None},
    "ä¹…ç•™ç±³":{"lat":33.316667,"lon":130.547778,"home_azimuth":None},
    "æ­¦é›„":{"lat":33.194083,"lon":130.023083,"home_azimuth":None},
    "ä½ä¸–ä¿":{"lat":33.161667,"lon":129.712833,"home_azimuth":None},
    "åˆ¥åºœ":{"lat":33.282806,"lon":131.460472,"home_azimuth":None},
    "ç†Šæœ¬":{"lat":32.789167,"lon":130.754722,"home_azimuth":None},
    "æ‰‹å…¥åŠ›":{"lat":None,"lon":None,"home_azimuth":None},
}

# --- æœ€æ–°ã®å°åˆ¥å®Ÿæ¸¬ç‡ï¼ˆ2025/09/25ç‰ˆï¼šç”»åƒåæ˜ æ¸ˆï¼‰ -----------------
# === ãƒ©ãƒ³ã‚¯åˆ¥çµ±è¨ˆãƒ‡ãƒ¼ã‚¿ æœ€æ–°ç‰ˆ (2025/9/28) ===

# --- å…¨ä½“ ---
RANK_STATS_TOTAL = {
    "â—": {"p1": 0.364, "pTop2": 0.539, "pTop3": 0.641},
    "ã€‡": {"p1": 0.157, "pTop2": 0.364, "pTop3": 0.516},
    "â–²": {"p1": 0.143, "pTop2": 0.309, "pTop3": 0.484},
    "â–³": {"p1": 0.101, "pTop2": 0.258, "pTop3": 0.475},
    "Ã—": {"p1": 0.083, "pTop2": 0.198, "pTop3": 0.332},
    "Î±": {"p1": 0.101, "pTop2": 0.198, "pTop3": 0.304},
    "ç„¡": {"p1": 0.046, "pTop2": 0.113, "pTop3": 0.218},
}

# --- F2ï¼ˆæœ€æ–° 9/28ï¼‰ ---
RANK_STATS_F2 = {
    "â—": {"p1": 0.358, "pTop2": 0.540, "pTop3": 0.637},
    "ã€‡": {"p1": 0.163, "pTop2": 0.358, "pTop3": 0.493},
    "â–²": {"p1": 0.144, "pTop2": 0.312, "pTop3": 0.484},
    "â–³": {"p1": 0.102, "pTop2": 0.288, "pTop3": 0.521},
    "Ã—": {"p1": 0.084, "pTop2": 0.209, "pTop3": 0.335},
    "Î±": {"p1": 0.098, "pTop2": 0.149, "pTop3": 0.274},
    "ç„¡": {"p1": 0.050, "pTop2": 0.139, "pTop3": 0.257},
}


# --- F1 ---
RANK_STATS_F1 = {
    "â—": {"p1": 0.278, "pTop2": 0.444, "pTop3": 0.556},
    "ã€‡": {"p1": 0.185, "pTop2": 0.370, "pTop3": 0.574},
    "â–²": {"p1": 0.167, "pTop2": 0.315, "pTop3": 0.463},
    "â–³": {"p1": 0.111, "pTop2": 0.259, "pTop3": 0.407},
    "Ã—": {"p1": 0.111, "pTop2": 0.204, "pTop3": 0.370},
    "Î±": {"p1": 0.093, "pTop2": 0.278, "pTop3": 0.407},
    "ç„¡": {"p1": 0.057, "pTop2": 0.132, "pTop3": 0.226},
}

# --- G ---
RANK_STATS_G = {
    "â—": {"p1": 0.278, "pTop2": 0.500, "pTop3": 0.556},
    "ã€‡": {"p1": 0.111, "pTop2": 0.167, "pTop3": 0.222},
    "â–²": {"p1": 0.111, "pTop2": 0.222, "pTop3": 0.333},
    "â–³": {"p1": 0.167, "pTop2": 0.278, "pTop3": 0.444},
    "Ã—": {"p1": 0.111, "pTop2": 0.167, "pTop3": 0.222},
    "Î±": {"p1": 0.111, "pTop2": 0.222, "pTop3": 0.278},
    "ç„¡": {"p1": 0.040, "pTop2": 0.160, "pTop3": 0.340},
}

# --- ã‚¬ãƒ¼ãƒ«ã‚ºï¼ˆLç´šï¼‰ ---
RANK_STATS_GIRLS = {
    "â—": {"p1": 0.583, "pTop2": 0.667, "pTop3": 0.833},
    "ã€‡": {"p1": 0.167, "pTop2": 0.750, "pTop3": 0.833},
    "â–²": {"p1": 0.167, "pTop2": 0.250, "pTop3": 0.583},
    "â–³": {"p1": 0.083, "pTop2": 0.083, "pTop3": 0.250},
    "Ã—": {"p1": 0.000, "pTop2": 0.083, "pTop3": 0.250},
    "Î±": {"p1": 0.000, "pTop2": 0.167, "pTop3": 0.250},
    "ç„¡": {"p1": 0.000, "pTop2": 0.000, "pTop3": 0.000},
}



# --- ã‚°ãƒ¬ãƒ¼ãƒ‰é€£å‹•ç”¨ãƒãƒƒãƒ— ---
RANK_STATS_BY_GRADE = {
    "TOTAL":  RANK_STATS_TOTAL,
    "F2":     RANK_STATS_F2,
    "F1":     RANK_STATS_F1,
    "G":      RANK_STATS_G,
    "GIRLS":  RANK_STATS_GIRLS,
}

# äº’æ›: æ—§ã‚³ãƒ¼ãƒ‰ãŒå‚ç…§ã™ã‚‹ RANK_STATS ã¯ TOTAL ã‚’æŒ‡ã™
RANK_STATS = RANK_STATS_TOTAL

RANK_FALLBACK_MARK = "â–³"
if RANK_FALLBACK_MARK not in RANK_STATS:
    RANK_FALLBACK_MARK = next(iter(RANK_STATS.keys()))
FALLBACK_DIST = RANK_STATS.get(RANK_FALLBACK_MARK, {"p1": 0.15, "pTop2": 0.30, "pTop3": 0.45})



# KO(å‹ã¡ä¸ŠãŒã‚Š)é–¢é€£
KO_GIRLS_SCALE = 0.0
KO_HEADCOUNT_SCALE = {5:0.6, 6:0.8, 7:1.0, 8:1.0, 9:1.0}
KO_GAP_DELTA = 0.007   # 0.010 â†’ 0.007
KO_STEP_SIGMA = 0.35   # 0.4 â†’ 0.35


# â—ãƒ©ã‚¤ãƒ³æ ¼ä¸Šã’
LINE_BONUS_ON_TENKAI = {"å„ªä½"}
LINE_BONUS = {"second": 0.08, "thirdplus": 0.04}
LINE_BONUS_CAP = 0.10
PROB_U = {"second": 0.00, "thirdplus": 0.00}

# --- å®‰å®šåº¦ï¼ˆç€é †åˆ†å¸ƒï¼‰ã‚’Tæœ¬ä½“ã«å…¥ã‚Œã‚‹ãŸã‚ã®é‡ã¿ ---
STAB_W_IN3  = 0.10   # 3ç€å†…ç‡ã®é‡ã¿
STAB_W_OUT  = 0.12   # ç€å¤–ç‡ã®é‡ã¿ï¼ˆãƒã‚¤ãƒŠã‚¹è£œæ­£ï¼‰
STAB_W_LOWN = 0.05   # ã‚µãƒ³ãƒ—ãƒ«ä¸è¶³è£œæ­£
STAB_PRIOR_IN3 = 0.33
STAB_PRIOR_OUT = 0.45
def _stab_n0(n: int) -> int:
    """ã‚µãƒ³ãƒ—ãƒ«ä¸è¶³æ™‚ã®äº‹å‰åˆ†å¸ƒã®å¼·ã•ï¼ˆnãŒå°ã•ã„ã»ã©å¼·ãåŠ¹ã‹ã›ã‚‹ï¼‰"""
    if n <= 6: return 12
    if n <= 14: return 8
    if n <= 29: return 5
    return 3
# ==============================
# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
# ==============================
def clamp(x,a,b): return max(a, min(b, x))

def zscore_list(arr):
    arr = np.array(arr, dtype=float)
    m, s = float(np.mean(arr)), float(np.std(arr))
    return np.zeros_like(arr) if s==0 else (arr-m)/s

def zscore_val(x, xs):
    xs = np.array(xs, dtype=float); m, s = float(np.mean(xs)), float(np.std(xs))
    return 0.0 if s==0 else (float(x)-m)/s

def t_score_from_finite(values: np.ndarray, eps: float = 1e-9):
    """NaNã‚’é™¤ã„ãŸæ¯é›†å›£ã§T=50+10*(x-Î¼)/Ïƒã‚’ä½œã‚Šã€NaNã¯50ã«ç½®æ›ã—ã¦è¿”ã™"""
    v = values.astype(float, copy=True)
    finite = np.isfinite(v)
    k = int(finite.sum())
    if k < 2:
        return np.full_like(v, 50.0), (float("nan") if k==0 else float(v[finite][0])), 0.0, k
    mu = float(np.mean(v[finite]))
    sd = float(np.std(v[finite], ddof=0))
    if (not np.isfinite(sd)) or sd < eps:
        return np.full_like(v, 50.0), mu, 0.0, k
    T = 50.0 + 10.0 * ((v - mu) / sd)
    T[~finite] = 50.0
    return T, mu, sd, k

def extract_car_list(s, nmax):
    s = str(s or "").strip()
    return [int(c) for c in s if c.isdigit() and 1 <= int(c) <= nmax]

def build_line_maps(lines):
    labels = "ABCDEFG"
    line_def = {labels[i]: lst for i,lst in enumerate(lines) if lst}
    car_to_group = {c:g for g,mem in line_def.items() for c in mem}
    return line_def, car_to_group

def role_in_line(car, line_def):
    for g, mem in line_def.items():
        if car in mem:
            if len(mem)==1: return 'single'
            idx = mem.index(car)
            return ['head','second','thirdplus'][idx] if idx<3 else 'thirdplus'
    return 'single'

# å˜é¨ã‚’å…¨ä½“çš„ã«æŠ‘ãˆã‚‹å…±é€šä¿‚æ•°ï¼ˆã‚ã¨ã§ã„ã˜ã‚Œã‚‹ã‚ˆã†ã«ã™ã‚‹ï¼‰
SINGLE_NERF = float(globals().get("SINGLE_NERF", 0.85))  # 0.80ã€œ0.88ãã‚‰ã„ã§èª¿æ•´

def pos_coeff(role, line_factor):
    base_map = {
        'head':      1.00,
        'second':    0.72,   # 0.70â†’0.72ã«å°‘ã—ä¸Šã’ã¦ãƒ©ã‚¤ãƒ³2ç•ªæ‰‹ã‚’ã¡ã‚ƒã‚“ã¨è©•ä¾¡
        'thirdplus': 0.55,
        'single':    0.52,   # 0.90 â†’ 0.52 ã«ãƒ‰ãƒ³ã¨è½ã¨ã™
    }
    base = base_map.get(role, 0.52)
    if role == 'single':
        base *= SINGLE_NERF      # ã“ã“ã§ã•ã‚‰ã«ç´°ã‹ãè½ã¨ã›ã‚‹
    return base * line_factor


def tenscore_correction(tenscores):
    n = len(tenscores)
    if n<=2: return [0.0]*n
    df = pd.DataFrame({"å¾—ç‚¹":tenscores})
    df["é †ä½"] = df["å¾—ç‚¹"].rank(ascending=False, method="min").astype(int)
    hi = min(n,8)
    baseline = df[df["é †ä½"].between(2,hi)]["å¾—ç‚¹"].mean()
    def corr(row):
        return round(abs(baseline-row["å¾—ç‚¹"])*0.03, 3) if row["é †ä½"] in [2,3,4] else 0.0
    return df.apply(corr, axis=1).tolist()

def wind_adjust(wind_dir, wind_speed, role, prof_escape):
    s = max(0.0, float(wind_speed))
    WIND_ZERO   = float(globals().get("WIND_ZERO", 0.0))
    WIND_SIGN   = float(globals().get("WIND_SIGN", 1.0))
    WIND_GAIN   = float(globals().get("WIND_GAIN", 1.0))  # 33ã§ã¯åˆ¥å‡¦ç†ã§0.5å€ã«ã—ã¦ãŠãæƒ³å®š
    WIND_CAP    = float(globals().get("WIND_CAP", 0.06))
    WIND_MODE   = globals().get("WIND_MODE", "scalar")
    WIND_COEFF  = globals().get("WIND_COEFF", {})
    SPECIAL_DIRECTIONAL_VELODROMES = globals().get("SPECIAL_DIRECTIONAL_VELODROMES", set())
    s_state_track = None
    try:
        s_state_track = st.session_state.get("track", "")
    except Exception:
        pass

    if s <= WIND_ZERO:
        base = 0.0
    elif s <= 5.0:
        base = 0.006 * (s - WIND_ZERO)
    elif s <= 8.0:
        base = 0.021 + 0.008 * (s - 5.0)
    else:
        base = 0.045 + 0.010 * min(s - 8.0, 4.0)

    pos = {'head':1.00,'second':0.85,'single':0.75,'thirdplus':0.65}.get(role, 0.75)
    prof = 0.35 + 0.65*float(prof_escape)
    val = base * pos * prof

    if (WIND_MODE == "directional") or (s >= 7.0 and s_state_track in SPECIAL_DIRECTIONAL_VELODROMES):
        wd = WIND_COEFF.get(wind_dir, 0.0)
        dir_term = clamp(s * wd * (0.30 + 0.70*float(prof_escape)) * 0.6, -0.03, 0.03)
        val += dir_term

    val = (val * float(WIND_SIGN)) * float(WIND_GAIN)
    return round(clamp(val, -float(WIND_CAP), float(WIND_CAP)), 3)


# === ç›´ç·šãƒ©ã‚¹ãƒˆ200mï¼ˆæ®‹è„šï¼‰è£œæ­£ï½œ33ãƒãƒ³ã‚¯å¯¾å¿œç‰ˆ ==============================
# 33ï¼ˆ<=340mï¼‰ã¯ã€Œå…ˆè¡ŒãƒšãƒŠå¼±ã‚ï¼å·®ã—ãƒ»è¿½è¾¼ãƒœãƒ¼ãƒŠã‚¹æ§ãˆã‚ã€ã¸æœ€é©åŒ–
L200_ESC_PENALTY = float(globals().get("L200_ESC_PENALTY", -0.06))  # å…ˆè¡Œã¯å‚ã‚Œã‚„ã™ã„ï¼ˆåŸºæœ¬ï¼‰
L200_SASHI_BONUS = float(globals().get("L200_SASHI_BONUS", +0.03))  # å·®ã—ã¯ä¼¸ã³ã‚„ã™ã„
L200_MARK_BONUS  = float(globals().get("L200_MARK_BONUS",  +0.02))  # è¿½è¾¼ã¯å°‘ã—ä¸Šã’

L200_GRADE_GAIN  = globals().get("L200_GRADE_GAIN", {
    "F2": 1.18, "F1": 1.10, "G": 1.05, "GIRLS": 0.95, "TOTAL": 1.00
})

# çŸ­èµ°è·¯å¢—å¹…ï¼šæ—§1.15 â†’ 33ã¯ã‚€ã—ã‚ç·©å’Œï¼ˆ0.85ï¼‰
L200_SHORT_GAIN_33   = float(globals().get("L200_SHORT_GAIN_33", 0.85))
L200_SHORT_GAIN_OTH  = float(globals().get("L200_SHORT_GAIN_OTH", 1.00))
L200_LONG_RELAX      = float(globals().get("L200_LONG_RELAX", 0.90))
L200_CAP             = float(globals().get("L200_CAP", 0.08))
L200_WET_GAIN        = float(globals().get("L200_WET_GAIN", 1.15))

# 33å°‚ç”¨ æˆåˆ†åˆ¥ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
L200_33_ESC_MULT   = float(globals().get("L200_33_ESC_MULT", 0.80))  # é€ƒãƒšãƒŠ 20%ç¸®å°
L200_33_SASHI_MULT = float(globals().get("L200_33_SASHI_MULT", 0.85))# å·®ã—  15%ç¸®å°
L200_33_MARK_MULT  = float(globals().get("L200_33_MARK_MULT", 0.90)) # è¿½è¾¼  10%ç¸®å°

def _grade_key_from_class(race_class: str) -> str:
    if "ã‚¬ãƒ¼ãƒ«" in race_class: return "GIRLS"
    if "ï¼³ç´š" in race_class or "Sç´š" in race_class: return "G"
    if "ãƒãƒ£ãƒ¬ãƒ³ã‚¸" in race_class: return "F2"
    if "ï¼¡ç´š" in race_class or "Aç´š" in race_class: return "F1"
    return "TOTAL"

def l200_adjust(role: str,
                straight_length: float,
                bank_length: float,
                race_class: str,
                prof_escape: float,    # é€ƒ
                prof_sashi: float,     # å·®
                prof_oikomi: float,    # ãƒ
                is_wet: bool = False) -> float:
    """
    ãƒ©ã‚¹ãƒˆ200mã®â€œæ®‹è„šâ€ã‚’è„šè³ªÃ—ãƒãƒ³ã‚¯Ã—ã‚°ãƒ¬ãƒ¼ãƒ‰ã§èª¿æ•´ã—ãŸç„¡æ¬¡å…ƒå€¤ï¼ˆÂ±ï¼‰ã‚’è¿”ã™ã€‚
    â€» ENVåˆè¨ˆï¼ˆtotal_rawï¼‰ã«ã¯è¶³ã•ãšã€ç‹¬ç«‹æŸ±ã¨ã—ã¦ z åŒ–â†’anchor_score ã¸ã€‚
    """
    esc_term   = L200_ESC_PENALTY * float(prof_escape)
    sashi_term = L200_SASHI_BONUS * float(prof_sashi)
    mark_term  = L200_MARK_BONUS  * float(prof_oikomi)

    is_33 = float(bank_length) <= 340.0
    if is_33:
        esc_term   *= L200_33_ESC_MULT
        sashi_term *= L200_33_SASHI_MULT
        mark_term  *= L200_33_MARK_MULT

    base = esc_term + sashi_term + mark_term

    if is_33:
        base *= L200_SHORT_GAIN_33
    else:
        base *= L200_SHORT_GAIN_OTH

    if float(straight_length) >= 60.0:
        base *= L200_LONG_RELAX

    base *= float(L200_GRADE_GAIN.get(_grade_key_from_class(race_class), 1.0))

    if is_wet:
        base *= L200_WET_GAIN

    pos_factor = {'head':1.00,'second':0.85,'thirdplus':0.70,'single':0.80}.get(role, 0.80)
    base *= pos_factor

    return round(clamp(base, -float(L200_CAP), float(L200_CAP)), 3)


def bank_character_bonus(bank_angle, straight_length, prof_escape, prof_sashi):
    straight_factor = (float(straight_length)-40.0)/10.0
    angle_factor = (float(bank_angle)-25.0)/5.0
    total = clamp(-0.1*straight_factor + 0.1*angle_factor, -0.05, 0.05)
    return round(total*prof_escape - 0.5*total*prof_sashi, 3)

def bank_length_adjust(bank_length, prof_oikomi):
    delta = clamp((float(bank_length)-411.0)/100.0, -0.05, 0.05)
    return round(delta*prof_oikomi, 3)

# --- ãƒ©ã‚¤ãƒ³SBãƒœãƒ¼ãƒŠã‚¹ï¼ˆ33mã¯è‡ªå‹•ã§åŠæ¸›ï¼‰ --------------------
def compute_lineSB_bonus(line_def, S, B, line_factor=1.0, exclude=None, cap=0.06, enable=True):
    """
    33mç³»ï¼ˆ<=340ï¼‰ã§ã¯è‡ªå‹•ã§åŠ¹ãã‚’åŠæ¸›:
      - LINE_SB_33_MULTï¼ˆæ—¢å®š0.5ï¼‰ã‚’ line_factor ã«ä¹—ç®—
      - LINE_SB_CAP_33_MULTï¼ˆæ—¢å®š0.5ï¼‰ã‚’ cap ã«ä¹—ç®—
    """
    if not enable or not line_def:
        return ({g: 0.0 for g in line_def.keys()} if line_def else {}), {}

    # 33ã‹ã©ã†ã‹ã®è‡ªå‹•æ¨å®š
    try:
        bank_len = st.session_state.get("bank_length", st.session_state.get("track_length", None))
    except Exception:
        bank_len = globals().get("BANK_LENGTH", None)

    eff_line_factor = float(line_factor)
    eff_cap = float(cap)

    if bank_len is not None:
        try:
            if float(bank_len) <= 340.0:
                mult = float(globals().get("LINE_SB_33_MULT", 0.50))
                capm = float(globals().get("LINE_SB_CAP_33_MULT", 0.50))
                eff_line_factor *= mult
                eff_cap *= capm
        except Exception:
            pass

    # ãƒ©ã‚¤ãƒ³å†…ã®ä½ç½®é‡ã¿ï¼ˆå˜é¨ã‚’ä¸‹ã’ã‚‹ï¼‰
    w_pos_base = {
        "head":      1.00,
        "second":    0.55,
        "thirdplus": 0.38,
        "single":    0.34,
    }

    # ãƒ©ã‚¤ãƒ³ã”ã¨ã®S/Bé›†è¨ˆ
    Sg = {}
    Bg = {}
    for g, mem in line_def.items():
        s = 0.0
        b = 0.0
        for car in mem:
            if exclude is not None and car == exclude:
                continue
            role = role_in_line(car, line_def)
            w = w_pos_base[role] * eff_line_factor
            s += w * float(S.get(car, 0))
            b += w * float(B.get(car, 0))
        Sg[g] = s
        Bg[g] = b

    # ãƒ©ã‚¤ãƒ³ã”ã¨ã®â€œå¼·ã•â€ã‚¹ã‚³ã‚¢
    raw = {}
    for g in line_def.keys():
        s = Sg[g]
        b = Bg[g]
        ratioS = s / (s + b + 1e-6)
        raw[g] = (0.6 * b + 0.4 * s) * (0.6 + 0.4 * ratioS)

    # zåŒ–ã—ã¦ãƒœãƒ¼ãƒŠã‚¹åŒ–
    zz = zscore_list(list(raw.values())) if raw else []
    bonus = {}
    for i, g in enumerate(raw.keys()):
        bonus[g] = clamp(0.02 * float(zz[i]), -eff_cap, eff_cap)

    return bonus, raw


# ==============================
# KO Utilitiesï¼ˆã“ã“ã‹ã‚‰ä¸‹ã‚’1ã‹ãŸã¾ã‚Šã§ï¼‰
# ==============================

def _role_of(car, mem):
    """ãƒ©ã‚¤ãƒ³ã®ä¸­ã§ã®å½¹å‰²ã‚’è¿”ã™ï¼ˆhead / second / thirdplus / singleï¼‰"""
    if len(mem) == 1:
        return "single"
    idx = mem.index(car)
    return ["head", "second", "thirdplus"][idx] if idx < 3 else "thirdplus"


# KOã§ã‚‚ã€ãƒ©ã‚¤ãƒ³å¼·åº¦ã§ã‚‚ã€åŒã˜ä½ç½®é‡ã¿ã‚’ä½¿ã†
LINE_W_POS = {
    "head":      1.00,
    "second":    0.55,
    "thirdplus": 0.38,
    "single":    0.34,
}


def _line_strength_raw(line_def, S, B, line_factor: float = 1.0) -> dict:
    """
    KOã‚„ãƒˆãƒƒãƒ—2ãƒ©ã‚¤ãƒ³æŠ½å‡ºã§ä½¿ã†â€œç”Ÿã®ãƒ©ã‚¤ãƒ³å¼·åº¦â€
    compute_lineSB_bonus ã¨å¼ã‚’ãã‚ãˆã¦ã‚ã‚‹
    """
    if not line_def:
        return {}

    w_pos = {k: v * float(line_factor) for k, v in LINE_W_POS.items()}

    raw: dict[str, float] = {}
    for g, mem in line_def.items():
        s = 0.0
        b = 0.0
        for c in mem:
            role = _role_of(c, mem)
            w = w_pos.get(role, 0.34)
            s += w * float(S.get(c, 0))
            b += w * float(B.get(c, 0))
        ratioS = s / (s + b + 1e-6)
        raw[g] = (0.6 * b + 0.4 * s) * (0.6 + 0.4 * ratioS)
    return raw


def _top2_lines(line_def, S, B, line_factor=1.0):
    """ãƒ©ã‚¤ãƒ³ã®ä¸­ã‹ã‚‰å¼·ã„2æœ¬ã‚’å–ã‚‹"""
    raw = _line_strength_raw(line_def, S, B, line_factor)
    order = sorted(raw.keys(), key=lambda g: raw[g], reverse=True)
    return (order[0], order[1]) if len(order) >= 2 else (order[0], None) if order else (None, None)


def _extract_role_car(line_def, gid, role_name):
    """æŒ‡å®šãƒ©ã‚¤ãƒ³ã®head/secondã‚’æŠœã"""
    if gid is None or gid not in line_def:
        return None
    mem = line_def[gid]
    if role_name == "head":
        return mem[0] if len(mem) >= 1 else None
    if role_name == "second":
        return mem[1] if len(mem) >= 2 else None
    return None


def _ko_order(v_base_map,
              line_def,
              S,
              B,
              line_factor: float = 1.0,
              gap_delta: float = 0.007):
    """
    KOç”¨ã®ä¸¦ã³ã‚’ä½œã‚‹
    1) ä¸Š2ãƒ©ã‚¤ãƒ³ã®head
    2) ä¸Š2ãƒ©ã‚¤ãƒ³ã®second
    3) æ®‹ã‚Šã®ãƒ©ã‚¤ãƒ³ã®æ®‹ã‚Šã‚’ã‚¹ã‚³ã‚¢é †
    4) ãã®ä»–ã®è»Šç•ª
    åŒã˜ãƒ©ã‚¤ãƒ³å†…ã§ã‚¹ã‚³ã‚¢å·®ãŒ gap_delta ä»¥å†…ãªã‚‰å¯„ã›ã‚‹
    """
    cars = list(v_base_map.keys())

    # ãƒ©ã‚¤ãƒ³ãŒç„¡ã„ã¨ãã¯ãµã¤ã†ã«ã‚¹ã‚³ã‚¢é †
    if not line_def or len(line_def) < 1:
        return [c for c, _ in sorted(v_base_map.items(), key=lambda x: x[1], reverse=True)]

    g1, g2 = _top2_lines(line_def, S, B, line_factor)

    head1 = _extract_role_car(line_def, g1, "head")
    head2 = _extract_role_car(line_def, g2, "head")
    sec1  = _extract_role_car(line_def, g1, "second")
    sec2  = _extract_role_car(line_def, g2, "second")

    others: list[int] = []
    if g1:
        mem = line_def[g1]
        if len(mem) >= 3:
            others += mem[2:]
    if g2:
        mem = line_def[g2]
        if len(mem) >= 3:
            others += mem[2:]
    for g, mem in line_def.items():
        if g not in {g1, g2}:
            others += mem

    order: list[int] = []

    # 1) headã‚’ã‚¹ã‚³ã‚¢é †ã§
    head_pair = [x for x in [head1, head2] if x is not None]
    order += sorted(head_pair, key=lambda c: v_base_map.get(c, -1e9), reverse=True)

    # 2) secondã‚’ã‚¹ã‚³ã‚¢é †ã§
    sec_pair = [x for x in [sec1, sec2] if x is not None]
    order += sorted(sec_pair, key=lambda c: v_base_map.get(c, -1e9), reverse=True)

    # 3) æ®‹ã‚Šãƒ©ã‚¤ãƒ³ã®æ®‹ã‚Šï¼ˆé‡è¤‡ã‚’è½ã¨ã™ï¼‰
    others = list(dict.fromkeys([c for c in others if c is not None]))
    others_sorted = sorted(others, key=lambda c: v_base_map.get(c, -1e9), reverse=True)
    order += [c for c in others_sorted if c not in order]

    # 4) ã¾ã å‡ºã¦ãªã„è»Šã‚’æœ€å¾Œã«
    for c in cars:
        if c not in order:
            order.append(c)

    # ãƒ©ã‚¤ãƒ³å†…ã®å°å·®è©°ã‚
    def _same_group(a, b):
        if a is None or b is None:
            return False
        ga = next((g for g, mem in line_def.items() if a in mem), None)
        gb = next((g for g, mem in line_def.items() if b in mem), None)
        return ga is not None and ga == gb

    i = 0
    while i < len(order) - 2:
        a, b, c = order[i], order[i + 1], order[i + 2]
        if _same_group(a, b):
            vx = v_base_map.get(b, 0.0) - v_base_map.get(c, 0.0)
            if vx >= -gap_delta:
                order.pop(i + 2)
                order.insert(i + 1, b)
        i += 1

    return order


def _zone_from_p(p: float):
    needed = 1.0 / max(p, 1e-12)
    return needed, needed * (1.0 + E_MIN), needed * (1.0 + E_MAX)


def apply_anchor_line_bonus(score_raw: dict[int, float],
                            line_of: dict[int, int],
                            role_map: dict[int, str],
                            anchor: int,
                            tenkai: str) -> dict[int, float]:
    a_line = line_of.get(anchor, None)
    is_on = (tenkai in LINE_BONUS_ON_TENKAI) and (a_line is not None)
    score_adj: dict[int, float] = {}
    for i, s in score_raw.items():
        bonus = 0.0
        if is_on and line_of.get(i) == a_line and i != anchor:
            role = role_map.get(i, "single")
            bonus = min(max(0.0, LINE_BONUS.get(role, 0.0)), LINE_BONUS_CAP)
        score_adj[i] = s + bonus
    return score_adj


def format_rank_all(score_map: dict[int, float], P_floor_val: float | None = None) -> str:
    order = sorted(score_map.keys(), key=lambda k: (-score_map[k], k))
    rows = []
    for i in order:
        if P_floor_val is None:
            rows.append(f"{i}")
        else:
            rows.append(f"{i}" if score_map[i] >= P_floor_val else f"{i}(Pæœªæº€)")
    return " ".join(rows)



# ==============================
# é¢¨ã®è‡ªå‹•å–å¾—ï¼ˆOpen-Meteo / æ™‚åˆ»å›ºå®šï¼‰
# ==============================
def make_target_dt_naive(jst_date, race_slot: str):
    h = SESSION_HOUR.get(race_slot, 11)
    if isinstance(jst_date, datetime):
        jst_date = jst_date.date()
    try:
        y, m, d = jst_date.year, jst_date.month, jst_date.day
    except Exception:
        dt = pd.to_datetime(str(jst_date))
        y, m, d = dt.year, dt.month, dt.day
    return datetime(y, m, d, h, 0, 0)

def fetch_openmeteo_hour(lat, lon, target_dt_naive):
    import numpy as np
    d = target_dt_naive.strftime("%Y-%m-%d")
    base = "https://api.open-meteo.com/v1/forecast"
    urls = [
        (f"{base}?latitude={lat:.5f}&longitude={lon:.5f}"
         "&hourly=wind_speed_10m,wind_direction_10m"
         "&timezone=Asia%2FTokyo"
         f"&start_date={d}&end_date={d}", True),
        (f"{base}?latitude={lat:.5f}&longitude={lon:.5f}"
         "&hourly=wind_speed_10m"
         "&timezone=Asia%2FTokyo"
         f"&start_date={d}&end_date={d}", False),
        (f"{base}?latitude={lat:.5f}&longitude={lon:.5f}"
         "&hourly=wind_speed_10m,wind_direction_10m"
         "&timezone=Asia%2FTokyo&past_days=2&forecast_days=2", True),
        (f"{base}?latitude={lat:.5f}&longitude={lon:.5f}"
         "&hourly=wind_speed_10m"
         "&timezone=Asia%2FTokyo&past_days=2&forecast_days=2", False),
    ]
    last_err = None
    for url, with_dir in urls:
        try:
            r = requests.get(url, timeout=15)
            r.raise_for_status()
            j = r.json().get("hourly", {})
            times = [datetime.fromisoformat(t) for t in j.get("time", [])]
            if not times: raise RuntimeError("empty hourly times")
            diffs = [abs((t - target_dt_naive).total_seconds()) for t in times]
            k = int(np.argmin(diffs))
            sp = j.get("wind_speed_10m", [])
            di = j.get("wind_direction_10m", []) if with_dir else []
            speed = float(sp[k]) if k < len(sp) else float("nan")
            deg   = (float(di[k]) if with_dir and k < len(di) else None)
            return {"time": times[k], "speed_ms": speed, "deg": deg, "diff_min": diffs[k]/60.0}
        except Exception as e:
            last_err = e
            continue
    raise RuntimeError(f"Open-Meteoå–å¾—å¤±æ•—ï¼ˆæœ€å¾Œã®ã‚¨ãƒ©ãƒ¼: {last_err}ï¼‰")

# ==============================
# ã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼šé–‹å‚¬æƒ…å ± / ãƒãƒ³ã‚¯ãƒ»é¢¨ãƒ»é ­æ•°
# ==============================

# --- ä¼šå ´å·®åˆ†ï¼ˆå¾—æ„ä¼šå ´å¹³å‡ã‚’æ¨™æº–ï¼‰ãƒ˜ãƒ«ãƒ‘ãƒ¼ï¼ˆã“ã®ãƒ–ãƒ­ãƒƒã‚¯å†…ã«è‡ªå·±å®Œçµï¼‰
FAVORABLE_VENUES = ["åå¤å±‹","ã„ã‚ãå¹³","å‰æ©‹","ç«‹å·","å®‡éƒ½å®®","å²¸å’Œç”°","é«˜çŸ¥"]

def _std_from_venues(names):
    Ls = [KEIRIN_DATA[v]["straight_length"] for v in names if v in KEIRIN_DATA]
    Th = [KEIRIN_DATA[v]["bank_angle"]      for v in names if v in KEIRIN_DATA]
    Cs = [KEIRIN_DATA[v]["bank_length"]     for v in names if v in KEIRIN_DATA]
    return (float(np.mean(Th)), float(np.mean(Ls)), float(np.mean(Cs)))

TH_STD, L_STD, C_STD = _std_from_venues(FAVORABLE_VENUES)

_ALL_L = np.array([KEIRIN_DATA[k]["straight_length"] for k in KEIRIN_DATA], float)
_ALL_TH = np.array([KEIRIN_DATA[k]["bank_angle"]      for k in KEIRIN_DATA], float)
SIG_L  = float(np.std(_ALL_L)) if np.std(_ALL_L)>1e-9 else 1.0
SIG_TH = float(np.std(_ALL_TH)) if np.std(_ALL_TH)>1e-9 else 1.0

def venue_z_terms(straight_length: float, bank_angle: float, bank_length: float):
    zL  = (float(straight_length) - L_STD)  / SIG_L
    zTH = (float(bank_angle)      - TH_STD) / SIG_TH
    if bank_length >= 480: dC = +0.4
    elif bank_length >= 380: dC = 0.0
    else: dC = -0.4
    return zL, zTH, dC

def venue_mix(zL, zTH, dC):
    # ç›´ç·šé•·â†‘ï¼å·®ã—/æ²ã‚Šå¯„ã‚Š(âˆ’)ã€ã‚«ãƒ³ãƒˆâ†‘ï¼å…ˆè¡Œ/ã‚¹ãƒ”ãƒ¼ãƒ‰å‹è² (+)ã€333çŸ­å‘¨é•·ï¼ãƒ©ã‚¤ãƒ³å¯„ã‚Š(âˆ’)
    return float(clamp(0.50*zTH - 0.35*zL - 0.30*dC, -1.0, +1.0))


st.sidebar.header("é–‹å‚¬æƒ…å ± / ãƒãƒ³ã‚¯ãƒ»é¢¨ãƒ»é ­æ•°")
n_cars = st.sidebar.selectbox("å‡ºèµ°æ•°ï¼ˆ5ã€œ9ï¼‰", [5,6,7,8,9], index=2)
track_names = list(KEIRIN_DATA.keys())
track = st.sidebar.selectbox("ç«¶è¼ªå ´ï¼ˆãƒ—ãƒªã‚»ãƒƒãƒˆï¼‰", track_names, index=track_names.index("å·å´") if "å·å´" in track_names else 0)
info = KEIRIN_DATA[track]
st.session_state["track"] = track

race_time = st.sidebar.selectbox("é–‹å‚¬åŒºåˆ†", ["ãƒ¢ãƒ¼ãƒ‹ãƒ³ã‚°","ãƒ‡ã‚¤","ãƒŠã‚¤ã‚¿ãƒ¼","ãƒŸãƒƒãƒ‰ãƒŠã‚¤ãƒˆ"], 1)
race_day = st.sidebar.date_input("é–‹å‚¬æ—¥ï¼ˆé¢¨ã®å–å¾—åŸºæº–æ—¥ï¼‰", value=date.today())

wind_dir = st.sidebar.selectbox("é¢¨å‘", ["ç„¡é¢¨","å·¦ä¸Š","ä¸Š","å³ä¸Š","å·¦","å³","å·¦ä¸‹","ä¸‹","å³ä¸‹"], index=0, key="wind_dir_input")
wind_speed_default = st.session_state.get("wind_speed", 3.0)
wind_speed = st.sidebar.number_input("é¢¨é€Ÿ(m/s)", 0.0, 30.0, float(wind_speed_default), 0.1)

with st.sidebar.expander("ğŸŒ€ é¢¨ã‚’APIã§è‡ªå‹•å–å¾—ï¼ˆOpen-Meteoï¼‰", expanded=False):
    api_date = st.date_input("é–‹å‚¬æ—¥ï¼ˆé¢¨ã®å–å¾—åŸºæº–æ—¥ï¼‰", value=pd.to_datetime("today").date(), key="api_date")
    st.caption("åŸºæº–æ™‚åˆ»ï¼šãƒ¢=8æ™‚ / ãƒ‡=11æ™‚ / ãƒŠ=18æ™‚ / ãƒŸ=22æ™‚ï¼ˆJSTãƒ»tzãªã—ã§å–å¾—ï¼‰")
    if st.button("APIã§å–å¾—â†’é¢¨é€Ÿã«åæ˜ ", use_container_width=True):
        info_xy = VELODROME_MASTER.get(track)
        if not info_xy or info_xy.get("lat") is None or info_xy.get("lon") is None:
            st.error(f"{track} ã®åº§æ¨™ãŒæœªç™»éŒ²ã§ã™ï¼ˆVELODROME_MASTER ã« lat/lon ã‚’å…¥ã‚Œã¦ãã ã•ã„ï¼‰")
        else:
            try:
                target = make_target_dt_naive(api_date, race_time)
                data = fetch_openmeteo_hour(info_xy["lat"], info_xy["lon"], target)
                st.session_state["wind_speed"] = round(float(data["speed_ms"]), 2)
                st.success(f"{track} {target:%Y-%m-%d %H:%M} é¢¨é€Ÿ {st.session_state['wind_speed']:.1f} m/s ï¼ˆAPIå´ã¨{data['diff_min']:.0f}åˆ†ã‚ºãƒ¬ï¼‰")
                st.rerun()
            except Exception as e:
                st.error(f"å–å¾—ã«å¤±æ•—ï¼š{e}")

straight_length = st.sidebar.number_input("ã¿ãªã—ç›´ç·š(m)", 30.0, 80.0, float(info["straight_length"]), 0.1)
bank_angle = st.sidebar.number_input("ãƒãƒ³ã‚¯è§’(Â°)", 20.0, 45.0, float(info["bank_angle"]), 0.1)
bank_length = st.sidebar.number_input("å‘¨é•·(m)", 300.0, 500.0, float(info["bank_length"]), 0.1)

base_laps = st.sidebar.number_input("å‘¨å›ï¼ˆé€šå¸¸4ï¼‰", 1, 10, 4, 1)
day_label = st.sidebar.selectbox("é–‹å‚¬æ—¥", ["åˆæ—¥","2æ—¥ç›®","æœ€çµ‚æ—¥"], 0)
eff_laps = int(base_laps) + {"åˆæ—¥":1,"2æ—¥ç›®":2,"æœ€çµ‚æ—¥":3}[day_label]

race_class = st.sidebar.selectbox("ç´šåˆ¥", ["ï¼³ç´š","ï¼¡ç´š","ï¼¡ç´šãƒãƒ£ãƒ¬ãƒ³ã‚¸","ã‚¬ãƒ¼ãƒ«ã‚º"], 0)

# === ä¼šå ´styleã‚’ã€Œå¾—æ„ä¼šå ´å¹³å‡ã€ã‚’åŸºæº–ã«å†å®šç¾©
zL, zTH, dC = venue_z_terms(straight_length, bank_angle, bank_length)
style_raw = venue_mix(zL, zTH, dC)
override = st.sidebar.slider("ä¼šå ´ãƒã‚¤ã‚¢ã‚¹è£œæ­£ï¼ˆâˆ’2å·®ã— â†â†’ +2å…ˆè¡Œï¼‰", -2.0, 2.0, 0.0, 0.1)
style = clamp(style_raw + 0.25*override, -1.0, +1.0)

CLASS_FACTORS = {
    "ï¼³ç´š":           {"spread":1.00, "line":1.00},
    "ï¼¡ç´š":           {"spread":0.90, "line":0.85},
    "ï¼¡ç´šãƒãƒ£ãƒ¬ãƒ³ã‚¸": {"spread":0.80, "line":0.70},
    "ã‚¬ãƒ¼ãƒ«ã‚º":       {"spread":0.85, "line":1.00},
}
cf = CLASS_FACTORS[race_class]

# æ—§ï¼š
# DAY_FACTOR = {"åˆæ—¥":1.00, "2æ—¥ç›®":0.60, "æœ€çµ‚æ—¥":0.85}

# æ–°ï¼ˆã¾ãšã¯å®Œå…¨ãƒ•ãƒ©ãƒƒãƒˆï¼‰ï¼š
DAY_FACTOR = {"åˆæ—¥":1.00, "2æ—¥ç›®":1.00, "æœ€çµ‚æ—¥":1.00}
day_factor = DAY_FACTOR[day_label]

cap_base = clamp(0.06 + 0.02*style, 0.04, 0.08)
line_factor_eff = cf["line"] * day_factor
cap_SB_eff = cap_base * day_factor
if race_time == "ãƒŸãƒƒãƒ‰ãƒŠã‚¤ãƒˆ":
    line_factor_eff *= 0.95
    cap_SB_eff *= 0.95

# ===== æ—¥ç¨‹ãƒ»ç´šåˆ¥ãƒ»é ­æ•°ã§â€œå‘¨å›ç–²åŠ´ã®åŠ¹ãâ€ã‚’è–„ãã‚·ãƒ•ãƒˆï¼ˆå‡ºåŠ›ã«ã¯å‡ºã•ãªã„ï¼‰ =====
DAY_SHIFT = {"åˆæ—¥": -0.5, "2æ—¥ç›®": 0.0, "æœ€çµ‚æ—¥": +0.5}
CLASS_SHIFT = {"ï¼³ç´š": 0.0, "ï¼¡ç´š": +0.10, "ï¼¡ç´šãƒãƒ£ãƒ¬ãƒ³ã‚¸": +0.20, "ã‚¬ãƒ¼ãƒ«ã‚º": -0.10}
HEADCOUNT_SHIFT = {5: -0.20, 6: -0.10, 7: -0.05, 8: 0.0, 9: +0.10}

def fatigue_extra(eff_laps: int, day_label: str, n_cars: int, race_class: str) -> float:
    """
    æ—¢å­˜ã® extra = max(eff_laps - 2, 0) ã‚’ãƒ™ãƒ¼ã‚¹ã«ã€
    ãƒ»æ—¥ç¨‹ã‚·ãƒ•ãƒˆï¼šåˆæ—¥ -0.5ï¼2æ—¥ç›® 0ï¼æœ€çµ‚æ—¥ +0.5
    ãƒ»ç´šåˆ¥ã‚·ãƒ•ãƒˆï¼šAç´š/ãƒãƒ£ãƒ¬ãƒ³ã‚¸ã‚’ã‚„ã‚„é‡ã‚ã€ã‚¬ãƒ¼ãƒ«ã‚ºã¯ã‚„ã‚„è»½ã‚
    ãƒ»é ­æ•°ã‚·ãƒ•ãƒˆï¼š9è»Šã¯å°‘ã—é‡ãã€5ã€œ7è»Šã¯å°‘ã—è»½ã
    """
    d = float(DAY_SHIFT.get(day_label, 0.0))
    c = float(CLASS_SHIFT.get(race_class, 0.0))
    h = float(HEADCOUNT_SHIFT.get(int(n_cars), 0.0))
    x = (float(eff_laps) - 2.0) + d + c + h
    return max(0.0, x)

# === PATCH-L200: ç›´ç·šãƒ©ã‚¹ãƒˆ200mã®æ®‹è„šè£œæ­£ =========================
# ç›®çš„: é€ƒã’å…ˆè¡ŒãŒç›´ç·šã§è‹¦ã—ããªã‚‹å ´é¢ã‚’å°‘ã—ã ã‘æ¸›ç‚¹ã€å·®ã—ãƒ»ãƒãƒ¼ã‚¯ã¯å¾®åŠ ç‚¹ã€‚
# å¼·ã•ã¯ãƒŸãƒƒãƒ‰ãƒŠã‚¤ãƒˆ/çŸ­èµ°è·¯ã§å°‘ã—ã ã‘å¼·ã‚ã«ã€‚

L200_ESC_PENALTY   = -0.06   # é€ƒã’(å…ˆè¡Œ)ã®åŸºç¤ãƒã‚¤ãƒŠã‚¹
L200_SASHI_BONUS   = +0.03   # å·®ã—ã®åŸºç¤ãƒ—ãƒ©ã‚¹
L200_MARK_BONUS    = +0.02   # ãƒãƒ¼ã‚¯(è¿½è¾¼)ã®åŸºç¤ãƒ—ãƒ©ã‚¹
L200_MNIGHT_GAIN   = 1.20    # ãƒŸãƒƒãƒ‰ãƒŠã‚¤ãƒˆã®å€ç‡
L200_SHORT_GAIN    = 1.15    # 333mãªã©çŸ­èµ°è·¯ã®å€ç‡
L200_LONG_RELAX    = 0.90    # ç›´ç·šé•·ã‚ã¯ã‚„ã‚„ç·©å’Œ
L200_CAP           = 0.08    # çµ¶å¯¾å€¤ã‚­ãƒ£ãƒƒãƒ—ï¼ˆå®‰å…¨å¼ï¼‰

def last200_bonus(no: int, role: str) -> float:
    """è„šè³ªÃ—ãƒãƒ³ã‚¯æ¡ä»¶ã‹ã‚‰ãƒ©ã‚¹ãƒˆ200mã®å¾®èª¿æ•´ã‚’è¿”ã™ï¼ˆÂ±0.08ç¨‹åº¦ï¼‰ã€‚"""
    esc   = float(prof_escape.get(no, 0.0))
    sashi = float(prof_sashi.get(no, 0.0))
    mark  = float(prof_oikomi.get(no, 0.0))

    # åŸºç¤ï¼šè„šè³ªãƒŸãƒƒã‚¯ã‚¹
    base = (L200_ESC_PENALTY * esc) + (L200_SASHI_BONUS * sashi) + (L200_MARK_BONUS * mark)

    # ãƒˆãƒ©ãƒƒã‚¯æ¡ä»¶
    gain = 1.0
    if race_time == "ãƒŸãƒƒãƒ‰ãƒŠã‚¤ãƒˆ":
        gain *= L200_MNIGHT_GAIN
    if float(bank_length) <= 360.0:
        gain *= L200_SHORT_GAIN
    if float(straight_length) >= 58.0:
        gain *= L200_LONG_RELAX

    # ä½ç½®ï¼ˆå…ˆé ­ï¼é‡ã‚ã€å¾Œã‚è–„ã‚ï¼‰
    pos_w = {'head': 1.00, 'second': 0.70, 'thirdplus': 0.55, 'single': 0.80}.get(role, 0.80)

    val = base * gain * pos_w
    # ä¼šå ´ãƒã‚¤ã‚¢ã‚¹ï¼ˆstyle>0=å…ˆè¡Œå¯„ã‚Šâ†’æ¸›ç‚¹ã‚’å°‘ã—ç·©ã‚ã‚‹ï¼‰
    val *= (0.95 if style > 0 else 1.05)

    return round(max(-L200_CAP, min(L200_CAP, val)), 3)
# === PATCH-L200: ã“ã“ã¾ã§ ==========================================


line_sb_enable = (race_class != "ã‚¬ãƒ¼ãƒ«ã‚º")

st.sidebar.caption(
    f"ä¼šå ´ã‚¹ã‚¿ã‚¤ãƒ«: {style:+.2f}ï¼ˆraw {style_raw:+.2f}ï¼‰ / "
    f"ç´šåˆ¥: spread={cf['spread']:.2f}, line={cf['line']:.2f} / "
    f"æ—¥ç¨‹ä¿‚æ•°(line)={day_factor:.2f} â†’ lineä¿‚æ•°={line_factor_eff:.2f}, SBcapÂ±{cap_SB_eff:.2f}"
)

# ==============================
# ãƒ¡ã‚¤ãƒ³ï¼šå…¥åŠ›
# ==============================
st.title("â­ ãƒ´ã‚§ãƒ­ãƒ“ï¼ˆç´šåˆ¥Ã—æ—¥ç¨‹ãƒ€ã‚¤ãƒŠãƒŸã‚¯ã‚¹ / 5ã€œ9è»Šãƒ»è²·ã„ç›®ä»˜ãï¼šçµ±åˆç‰ˆï¼‰â­")
st.caption(f"é¢¨è£œæ­£ãƒ¢ãƒ¼ãƒ‰: {WIND_MODE}ï¼ˆ'speed_only'=é¢¨é€Ÿã®ã¿ / 'directional'=å‘ãã‚‚è–„ãè€ƒæ…®ï¼‰")

st.subheader("ãƒ¬ãƒ¼ã‚¹ç•ªå·ï¼ˆç›´å‰ã«ã‚µã‚¯ãƒƒã¨å¤‰æ›´ï¼‰")
if "race_no_main" not in st.session_state:
    st.session_state["race_no_main"] = 1
c1, c2, c3 = st.columns([6,2,2])
with c1:
    race_no_input = st.number_input("R", min_value=1, max_value=12, step=1,
                                    value=int(st.session_state["race_no_main"]),
                                    key="race_no_input")
with c2:
    prev_clicked = st.button("â—€ å‰ã®R", use_container_width=True)
with c3:
    next_clicked = st.button("æ¬¡ã®R â–¶", use_container_width=True)
if prev_clicked:
    st.session_state["race_no_main"] = max(1, int(race_no_input) - 1); st.rerun()
elif next_clicked:
    st.session_state["race_no_main"] = min(12, int(race_no_input) + 1); st.rerun()
else:
    st.session_state["race_no_main"] = int(race_no_input)
race_no = int(st.session_state["race_no_main"])

# ãƒ©ã‚¤ãƒ³æ§‹æˆï¼ˆæœ€å¤§7ï¼šå˜é¨ã‚‚1ãƒ©ã‚¤ãƒ³ï¼‰
line_inputs = [
    st.text_input("ãƒ©ã‚¤ãƒ³1ï¼ˆä¾‹ï¼š317ï¼‰", key="line_1", max_chars=9),
    st.text_input("ãƒ©ã‚¤ãƒ³2ï¼ˆä¾‹ï¼š6ï¼‰", key="line_2", max_chars=9),
    st.text_input("ãƒ©ã‚¤ãƒ³3ï¼ˆä¾‹ï¼š425ï¼‰", key="line_3", max_chars=9),
    st.text_input("ãƒ©ã‚¤ãƒ³4ï¼ˆä»»æ„ï¼‰", key="line_4", max_chars=9),
    st.text_input("ãƒ©ã‚¤ãƒ³5ï¼ˆä»»æ„ï¼‰", key="line_5", max_chars=9),
    st.text_input("ãƒ©ã‚¤ãƒ³6ï¼ˆä»»æ„ï¼‰", key="line_6", max_chars=9),
    st.text_input("ãƒ©ã‚¤ãƒ³7ï¼ˆä»»æ„ï¼‰", key="line_7", max_chars=9),
]
n_cars = int(n_cars)
lines = [extract_car_list(x, n_cars) for x in line_inputs if str(x).strip()]
line_def, car_to_group = build_line_maps(lines)
active_cars = sorted({c for lst in lines for c in lst}) if lines else list(range(1, n_cars+1))

# â†â†â† ã“ã“ã«å…¥ã‚Œã‚‹
import re, unicodedata
def input_float_text(label: str, key: str, placeholder: str = "") -> float | None:
    s = st.text_input(label, value=st.session_state.get(key, ""), key=key, placeholder=placeholder)
    ss = unicodedata.normalize("NFKC", str(s)).replace(",", "").strip()
    if ss == "":
        return None
    if not re.fullmatch(r"[+-]?\d+(\.\d+)?", ss):
        st.warning(f"{label} ã¯æ•°å€¤ã§å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆå…¥åŠ›å€¤: {s}ï¼‰")
        return None
    return float(ss)
# â†’â†’â†’ ã“ã“ã¾ã§

st.subheader("å€‹äººãƒ‡ãƒ¼ã‚¿ï¼ˆç›´è¿‘4ã‹æœˆï¼šå›æ•°ï¼‰")
cols = st.columns(n_cars)
ratings, S, B = {}, {}, {}
...

k_esc, k_mak, k_sashi, k_mark = {}, {}, {}, {}
x1, x2, x3, x_out = {}, {}, {}, {}

for i, no in enumerate(active_cars):
    with cols[i]:
        st.markdown(f"**{no}ç•ª**")
        ratings[no] = input_float_text("å¾—ç‚¹ï¼ˆç©ºæ¬„å¯ï¼‰", key=f"pt_{no}", placeholder="ä¾‹: 55.0")
        S[no] = st.number_input("S", 0, 99, 0, key=f"s_{no}")
        B[no] = st.number_input("B", 0, 99, 0, key=f"b_{no}")
        k_esc[no]   = st.number_input("é€ƒ", 0, 99, 0, key=f"ke_{no}")
        k_mak[no]   = st.number_input("æ²", 0, 99, 0, key=f"km_{no}")
        k_sashi[no] = st.number_input("å·®", 0, 99, 0, key=f"ks_{no}")
        k_mark[no]  = st.number_input("ãƒ", 0, 99, 0, key=f"kk_{no}")
        x1[no]  = st.number_input("1ç€", 0, 99, 0, key=f"x1_{no}")
        x2[no]  = st.number_input("2ç€", 0, 99, 0, key=f"x2_{no}")
        x3[no]  = st.number_input("3ç€", 0, 99, 0, key=f"x3_{no}")
        x_out[no]= st.number_input("ç€å¤–", 0, 99, 0, key=f"xo_{no}")

ratings_val = {no: (ratings[no] if ratings[no] is not None else 55.0) for no in active_cars}

# 1ç€ãƒ»2ç€ã®ç¸®ç´„ï¼ˆç´šåˆ¥Ã—ä¼šå ´ã®äº‹å‰åˆ†å¸ƒã‚’æ··ãœã‚‹ï¼‰
def prior_by_class(cls, style_adj):
    if "ã‚¬ãƒ¼ãƒ«" in cls: p1,p2 = 0.18,0.24
    elif "ï¼³ç´š" in cls: p1,p2 = 0.22,0.26
    elif "ãƒãƒ£ãƒ¬ãƒ³ã‚¸" in cls: p1,p2 = 0.18,0.22
    else: p1,p2 = 0.20,0.25
    p1 += 0.010*style_adj; p2 -= 0.005*style_adj
    return clamp(p1,0.05,0.60), clamp(p2,0.05,0.60)

def n0_by_n(n):
    if n<=6: return 12
    if n<=14: return 8
    if n<=29: return 5
    return 3

# ã“ã“ã¯å¾“æ¥é€šã‚Šã§OK
p1_eff, p2_eff = {}, {}
for no in active_cars:
    n = x1[no]+x2[no]+x3[no]+x_out[no]
    p1_prior, p2_prior = prior_by_class(race_class, style)
    n0 = n0_by_n(n)
    if n==0:
        p1_eff[no], p2_eff[no] = p1_prior, p2_prior
    else:
        p1_eff[no] = clamp((x1[no] + n0*p1_prior)/(n+n0), 0.0, 0.40)
        p2_eff[no] = clamp((x2[no] + n0*p2_prior)/(n+n0), 0.0, 0.50)

# â†ã“ã“ã¯Formã ã‘ä½œã‚‹ï¼ˆåå·®å€¤åŒ–ã¯ã¾ã ã—ãªã„ï¼‰
Form = {no: 0.7*p1_eff[no] + 0.3*p2_eff[no] for no in active_cars}

# === Form åå·®å€¤åŒ–ï¼ˆå¹³å‡50, SD10ï¼‰
form_list = [Form[n] for n in active_cars]
form_T, mu_form, sd_form, _ = t_score_from_finite(np.array(form_list))
form_T_map = {n: float(form_T[i]) for i, n in enumerate(active_cars)}



# --- è„šè³ªãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ï¼ˆä¼šå ´é©æ€§ï¼šå¾—æ„ä¼šå ´å¹³å‡åŸºæº–ã®styleã‚’æ›ã‘ã‚‹ï¼‰
prof_base, prof_escape, prof_sashi, prof_oikomi = {}, {}, {}, {}
for no in active_cars:
    tot = k_esc[no]+k_mak[no]+k_sashi[no]+k_mark[no]
    if tot==0: esc=mak=sashi=mark = 0.25
    else:
        esc=k_esc[no]/tot; mak=k_mak[no]/tot; sashi=k_sashi[no]/tot; mark=k_mark[no]/tot
    prof_escape[no]=esc; prof_sashi[no]=sashi; prof_oikomi[no]=mark
    base = esc*BASE_BY_KAKU["é€ƒ"] + mak*BASE_BY_KAKU["æ²"] + sashi*BASE_BY_KAKU["å·®"] + mark*BASE_BY_KAKU["ãƒ"]
    vmix = style
    venue_bonus = 0.06 * vmix * ( +1.00*esc + 0.40*mak - 0.60*sashi - 0.25*mark )
    prof_base[no] = base + clamp(venue_bonus, -0.06, +0.06)

# ======== å€‹äººè£œæ­£ï¼ˆå¾—ç‚¹/è„šè³ªä¸Šä½/ç€é †åˆ†å¸ƒï¼‰ ========
ratings_sorted = sorted(active_cars, key=lambda n: ratings_val[n], reverse=True)
ratings_rank = {no: i+1 for i,no in enumerate(ratings_sorted)}
def tenscore_bonus(no):
    r = ratings_rank[no]
    top_n = min(3, len(active_cars))
    bottom_n = min(3, len(active_cars))
    if r <= top_n: return +0.03
    if r >= len(active_cars)-bottom_n+1: return -0.02
    return 0.0
def topk_bonus(k_dict, topn=3, val=0.02):
    order = sorted(k_dict.items(), key=lambda x:(x[1], -x[0]), reverse=True)
    grant = set([no for i,(no,v) in enumerate(order) if i<topn])
    return {no:(val if no in grant else 0.0) for no in k_dict}
esc_bonus   = topk_bonus(k_esc,   topn=3, val=0.02)
mak_bonus   = topk_bonus(k_mak,   topn=3, val=0.02)
sashi_bonus = topk_bonus(k_sashi, topn=3, val=0.015)
mark_bonus  = topk_bonus(k_mark,  topn=3, val=0.01)
def finish_bonus(no):
    tot = x1[no]+x2[no]+x3[no]+x_out[no]
    if tot == 0: return 0.0
    in3 = (x1[no]+x2[no]+x3[no]) / tot
    out = x_out[no] / tot
    bonus = 0.0
    if in3 > 0.50: bonus += 0.03
    if out > 0.70: bonus -= 0.03
    if out < 0.40: bonus += 0.02
    return bonus
extra_bonus = {}
for no in active_cars:
    total = (tenscore_bonus(no) +
             esc_bonus.get(no,0.0) + mak_bonus.get(no,0.0) +
             sashi_bonus.get(no,0.0) + mark_bonus.get(no,0.0) +
             finish_bonus(no))
    extra_bonus[no] = clamp(total, -0.10, +0.10)

# ===== ä¼šå ´å€‹æ€§ã‚’â€œå€‹äººã‚¹ã‚³ã‚¢â€ã«æµ¸é€ï¼šbankç³»è£œæ­£ã‚’å·®ã—æ›¿ãˆ =====
def bank_character_bonus(bank_angle, straight_length, prof_escape, prof_sashi):
    zL, zTH, dC = venue_z_terms(straight_length, bank_angle, bank_length)
    base = clamp(0.06*zTH - 0.05*zL - 0.03*dC, -0.08, +0.08)
    return round(base*float(prof_escape) - 0.5*base*float(prof_sashi), 3)

def bank_length_adjust(bank_length, prof_oikomi):
    dC = (+0.4 if bank_length>=480 else 0.0 if bank_length>=380 else -0.4)
    return round(0.03*(-dC)*float(prof_oikomi), 3)

# --- å®‰å®šåº¦ï¼ˆç€é †åˆ†å¸ƒï¼‰ã‚’Tæœ¬ä½“ã«å…¥ã‚Œã‚‹ãŸã‚ã®é‡ã¿ï¼ˆå¼·åŒ–ç‰ˆï¼‰ ---
STAB_W_IN3  = 0.18   # 3ç€å†…ã®å¯„ä¸
STAB_W_OUT  = 0.22   # ç€å¤–ã®ãƒšãƒŠãƒ«ãƒ†ã‚£
STAB_W_LOWN = 0.06   # ã‚µãƒ³ãƒ—ãƒ«ä¸è¶³ãƒšãƒŠãƒ«ãƒ†ã‚£
STAB_PRIOR_IN3 = 0.33
STAB_PRIOR_OUT = 0.45

def stability_score(no: int) -> float:
    n1 = x1.get(no, 0); n2 = x2.get(no, 0); n3 = x3.get(no, 0); nOut = x_out.get(no, 0)
    n  = n1 + n2 + n3 + nOut
    if n <= 0:
        return 0.0
    # å°‘ã‚µãƒ³ãƒ—ãƒ«ç¸®ç´„ï¼ˆã“ã®é–¢æ•°å†…ã§å®Œçµï¼‰
    if n <= 6:    n0 = 12
    elif n <= 14: n0 = 8
    elif n <= 29: n0 = 5
    else:         n0 = 3

    in3  = (n1 + n2 + n3 + n0*STAB_PRIOR_IN3) / (n + n0)
    out_ = (nOut          + n0*STAB_PRIOR_OUT) / (n + n0)

    bonus = 0.0
    bonus += STAB_W_IN3 * (in3 - STAB_PRIOR_IN3) * 2.0
    bonus -= STAB_W_OUT * (out_ - STAB_PRIOR_OUT) * 2.0

    if n < 10:
        bonus -= STAB_W_LOWN * (10 - n) / 10.0

    # ã‚­ãƒ£ãƒƒãƒ—ï¼šnã«å¿œã˜ã¦æ®µéšçš„ã«åºƒã’ã‚‹ï¼ˆÂ±0.35ã€œÂ±0.45ï¼‰
    cap = 0.35
    if n >= 15: cap = 0.45
    elif n >= 10: cap = 0.40

    return clamp(bonus, -cap, +cap)

# ===== SBãªã—åˆè¨ˆï¼ˆç’°å¢ƒè£œæ­£ + å¾—ç‚¹å¾®è£œæ­£ + å€‹äººè£œæ­£ + å‘¨å›ç–²åŠ´ + å®‰å®šåº¦ï¼‰ =====
tens_list = [ratings_val[no] for no in active_cars]
t_corr = tenscore_correction(tens_list) if active_cars else []
tens_corr = {no:t_corr[i] for i,no in enumerate(active_cars)} if active_cars else {}

rows = []
_wind_func = wind_adjust
eff_wind_dir   = globals().get("eff_wind_dir",   wind_dir)
eff_wind_speed = globals().get("eff_wind_speed", wind_speed)
L200_RAW = {}  # â† æ–°è¦

for no in active_cars:
    role = role_in_line(no, line_def)

    # --- L200ï¼ˆæ®‹è„šï¼‰ç”Ÿå€¤ã‚’è¨ˆç®—ï¼šENVåˆè¨ˆã«ã¯â€œå…¥ã‚Œãªã„â€è¦³æ¸¬ç”¨ ---
    l200 = l200_adjust(
        role=role,
        straight_length=straight_length,
        bank_length=bank_length,
        race_class=race_class,
        prof_escape=float(prof_escape[no]),
        prof_sashi=float(prof_sashi[no]),
        prof_oikomi=float(prof_oikomi[no]),
        is_wet=st.session_state.get("is_wet", False)  # é›¨ãƒˆã‚°ãƒ«æœªå®Ÿè£…ãªã‚‰ False ã®ã¾ã¾
    )
    L200_RAW[int(no)] = float(l200)

    # --- å‘¨å›ç–²åŠ´ï¼ˆæ—¢å­˜ï¼‰ ---
    extra = fatigue_extra(eff_laps, day_label, n_cars, race_class)
    fatigue_scale = (1.0 if race_class == "ï¼³ç´š" else
                     1.1 if race_class == "ï¼¡ç´š" else
                     1.2 if race_class == "ï¼¡ç´šãƒãƒ£ãƒ¬ãƒ³ã‚¸" else
                     1.05)
    laps_adj = (
        -0.10 * extra * (1.0 if prof_escape[no] > 0.5 else 0.0)
        + 0.05 * extra * (1.0 if prof_oikomi[no] > 0.4 else 0.0)
    ) * fatigue_scale

rows = []
_wind_func = wind_adjust
eff_wind_dir   = globals().get("eff_wind_dir", wind_dir)
eff_wind_speed = globals().get("eff_wind_speed", wind_speed)

for no in active_cars:
    role = role_in_line(no, line_def)
    # ã“ã“ã«å„ç¨®è¨ˆç®—ã¨ rows.append(...) ãŒç¶šã


    # å‘¨å›ç–²åŠ´ï¼ˆDAYÃ—é ­æ•°Ã—ç´šåˆ¥ã‚’åæ˜ ï¼‰
    extra = fatigue_extra(eff_laps, day_label, n_cars, race_class)
    fatigue_scale = (
        1.0  if race_class == "ï¼³ç´š" else
        1.1  if race_class == "ï¼¡ç´š" else
        1.2  if race_class == "ï¼¡ç´šãƒãƒ£ãƒ¬ãƒ³ã‚¸" else
        1.05
    )
    laps_adj = (
        -0.10 * extra * (1.0 if prof_escape[no] > 0.5 else 0.0)
        + 0.05 * extra * (1.0 if prof_oikomi[no] > 0.4 else 0.0)
    ) * fatigue_scale

    # ç’°å¢ƒãƒ»å€‹äººè£œæ­£ï¼ˆæ—¢å­˜ï¼‰
    wind     = _wind_func(eff_wind_dir, float(eff_wind_speed or 0.0), role, float(prof_escape[no]))
    bank_b   = bank_character_bonus(bank_angle, straight_length, prof_escape[no], prof_sashi[no])
    length_b = bank_length_adjust(bank_length, prof_oikomi[no])
    indiv    = extra_bonus.get(no, 0.0)
    stab     = stability_score(no)  # å®‰å®šåº¦

    # â˜… ãƒ©ã‚¹ãƒˆ200ï¼ˆå¿…è¦ãªã‚‰ last200_bonus ã‚’ l200_adjust ã«å¤‰æ›´ï¼‰
    l200 = l200_adjust(role, straight_length, bank_length, race_class,
                   float(prof_escape[no]), float(prof_sashi[no]), float(prof_oikomi[no]),
                   is_wet=st.session_state.get("is_wet", False))


    # â˜… åˆè¨ˆï¼ˆSBãªã—ï¼‰â€¦ã“ã“ã§ã¯ l200 ã‚‚åŠ ç®—ã™ã‚‹ç‰ˆ
    total_raw = (
        prof_base[no] +
        wind +
        cf["spread"] * tens_corr.get(no, 0.0) +
        bank_b + length_b +
        laps_adj + indiv + stab +
        l200
    )

    rows.append([
        int(no), role,
        round(prof_base[no], 3),
        round(wind, 3),
        round(cf["spread"] * tens_corr.get(no, 0.0), 3),
        round(bank_b, 3),
        round(length_b, 3),
        round(laps_adj, 3),
        round(indiv, 3),
        round(stab, 3),
        round(l200, 3),
        total_raw
    ])

df = pd.DataFrame(rows, columns=[
    "è»Šç•ª","å½¹å‰²","è„šè³ªåŸºæº–(ä¼šå ´)","é¢¨è£œæ­£","å¾—ç‚¹è£œæ­£","ãƒãƒ³ã‚¯è£œæ­£",
    "å‘¨é•·è£œæ­£","å‘¨å›è£œæ­£","å€‹äººè£œæ­£","å®‰å®šåº¦","ãƒ©ã‚¹ãƒˆ200","åˆè¨ˆ_SBãªã—_raw",
])

# === ã“ã“ã¯ df = pd.DataFrame(...) ã®ç›´å¾Œã«è²¼ã‚‹ã ã‘ ===

# --- fallback: note_sections ãŒç„¡ã„ç’°å¢ƒã§ã‚‚è½ã¡ãªã„ã‚ˆã†ã« ---
ns = globals().get("note_sections", None)
if not isinstance(ns, list):
    ns = []
    globals()["note_sections"] = ns
note_sections = ns


# â¶ ãƒãƒ³ã‚¯åˆ†é¡ã‚’â€œã¿ãªã—ç›´ç·š/å‘¨é•·â€ã‹ã‚‰æ±ºå®šï¼ˆ33 / 400 / 500ï¼‰
def _bank_str_from_lengths(bank_length: float) -> str:
    try:
        bl = float(bank_length)
    except:
        bl = 400.0
    if bl <= 340.0:   # 333ç³»
        return "33"
    elif bl >= 480.0: # 500ç³»
        return "500"
    return "400"

# â· ä¼šå ´ã®â€œæœ‰åˆ©è„šè³ªâ€ã‚»ãƒƒãƒˆ
def _favorable_styles(bank_str: str) -> set[str]:
    if bank_str == "33":   # 33ï¼å…ˆè¡Œç³»ãƒ»ãƒ©ã‚¤ãƒ³å¯„ã‚Š
        return {"é€ƒã’", "ãƒãƒ¼ã‚¯"}
    if bank_str == "500":  # 500ï¼å·®ã—ãƒ»ãƒãƒ¼ã‚¯å¯„ã‚Š
        return {"å·®ã—", "ãƒãƒ¼ã‚¯"}
    return {"ã¾ãã‚Š", "å·®ã—"}  # æ—¢å®š=400

# â¸ å½¹å‰²ã®æ—¥æœ¬èªåŒ–ï¼ˆlineã®ä¸¦ã³ã‹ã‚‰ï¼‰
def _role_jp(no: int, line_def: dict) -> str:
    r = role_in_line(no, line_def)  # 'head'/'second'/'thirdplus'/'single'
    return {"head":"å…ˆé ­","second":"ç•ªæ‰‹","thirdplus":"ä¸‰ç•ªæ‰‹","single":"å…ˆé ­"}.get(r, "å…ˆé ­")

# â¹ å…¥åŠ›ã®â€œé€ƒ/æ²/å·®/ãƒâ€ã‹ã‚‰ã€ãã®é¸æ‰‹ã®å®Ÿè„šè³ªã‚’æ±ºå®šï¼ˆåŒç‚¹æ™‚ã¯ãƒ©ã‚¤ãƒ³ä½ç½®ã§ãƒ–ãƒ¬ãªã„æ±ºã‚æ–¹ï¼‰
def _dominant_style(no: int) -> str:
    vec = [("é€ƒã’", k_esc.get(no,0)), ("ã¾ãã‚Š", k_mak.get(no,0)),
           ("å·®ã—", k_sashi.get(no,0)), ("ãƒãƒ¼ã‚¯", k_mark.get(no,0))]
    m = max(v for _,v in vec)
    cand = [s for s,v in vec if v == m and m > 0]
    if cand:
        # ã‚¿ã‚¤ãƒ–ãƒ¬ãƒ¼ã‚¯ï¼šå…ˆé ­>ç•ªæ‰‹>ä¸‰ç•ªæ‰‹>å˜é¨ ã‚’å„ªå…ˆï¼ˆå…ˆè¡Œæ°—å‘³â†’å·®ã—â†’ãƒãƒ¼ã‚¯ã®é †ï¼‰
        pr = {"å…ˆé ­":3,"ç•ªæ‰‹":2,"ä¸‰ç•ªæ‰‹":1,"å˜é¨":0}
        role = role_in_line(no, line_def)
        role_pr = {"head":"å…ˆé ­","second":"ç•ªæ‰‹","thirdplus":"ä¸‰ç•ªæ‰‹","single":"å˜é¨"}.get(role,"å˜é¨")
        if "é€ƒã’" in cand: return "é€ƒã’"
        # æ®‹ã‚Šã¯ãƒ©ã‚¤ãƒ³ä½ç½®ã§â€œå·®ã—â€å„ªå…ˆã€ãã®æ¬¡ã«â€œãƒãƒ¼ã‚¯â€
        if "å·®ã—" in cand and pr.get(role_pr,0) >= 2: return "å·®ã—"
        if "ãƒãƒ¼ã‚¯" in cand: return "ãƒãƒ¼ã‚¯"
        return cand[0]
    # å‡ºèµ°å±¥æ­´ã‚¼ãƒ­ãªã‚‰ä½ç½®ã§æ±ºã‚ã‚‹
    role = role_in_line(no, line_def)
    return {"head":"é€ƒã’","second":"å·®ã—","thirdplus":"ãƒãƒ¼ã‚¯","single":"ã¾ãã‚Š"}.get(role,"ã¾ãã‚Š")

# âº Rider æ§‹é€ ä½“ï¼ˆã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ä¸Šéƒ¨ã§æ—¢ã«å®£è¨€æ¸ˆã¿ãªã‚‰å†å®šç¾©ä¸è¦ï¼‰
from dataclasses import dataclass
@dataclass
class Rider:
    num: int; hensa: float; line_id: int; role: str; style: str

# â» åå·®å€¤ï¼ˆTã‚¹ã‚³ã‚¢ï¼‰ã‚’ â€œåˆè¨ˆ_SBãªã—_rawâ€ ã‹ã‚‰ä½œã‚‹ï¼ˆãªã‘ã‚Œã° Form ã§ä»£ç”¨ï¼‰
def _hensa_map_from_df(df: pd.DataFrame) -> dict[int,float]:
    col = "åˆè¨ˆ_SBãªã—_raw" if "åˆè¨ˆ_SBãªã—_raw" in df.columns else None
    base = [float(df.loc[df["è»Šç•ª"]==no, col].values[0]) if col else float(form_T_map[no]) for no in active_cars]
    T, _, _, _ = t_score_from_finite(np.array(base, dtype=float))
    return {no: float(T[i]) for i,no in enumerate(active_cars)}

# â¼ RIDERS ã‚’â€œå®Ÿãƒ‡ãƒ¼ã‚¿â€ã§æ§‹ç¯‰ï¼ˆè„šè³ªã¯ â¹ã€åå·®å€¤ã¯ â»ï¼‰
bank_str = _bank_str_from_lengths(bank_length)
hensa_map = _hensa_map_from_df(df)
RIDERS = []
for no in active_cars:
    # ãƒ©ã‚¤ãƒ³IDã¯â€œãã®ãƒ©ã‚¤ãƒ³ã®å…ˆé ­è»Šç•ªâ€ã‚’ä»£è¡¨IDã«
    gid = None
    for g, mem in line_def.items():
        if no in mem:
            gid = mem[0]; break
    if gid is None: gid = no
    RIDERS.append(
        Rider(
            num=int(no),
            hensa=float(hensa_map[no]),
            line_id=int(gid),
            role=_role_jp(no, line_def),
            style=_dominant_style(no),
        )
    )

# â½ ãƒ•ã‚©ãƒ¼ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆæœ¬å‘½âˆ’2âˆ’å…¨ï¼‰ï¼š1åˆ—ç›®=æœ‰åˆ©è„šè³ªå†…ã®åå·®å€¤æœ€å¤§
def _pick_axis(riders: list[Rider], bank_str: str) -> Rider:
    fav = _favorable_styles(bank_str)
    cand = [r for r in riders if r.style in fav]
    if not cand:
        raise ValueError(f"æœ‰åˆ©è„šè³ª{sorted(fav)}ã«è©²å½“0ï¼ˆbank={bank_str} / styleèª¤ã‚Šã®å¯èƒ½æ€§ï¼‰")
    return max(cand, key=lambda r: r.hensa)

def _role_priority(bank_str: str) -> dict[str,int]:
    return ({"ãƒãƒ¼ã‚¯":3,"ç•ªæ‰‹":2,"ä¸‰ç•ªæ‰‹":1,"å…ˆé ­":0} if bank_str=="33"
            else {"ç•ªæ‰‹":3,"ãƒãƒ¼ã‚¯":2,"ä¸‰ç•ªæ‰‹":1,"å…ˆé ­":0})

def _pick_support(riders: list[Rider], first: Rider, bank_str: str) -> Rider|None:
    pr = _role_priority(bank_str)
    same = [r for r in riders if r.line_id==first.line_id and r.num!=first.num]
    if not same: return None
    same.sort(key=lambda r: (pr.get(r.role,0), r.hensa), reverse=True)
    return same[0]

# å°ï¼ˆâ—â†’â–²â†’åå·®å€¤è£œå®Œï¼‰
def _read_marks_idmap() -> dict[int,str]:
    rm = globals().get("result_marks") or globals().get("marks") or {}
    out={}
    if isinstance(rm, dict):
        if any(isinstance(k,int) or (isinstance(k,str) and k.isdigit()) for k in rm.keys()):
            for k,v in rm.items():
                try: out[int(k)] = ("â—‹" if str(v) in ("â—‹","ã€‡") else str(v))
                except: pass
        else:
            for sym,vid in rm.items():
                try: out[int(vid)] = ("â—‹" if str(sym) in ("â—‹","ã€‡") else str(sym))
                except: pass
    return out

def _pick_partner(riders: list[Rider], used: set[int]) -> int|None:
    id2sym = _read_marks_idmap()
    for want in ("â—","â–²"):
        t = next((i for i,s in id2sym.items() if i not in used and s==want), None)
        if t is not None: return t
    # è£œå®Œï¼šåå·®å€¤ä¸Šä½
    rest = sorted([r for r in riders if r.num not in used], key=lambda r: r.hensa, reverse=True)
    return rest[0].num if rest else None

def make_trio_formation_final(riders: list[Rider], bank_str: str) -> str:
    first = _pick_axis(riders, bank_str)
    support = _pick_support(riders, first, bank_str)
    used = {first.num} | ({support.num} if support else set())
    partner = _pick_partner(riders, used)
    second = []
    if support: second.append(support.num)
    if partner is not None: second.append(partner)
    if len(second) < 2:
        # 2è»Šã«æº€ãŸãªã‘ã‚Œã°åå·®å€¤è£œå®Œ
        rest = sorted([r.num for r in riders if r.num not in ({first.num}|set(second))],
                      key=lambda n: next(rr.hensa for rr in riders if rr.num==n),
                      reverse=True)
        if rest: second.append(rest[0])
    second = sorted(set(second))[:2]
    return f"ä¸‰é€£è¤‡ãƒ•ã‚©ãƒ¼ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ï¼š{first.num}ï¼{','.join(map(str, second))}ï¼å…¨"

# â¾ å‡ºåŠ›ï¼ˆnote_sections ãŒã‚ã‚Œã°ãã“ã¸ï¼‰
try:
    out = make_trio_formation_final(RIDERS, bank_str)
    (note_sections.append if isinstance(note_sections, list) else print)(f"ã€ç‹™ã„ãŸã„ãƒ¬ãƒ¼ã‚¹ãƒ•ã‚©ãƒ¼ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ã€‘ {out}")
except Exception as e:
    (note_sections.append if isinstance(note_sections, list) else print)(f"ã€ç‹™ã„ãŸã„ãƒ¬ãƒ¼ã‚¹ãƒ•ã‚©ãƒ¼ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ã€‘ ã‚¨ãƒ©ãƒ¼: {e}")


mu = float(df["åˆè¨ˆ_SBãªã—_raw"].mean()) if not df.empty else 0.0
df["åˆè¨ˆ_SBãªã—"] = mu + 1.0 * (df["åˆè¨ˆ_SBãªã—_raw"] - mu)

# === [PATCH-A] å®‰å®šåº¦ã‚’ENVã‹ã‚‰åˆ†é›¢ã—ã€å„æŸ±ã‚’ãƒ¬ãƒ¼ã‚¹å†…zåŒ–ï¼ˆSDå›ºå®šï¼‰ ===
SD_FORM = 0.28
SD_ENV  = 0.20
SD_STAB = 0.12
SD_L200 = float(globals().get("SD_L200", 0.22))  # â† è¿½åŠ ã€‚ã¾ãš0.22ã€œ0.30ã§æ§˜å­è¦‹


# å®‰å®šåº¦ï¼ˆrawï¼‰ã¨ã€ENVã®ãƒ™ãƒ¼ã‚¹ï¼ˆ= åˆè¨ˆ_SBãªã—_raw ã‹ã‚‰å®‰å®šåº¦ã ã‘é™¤ã„ãŸã‚‚ã®ï¼‰
STAB_RAW = {int(df.loc[i, "è»Šç•ª"]): float(df.loc[i, "å®‰å®šåº¦"]) for i in df.index}
ENV_BASE = {
    int(df.loc[i, "è»Šç•ª"]): float(df.loc[i, "åˆè¨ˆ_SBãªã—_raw"]) - float(df.loc[i, "å®‰å®šåº¦"])
    for i in df.index
}

# ENV â†’ z
_env_arr = np.array([float(ENV_BASE.get(n, np.nan)) for n in active_cars], dtype=float)
_mask = np.isfinite(_env_arr)
if int(_mask.sum()) >= 2:
    mu_env = float(np.mean(_env_arr[_mask])); sd_env = float(np.std(_env_arr[_mask]))
else:
    mu_env, sd_env = 0.0, 1.0
_den_env = (sd_env if sd_env > 1e-12 else 1.0)
ENV_Z = {int(n): (float(ENV_BASE.get(n, mu_env)) - mu_env) / _den_env for n in active_cars}

# FORMï¼ˆã™ã§ã« form_T_map ã¯ä½œã£ã¦ã‚ã‚‹å‰æï¼‰ â†’ z
FORM_Z = {int(n): (float(form_T_map.get(n, 50.0)) - 50.0) / 10.0 for n in active_cars}

# STABï¼ˆå®‰å®šåº¦ rawï¼‰ â†’ z
_stab_arr = np.array([float(STAB_RAW.get(n, np.nan)) for n in active_cars], dtype=float)
_m2 = np.isfinite(_stab_arr)
if int(_m2.sum()) >= 2:
    mu_st = float(np.mean(_stab_arr[_m2])); sd_st = float(np.std(_stab_arr[_m2]))
else:
    mu_st, sd_st = 0.0, 1.0
_den_st = (sd_st if sd_st > 1e-12 else 1.0)
STAB_Z = {int(n): (float(STAB_RAW.get(n, mu_st)) - mu_st) / _den_st for n in active_cars}

# L200ï¼ˆæ®‹è„šï¼‰â†’ z
_l200_arr = np.array([float(L200_RAW.get(n, np.nan)) for n in active_cars], dtype=float)
_m3 = np.isfinite(_l200_arr)
if int(_m3.sum()) >= 2:
    mu_l2 = float(np.mean(_l200_arr[_m3])); sd_l2 = float(np.std(_l200_arr[_m3]))
else:
    mu_l2, sd_l2 = 0.0, 1.0
_den_l2 = (sd_l2 if sd_l2 > 1e-12 else 1.0)
L200_Z = {int(n): (float(L200_RAW.get(n, mu_l2)) - mu_l2) / _den_l2 for n in active_cars}


# ===== KOæ–¹å¼ï¼ˆå°ã«æ··ãœãšï¼šå±•é–‹ãƒ»ã‚±ãƒ³ã§åˆ©ç”¨ï¼‰ =====
v_wo = {int(k): float(v) for k, v in zip(df["è»Šç•ª"].astype(int), df["åˆè¨ˆ_SBãªã—"].astype(float))}
_is_girls = (race_class == "ã‚¬ãƒ¼ãƒ«ã‚º")
head_scale = KO_HEADCOUNT_SCALE.get(int(n_cars), 1.0)
ko_scale_raw = (KO_GIRLS_SCALE if _is_girls else 1.0) * head_scale
KO_SCALE_MAX = 0.45
ko_scale = min(ko_scale_raw, KO_SCALE_MAX)

if ko_scale > 0.0 and line_def and len(line_def) >= 1:
    ko_order = _ko_order(v_wo, line_def, S, B,
                         line_factor=line_factor_eff,
                         gap_delta=KO_GAP_DELTA)
    vals = [v_wo[c] for c in v_wo.keys()]
    mu0  = float(np.mean(vals)); sd0 = float(np.std(vals) + 1e-12)
    KO_STEP_SIGMA_LOCAL = max(0.25, KO_STEP_SIGMA * 0.7)
    step = KO_STEP_SIGMA_LOCAL * sd0

    new_scores = {}
    for rank, car in enumerate(ko_order, start=1):
        rank_adjust = step * (len(ko_order) - rank)
        blended = (1.0 - ko_scale) * v_wo[car] + ko_scale * (
            mu0 + rank_adjust - (len(ko_order)/2.0 - 0.5)*step
        )
        new_scores[car] = blended
    v_final = {int(k): float(v) for k, v in new_scores.items()}
else:
    if v_wo:
        ko_order = sorted(v_wo.keys(), key=lambda c: v_wo[c], reverse=True)
        v_final = {int(c): float(v_wo[c]) for c in ko_order}
    else:
        ko_order = []
        v_final = {}

# --- ç´”SBãªã—ãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼ˆKOã¾ã§ï¼æ ¼ä¸Šã’å‰ï¼‰
df_sorted_pure = pd.DataFrame({
    "è»Šç•ª": list(v_final.keys()),
    "åˆè¨ˆ_SBãªã—": [round(float(v_final[c]), 6) for c in v_final.keys()]
}).sort_values("åˆè¨ˆ_SBãªã—", ascending=False).reset_index(drop=True)

# ===== å°ç”¨ï¼ˆæ—¢å­˜ã®å®‰å…¨å¼ã‚’ç¶­æŒï¼‰ =====
FINISH_WEIGHT   = globals().get("FINISH_WEIGHT", 6.0)
FINISH_WEIGHT_G = globals().get("FINISH_WEIGHT_G", 3.0)
POS_BONUS  = globals().get("POS_BONUS", {0: 0.0, 1: -0.6, 2: -0.9, 3: -1.2, 4: -1.4})
POS_WEIGHT = globals().get("POS_WEIGHT", 1.0)
SMALL_Z_RATING = globals().get("SMALL_Z_RATING", 0.01)
FINISH_CLIP = globals().get("FINISH_CLIP", 4.0)
TIE_EPSILON  = globals().get("TIE_EPSILON", 0.8)

# --- p2ã®ZåŒ–ãªã©ï¼ˆå¾“æ¥ã©ãŠã‚Šï¼‰ ---
p2_list = [float(p2_eff.get(n, 0.0)) for n in active_cars]
if len(p2_list) >= 1:
    mu_p2  = float(np.mean(p2_list))
    sd_p2  = float(np.std(p2_list) + 1e-12)
else:
    mu_p2, sd_p2 = 0.0, 1.0
p2z_map = {n: (float(p2_eff.get(n, 0.0)) - mu_p2) / sd_p2 for n in active_cars}
p1_eff_safe = {n: float(p1_eff.get(n, 0.0)) if 'p1_eff' in globals() and p1_eff is not None else 0.0 for n in active_cars}
p2only_map = {n: max(0.0, float(p2_eff.get(n, 0.0)) - float(p1_eff_safe.get(n, 0.0))) for n in active_cars}
zt = zscore_list([ratings_val[n] for n in active_cars]) if active_cars else []
zt_map = {n: float(zt[i]) for i, n in enumerate(active_cars)} if active_cars else {}

# === â˜…Form åå·®å€¤åŒ–ï¼ˆanchor_scoreã‚ˆã‚Šå‰ã«å¿…ãšç½®ãï¼ï¼‰ ===
# ã™ã§ã«ä¸Šã§ Form = 0.7*p1_eff + 0.3*p2_eff ã‚’ä½œã£ã¦ã‚ã‚‹å‰æ
# t_score_from_finite ã¯ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«å†…ã«å®šç¾©æ¸ˆã¿ã§ã‚ã‚‹å‰æ
form_list = [Form[n] for n in active_cars]
form_T, mu_form, sd_form, _ = t_score_from_finite(np.array(form_list))
form_T_map = {n: float(form_T[i]) for i, n in enumerate(active_cars)}

# === [PATCH-1] ENV/FORM ã‚’ãƒ¬ãƒ¼ã‚¹å†…ã§ z åŒ–ã—ã€ç›®æ¨™SDã‚’æ›ã‘ã‚‹ï¼ˆanchor_score ã®å‰ã«ç½®ãï¼‰ ===
SD_FORM = 0.28   # Balanced æ—¢å®š
SD_ENV  = 0.20

# ENV = v_finalï¼ˆé¢¨ãƒ»ä¼šå ´ãƒ»å‘¨å›ç–²åŠ´ãƒ»å€‹äººè£œæ­£ãƒ»å®‰å®šåº¦ ç­‰ã‚’å«ã‚€â€œFormä»¥å¤–â€ï¼‰
_env_arr = np.array([float(v_final.get(n, np.nan)) for n in active_cars], dtype=float)
_mask = np.isfinite(_env_arr)
if int(_mask.sum()) >= 2:
    mu_env = float(np.mean(_env_arr[_mask])); sd_env = float(np.std(_env_arr[_mask]))
else:
    mu_env, sd_env = 0.0, 1.0
_den = (sd_env if sd_env > 1e-12 else 1.0)
ENV_Z = {int(n): (float(v_final.get(n, mu_env)) - mu_env) / _den for n in active_cars}

# FORM = form_T_mapï¼ˆT=50, SD=10ï¼‰â†’ z åŒ–
FORM_Z = {int(n): (float(form_T_map.get(n, 50.0)) - 50.0) / 10.0 for n in active_cars}


def _pos_idx(no:int) -> int:
    g = car_to_group.get(no, None)
    if g is None or g not in line_def:
        return 0
    grp = line_def[g]
    try:
        return max(0, int(grp.index(no)))
    except Exception:
        return 0

bonus_init,_ = compute_lineSB_bonus(
    line_def, S, B,
    line_factor=line_factor_eff,
    exclude=None, cap=cap_SB_eff,
    enable=line_sb_enable
)



def anchor_score(no: int) -> float:
    role = role_in_line(no, line_def)
    sb = float(bonus_init.get(car_to_group.get(no, None), 0.0) * (pos_coeff(role, 1.0) if line_sb_enable else 0.0))
    pos_term  = POS_WEIGHT * POS_BONUS.get(_pos_idx(no), 0.0)
    env_term  = SD_ENV  * float(ENV_Z.get(int(no), 0.0))
    form_term = SD_FORM * float(FORM_Z.get(int(no), 0.0))
    stab_term = SD_STAB * float(STAB_Z.get(int(no), 0.0))
    l200_term = SD_L200 * float(L200_Z.get(int(no), 0.0))   # â† è¿½åŠ 
    tiny      = SMALL_Z_RATING * float(zt_map.get(int(no), 0.0))
    return env_term + form_term + stab_term + l200_term + sb + pos_term + tiny



# === ãƒ‡ãƒãƒƒã‚°è¡¨ç¤ºï¼ˆå¿…è¦ãªã¨ãã ã‘ / anchor_scoreå®šç¾©ã®å¾Œ, å°å‡ºåŠ›ã®å‰ï¼‰ ===
# for no in active_cars:
#     role = role_in_line(no, line_def)
#     sb_dbg  = bonus_init.get(car_to_group.get(no, None), 0.0) * (pos_coeff(role, 1.0) if line_sb_enable else 0.0)
#     pos_dbg = POS_WEIGHT * POS_BONUS.get(_pos_idx(no), 0.0)
#     form_dbg = SD_FORM * FORM_Z.get(no, 0.0)
#     env_dbg  = SD_ENV  * ENV_Z.get(no, 0.0)
#     stab_dbg = (SD_STAB * STAB_Z.get(no, 0.0)) if 'STAB_Z' in globals() else 0.0
#     tiny_dbg = SMALL_Z_RATING * zt_map.get(no, 0.0)

#     total = form_dbg + env_dbg + stab_dbg + sb_dbg + pos_dbg + tiny_dbg
#     st.write(no, {
#         "form": round(form_dbg, 4),
#         "env":  round(env_dbg, 4),
#         "stab": round(stab_dbg, 4),
#         "sb":   round(sb_dbg, 4),
#         "pos":  round(pos_dbg, 4),
#         "tiny": round(tiny_dbg, 4),
#         "TOTAL(anchor_scoreæœŸå¾…å€¤)": round(total, 4),
#     })



# ===== â—å€™è£œæŠ½å‡ºï¼ˆæ—¢å­˜ãƒ­ã‚¸ãƒƒã‚¯ç¶­æŒï¼‰
cand_sorted = sorted(active_cars, key=lambda n: anchor_score(n), reverse=True)
C = cand_sorted[:min(3, len(cand_sorted))]
ratings_sorted2 = sorted(active_cars, key=lambda n: ratings_val[n], reverse=True)
ratings_rank2 = {n: i+1 for i,n in enumerate(ratings_sorted2)}
ALLOWED_MAX_RANK = globals().get("ALLOWED_MAX_RANK", 5)

guarantee_top_rating = True
if guarantee_top_rating and (race_class == "ã‚¬ãƒ¼ãƒ«ã‚º") and len(ratings_sorted2) >= 1:
    top_rating_car = ratings_sorted2[0]
    if top_rating_car not in C:
        C = [top_rating_car] + [c for c in C if c != top_rating_car]
        C = C[:min(3, len(cand_sorted))]

ANCHOR_CAND_SB_TOPK   = globals().get("ANCHOR_CAND_SB_TOPK", 5)
ANCHOR_REQUIRE_TOP_SB = globals().get("ANCHOR_REQUIRE_TOP_SB", 3)
rank_pure = {int(df_sorted_pure.loc[i, "è»Šç•ª"]): i+1 for i in range(len(df_sorted_pure))}
cand_pool = [c for c in C if rank_pure.get(c, 999) <= ANCHOR_CAND_SB_TOPK]
if not cand_pool:
    cand_pool = [int(df_sorted_pure.loc[i, "è»Šç•ª"]) for i in range(min(ANCHOR_CAND_SB_TOPK, len(df_sorted_pure)))]
anchor_no_pre = max(cand_pool, key=lambda x: anchor_score(x)) if cand_pool else int(df_sorted_pure.loc[0, "è»Šç•ª"])
anchor_no = anchor_no_pre
top2 = sorted(cand_pool, key=lambda x: anchor_score(x), reverse=True)[:2]
if len(top2) >= 2:
    s1 = anchor_score(top2[0]); s2 = anchor_score(top2[1])
    if (s1 - s2) < TIE_EPSILON:
        better_by_rating = min(top2, key=lambda x: ratings_rank2.get(x, 999))
        anchor_no = better_by_rating
if rank_pure.get(anchor_no, 999) > ANCHOR_REQUIRE_TOP_SB:
    pool = [c for c in cand_pool if rank_pure.get(c, 999) <= ANCHOR_REQUIRE_TOP_SB]
    if pool:
        anchor_no = max(pool, key=lambda x: anchor_score(x))
    else:
        anchor_no = int(df_sorted_pure.loc[0, "è»Šç•ª"])
    st.caption(f"â€» â—ã¯ã€SBãªã— ä¸Šä½{ANCHOR_REQUIRE_TOP_SB}ä½ä»¥å†…ã€ç¸›ã‚Šã§ {anchor_no_pre}â†’{anchor_no} ã«èª¿æ•´ã€‚")

role_map = {no: role_in_line(no, line_def) for no in active_cars}
cand_scores = [anchor_score(no) for no in C] if len(C) >= 2 else [0, 0]
cand_scores_sorted = sorted(cand_scores, reverse=True)
conf_gap = cand_scores_sorted[0] - cand_scores_sorted[1] if len(cand_scores_sorted) >= 2 else 0.0
spread = float(np.std(list(v_final.values()))) if len(v_final) >= 2 else 0.0
norm = conf_gap / (spread if spread > 1e-6 else 1.0)
confidence = "å„ªä½" if norm >= 1.0 else ("äº’è§’" if norm >= 0.5 else "æ··æˆ¦")

score_adj_map = apply_anchor_line_bonus(v_final, car_to_group, role_map, anchor_no, confidence)

df_sorted_wo = pd.DataFrame({
    "è»Šç•ª": active_cars,
    "åˆè¨ˆ_SBãªã—": [round(float(score_adj_map.get(int(c), v_final.get(int(c), float("-inf")))), 6) for c in active_cars]
}).sort_values("åˆè¨ˆ_SBãªã—", ascending=False).reset_index(drop=True)

velobi_wo = list(zip(df_sorted_wo["è»Šç•ª"].astype(int).tolist(),
                     df_sorted_wo["åˆè¨ˆ_SBãªã—"].round(3).tolist()))

# ==============================
# â˜… ãƒ¬ãƒ¼ã‚¹å†…Tåå·®å€¤ â†’ å° â†’ è²·ã„ç›® â†’ noteå‡ºåŠ›ï¼ˆ2è»Šç³»å¯¾å¿œï¼‹ä¼šå ´å€‹æ€§æµ¸é€ç‰ˆï¼‰
# ==============================
import math
import numpy as np
import pandas as pd
import streamlit as st


# ===== ã—ãã„å€¤ï¼ˆSï¼åå·®å€¤Tã®åˆç®—ï¼‰ =====
S_TRIO_MIN_WIDE  = 158.0   # ä¸‰é€£è¤‡ï¼šæ‰‹åºƒã
S_TRIO_MIN_CORE  = 163.0   # ä¸‰é€£è¤‡ï¼šåŸºæº–ã‚¯ãƒªã‚¢ï¼ˆã“ã‚ŒãŒâ€œæœ¬ç·šâ€ï¼‰
S_QN_MIN         = 122.0
S_WIDE_MIN       = 116.0

# ä¸‰é€£å˜ã¯â€œåŸºæº–ã‚¯ãƒªã‚¢â€å´ã«åˆã‚ã›ã¦é‹ç”¨ï¼ˆç›¸è«‡ã©ãŠã‚Š164ï¼‰
S_TRIFECTA_MIN   = 164.0

# ç›®æ¨™å›åç‡ï¼ˆæ®ãˆç½®ãï¼‰
TARGET_ROI = {"trio":1.20, "qn":1.10, "wide":1.05}
ODDS_FLOOR_QN   = 8.0
ODDS_FLOOR_WIDE = 4.0
HEN_DEC_PLACES = 1
EPS = 1e-12


# ====== ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ ======
def coerce_score_map(d, n_cars: int) -> dict[int, float]:
    out: dict[int, float] = {}
    t = str(type(d)).lower()
    if "pandas.core.frame" in t:
        df_ = d
        car_col = "è»Šç•ª" if "è»Šç•ª" in df_.columns else None
        if car_col is None:
            for c in df_.columns:
                if np.issubdtype(df_[c].dtype, np.integer):
                    car_col = c; break
        score_col = None
        for cand in ["åˆè¨ˆ_SBãªã—","SBãªã—","ã‚¹ã‚³ã‚¢","score","SB_wo","SB"]:
            if cand in df_.columns:
                score_col = cand; break
        if score_col is None:
            for c in df_.columns:
                if c == car_col: continue
                if np.issubdtype(df_[c].dtype, np.number):
                    score_col = c; break
        if car_col is not None and score_col is not None:
            for _, r in df_.iterrows():
                try:
                    i = int(r[car_col]); x = float(r[score_col])
                except Exception:
                    continue
                out[i] = x
    elif "pandas.core.series" in t:
        for k, v in d.to_dict().items():
            try:
                i = int(k); x = float(v)
            except Exception:
                continue
            out[i] = x
    elif hasattr(d, "items"):
        for k, v in d.items():
            try:
                i = int(k); x = float(v)
            except Exception:
                continue
            out[i] = x
    elif isinstance(d, (list, tuple, np.ndarray)):
        arr = list(d)
        if len(arr) == n_cars and all(not isinstance(x,(list,tuple,dict)) for x in arr):
            for idx, v in enumerate(arr, start=1):
                try: out[idx] = float(v)
                except Exception: out[idx] = np.nan
        else:
            for it in arr:
                if isinstance(it,(list,tuple)) and len(it) >= 2:
                    try:
                        i = int(it[0]); x = float(it[1])
                        out[i] = x
                    except Exception:
                        continue
    for i in range(1, int(n_cars)+1):
        out.setdefault(i, np.nan)
    return out

def t_score_from_finite(values: np.ndarray, eps: float = 1e-9):
    v = values.astype(float, copy=True)
    finite = np.isfinite(v)
    k = int(finite.sum())
    if k < 2:
        return np.full_like(v, 50.0), (float("nan") if k==0 else float(v[finite][0])), 0.0, k
    mu = float(np.mean(v[finite]))
    sd = float(np.std(v[finite], ddof=0))
    if (not np.isfinite(sd)) or sd < eps:
        return np.full_like(v, 50.0), mu, 0.0, k
    T = 50.0 + 10.0 * ((v - mu) / sd)
    T[~finite] = 50.0
    return T, mu, sd, k


# â˜…Form ã®åå·®å€¤åŒ–ï¼ˆt_score_from_finite å®šç¾©ã®ç›´å¾Œï¼‰
form_list = [Form[n] for n in active_cars]
form_T, mu_form, sd_form, _ = t_score_from_finite(np.array(form_list))
form_T_map = {n: float(form_T[i]) for i, n in enumerate(active_cars)}






def _format_rank_from_array(ids, arr):
    pairs = [(i, float(arr[idx])) for idx, i in enumerate(ids)]
    pairs.sort(key=lambda kv: ((1,0) if not np.isfinite(kv[1]) else (0,-kv[1]), kv[0]))
    return " ".join(str(i) for i,_ in pairs)

# ====== ã“ã“ã‹ã‚‰å‡¦ç†æœ¬ä½“ ======

# 1) æ¯é›†å›£è»Šç•ª
try:
    USED_IDS = sorted(int(i) for i in (active_cars if active_cars else range(1, n_cars+1)))
except Exception:
    USED_IDS = list(range(1, int(n_cars)+1))
M = len(USED_IDS)

# 2) SBãªã—ã®ã‚½ãƒ¼ã‚¹ï¼ˆdfå„ªå…ˆâ†’velobi_woï¼‰
score_map_from_df = coerce_score_map(globals().get("df_sorted_wo", None), n_cars)
score_map_vwo     = coerce_score_map(globals().get("velobi_wo", None),   n_cars)
SB_BASE_MAP = score_map_from_df if any(np.isfinite(list(score_map_from_df.values()))) else score_map_vwo

# â˜…å¼·åˆ¶ï¼šåå·®å€¤ã®æ¯é›†å›£ã‚’ anchor_score ã«çµ±ä¸€ï¼ˆã“ã“ãŒå‘½ï¼‰
SB_BASE_MAP = {int(i): float(anchor_score(int(i))) for i in USED_IDS}


# 3) ã‚¹ã‚³ã‚¢é…åˆ—ï¼ˆã‚¹ã‚³ã‚¢é †è¡¨ç¤ºã¨åå·®å€¤æ¯é›†å›£ã‚’å…±ç”¨ï¼‰
xs_base_raw = np.array([SB_BASE_MAP.get(i, np.nan) for i in USED_IDS], dtype=float)

# 4) åå·®å€¤Tï¼ˆãƒ¬ãƒ¼ã‚¹å†…ï¼šå¹³å‡50ãƒ»SD10ã€NaNâ†’50ï¼‰
xs_race_t, mu_sb, sd_sb, k_finite = t_score_from_finite(xs_base_raw)




missing = ~np.isfinite(xs_base_raw)
if missing.any():
    sb_for_sort = {i: SB_BASE_MAP.get(i, -1e18) for i in USED_IDS}
    idxs = np.where(missing)[0].tolist()
    idxs.sort(key=lambda ii: (-float(sb_for_sort.get(USED_IDS[ii], -1e18)), USED_IDS[ii]))
    k = len(idxs); delta = 0.12; center = (k - 1)/2.0 if k > 1 else 0.0
    for r, ii in enumerate(idxs):
        xs_race_t[ii] = 50.0 + delta * (center - r)

# 5) dictåŒ–ãƒ»è¡¨ç¤ºç”¨
race_t = {USED_IDS[idx]: float(round(xs_race_t[idx], HEN_DEC_PLACES)) for idx in range(M)}

# === 5.5) ã‚¯ãƒ©ã‚¹åˆ¥ãƒ©ã‚¤ãƒ³åå·®å€¤ãƒœãƒ¼ãƒŠã‚¹ï¼ˆãƒ©ã‚¤ãƒ³é–“â†’ãƒ©ã‚¤ãƒ³å†…ï¼šä½Tå„ªå…ˆ 3:2:1ï¼‰ ===
# ã‚¯ãƒ©ã‚¹åˆ¥ã®ç·ãƒã‚¤ãƒ³ãƒˆï¼ˆGirlsã¯ç„¡åŠ¹ï¼‰
CLASS_LINE_POOL = {
    "ï¼³ç´š":           21.0,
    "ï¼¡ç´š":           15.0,
    "ï¼¡ç´šãƒãƒ£ãƒ¬ãƒ³ã‚¸":  9.0,
    "ã‚¬ãƒ¼ãƒ«ã‚º":        0.0,
}
pool_total = float(CLASS_LINE_POOL.get(race_class, 0.0))

def _line_rank_weights(n_lines: int) -> list[float]:
    # 2æœ¬: 3:2 / 3æœ¬: 5:4:3 / 4æœ¬ä»¥ä¸Š: 6,5,4,3,2,1...
    if n_lines <= 1: return [1.0]
    if n_lines == 2: return [3.0, 2.0]
    if n_lines == 3: return [5.0, 4.0, 3.0]
    base = [6.0, 5.0, 4.0, 3.0, 2.0, 1.0]
    if n_lines <= len(base): return base[:n_lines]
    ext = base[:]
    while len(ext) < n_lines:
        ext.append(max(1.0, ext[-1]-1.0))
    return ext[:n_lines]

def _in_line_weights(members_sorted_lowT_first: list[int]) -> dict[int, float]:
    # ãƒ©ã‚¤ãƒ³å†…ã¯ã€Œä½Tå„ªå…ˆã§ 3:2:1ã€4äººç›®ä»¥é™0ã€â†’åˆè¨ˆ1ã«æ­£è¦åŒ–
    raw = [3.0, 2.0, 1.0]
    w = {}
    for i, car in enumerate(members_sorted_lowT_first):
        w[int(car)] = (raw[i] if i < len(raw) else 0.0)
    s = sum(w.values())
    return {k: (v/s if s > 0 else 0.0) for k, v in w.items()}

_lines = list((globals().get("line_def") or {}).values())
if pool_total > 0.0 and _lines:
    # ãƒ©ã‚¤ãƒ³å¼·åº¦ï¼ãã®ãƒ©ã‚¤ãƒ³ã® race_t å¹³å‡
    line_scores = []
    for mem in _lines:
        if not mem: 
            continue
        avg_t = float(np.mean([race_t.get(int(c), 50.0) for c in mem]))
        line_scores.append((tuple(mem), avg_t))
    # å¼·ã„é †ã«ä¸¦ã¹ã¦ãƒ©ã‚¤ãƒ³é–“ãƒã‚¤ãƒ³ãƒˆé…åˆ†
    line_scores.sort(key=lambda x: (-x[1], x[0]))
    rank_w = _line_rank_weights(len(line_scores))
    sum_rank_w = float(sum(rank_w)) if rank_w else 1.0
    line_share = {}
    for (mem, _avg), wr in zip(line_scores, rank_w):
        line_share[mem] = pool_total * (float(wr) / sum_rank_w)

    # å„ãƒ©ã‚¤ãƒ³ã®é…åˆ†ã‚’ã€Œä½Tâ†’é«˜Tã€ã®é †ã« 3:2:1 ã§å‰²ã‚ŠæŒ¯ã‚Š
    bonus_map = {int(i): 0.0 for i in USED_IDS}
    for mem, share in line_share.items():
        mem = list(mem)
        mem_sorted_lowT = sorted(mem, key=lambda c: (race_t.get(int(c), 50.0), int(c)))
        w_in = _in_line_weights(mem_sorted_lowT)  # åˆè¨ˆ1
        for car in mem_sorted_lowT:
            bonus_map[int(car)] += share * w_in[int(car)]

    # åå·®å€¤ã«åŠ ç®—ï¼ˆxs_race_tãŒè¨ˆç®—æœ¬ä½“ã€‚race_tã¯è¡¨ç¤ºç”¨ã«ä¸¸ã‚ç›´ã™ï¼‰
    for idx, car in enumerate(USED_IDS):
        add = float(bonus_map.get(int(car), 0.0))
        xs_race_t[idx] = float(xs_race_t[idx]) + add
        race_t[int(car)] = float(round(xs_race_t[idx], HEN_DEC_PLACES))
# â† ã“ã®å¾Œã«æ—¢å­˜ã® race_z è¨ˆç®—ãŒç¶šã



race_z = (xs_race_t - 50.0) / 10.0

hen_df = pd.DataFrame({
    "è»Š": USED_IDS,
    "SBãªã—(æ¯é›†å›£)": [None if not np.isfinite(x) else float(x) for x in xs_base_raw],
    "åå·®å€¤T(ãƒ¬ãƒ¼ã‚¹å†…)": [race_t[i] for i in USED_IDS],
}).sort_values(["åå·®å€¤T(ãƒ¬ãƒ¼ã‚¹å†…)","è»Š"], ascending=[False, True]).reset_index(drop=True)

st.markdown("### åå·®å€¤ï¼ˆãƒ¬ãƒ¼ã‚¹å†…Tï¼å¹³å‡50ãƒ»SD10ï½œSBãªã—ã¨åŒä¸€æ¯é›†å›£ï¼‰")
st.caption(f"Î¼={mu_sb if np.isfinite(mu_sb) else 'nan'} / Ïƒ={sd_sb:.6f} / æœ‰åŠ¹ä»¶æ•°k={k_finite}")
st.dataframe(hen_df, use_container_width=True)

# 6) PLç”¨é‡ã¿ï¼ˆè³¼å…¥è¨ˆç®—ã«ä½¿ç”¨ï¼šæ—¢å­˜è¿‘ä¼¼ï¼‰
tau = 1.0
w   = np.exp(race_z * tau)
S_w = float(np.sum(w))
w_idx = {USED_IDS[idx]: float(w[idx]) for idx in range(M)}

def prob_top2_pair_pl(i: int, j: int) -> float:
    wi, wj = w_idx[i], w_idx[j]
    d_i = max(S_w - wi, EPS); d_j = max(S_w - wj, EPS)
    return (wi / S_w) * (wj / d_i) + (wj / S_w) * (wi / d_j)

def prob_top3_triple_pl(i: int, j: int, k: int) -> float:
    a, b, c = w_idx[i], w_idx[j], w_idx[k]
    total = 0.0
    for x, y, z in ((a,b,c),(a,c,b),(b,a,c),(b,c,a),(c,a,b),(c,b,a)):
        d1 = max(S_w - x, EPS)
        d2 = max(S_w - x - y, EPS)
        total += (x / S_w) * (y / d1) * (z / d2)
    return total

def prob_wide_pair_pl(i: int, j: int) -> float:
    total = 0.0
    for k in USED_IDS:
        if k == i or k == j: continue
        total += prob_top3_triple_pl(i, j, k)
    return total

# 7) å°ï¼ˆâ—ã€‡â–²ï¼‰ï¼ Tâ†“ â†’ SBãªã—â†“ â†’ è»Šç•ªâ†‘ï¼ˆÎ²ã¯é™¤å¤–ï¼‰
if "select_beta" not in globals():
    def select_beta(cars): return None
if "enforce_alpha_eligibility" not in globals():
    def enforce_alpha_eligibility(m): return m

# ===== Î²ãƒ©ãƒ™ãƒ«ä»˜ä¸ï¼ˆå˜ãªã‚‹é †ä½ãƒ©ãƒ™ãƒ«ï¼‰ =====
def assign_beta_label(result_marks: dict[str,int], used_ids: list[int], df_sorted) -> dict[str,int]:
    marks = dict(result_marks)
    # 6è»Šä»¥ä¸‹ã¯å‡ºã•ãªã„ï¼ˆé›†è¨ˆä»•æ§˜ï¼‰
    if len(used_ids) <= 6:
        return marks
    # æ—¢ã«Î²ãŒã‚ã‚Œã°ä½•ã‚‚ã—ãªã„
    if "Î²" in marks:
        return marks
    try:
        last_car = int(df_sorted.loc[len(df_sorted)-1, "è»Šç•ª"])
        if last_car not in marks.values():
            marks["Î²"] = last_car
    except Exception:
        pass
    return marks


# ===== å°ã®æ¡ç•ªï¼ˆÎ²å»ƒæ­¢â†’ç„¡å°ã§ä¿æŒï¼‰========================================
# ä¾å­˜: USED_IDS, race_t, xs_base_raw, line_def, car_to_group ãŒä¸Šã§å®šç¾©æ¸ˆã¿

# ã‚¹ã‚³ã‚¢ã®è£œåŠ©ï¼ˆå®‰å®šã®ãŸã‚ race_t å„ªå…ˆâ†’åŒç‚¹ã¯ sb_base ã§ã‚¿ã‚¤ãƒ–ãƒ¬ãƒ¼ã‚¯ï¼‰
sb_base = {
    int(USED_IDS[idx]): float(xs_base_raw[idx]) if np.isfinite(xs_base_raw[idx]) else float("-inf")
    for idx in range(len(USED_IDS))
}

def _race_t_val(i: int) -> float:
    try:
        return float(race_t.get(int(i), 50.0))
    except Exception:
        return 50.0

# === Î²ã¯ä½œã‚‰ãªã„ã€‚å…¨å“¡ã‚’å€™è£œã«ã—ã¦ä¸Šä½ã‹ã‚‰å°ã‚’æŒ¯ã‚‹
seed_pool = list(map(int, USED_IDS))
order_by_T = sorted(
    seed_pool,
    key=lambda i: (-_race_t_val(i), -sb_base.get(i, float("-inf")), i)
)

result_marks: dict[str,int] = {}
reasons: dict[int,str] = {}

# â—ã€‡â–² ã‚’ä¸Šä½ã‹ã‚‰
for mk, car in zip(["â—","ã€‡","â–²"], order_by_T):
    result_marks[mk] = int(car)

# â—ã®åŒãƒ©ã‚¤ãƒ³ã‚’å„ªå…ˆã—ã¦æ®‹ã‚Šå°ï¼ˆâ–³, Ã—, Î±ï¼‰ã‚’åŸ‹ã‚ã‚‹
line_def     = globals().get("line_def", {}) or {}
car_to_group = globals().get("car_to_group", {}) or {}
anchor_no    = result_marks.get("â—", None)

mates_sorted: list[int] = []
if anchor_no is not None:
    a_gid = car_to_group.get(anchor_no, None)
    if a_gid is not None and a_gid in line_def:
        used_now = set(result_marks.values())
        mates_sorted = sorted(
            [int(c) for c in line_def[a_gid] if int(c) not in used_now],
            key=lambda x: (-sb_base.get(int(x), float("-inf")), int(x))
        )

used = set(result_marks.values())
overall_rest = [int(c) for c in USED_IDS if int(c) not in used]
overall_rest = sorted(
    overall_rest,
    key=lambda x: (-sb_base.get(int(x), float("-inf")), int(x))
)

# åŒãƒ©ã‚¤ãƒ³å„ªå…ˆ â†’ æ®‹ã‚Šã‚¹ã‚³ã‚¢é †
tail_priority = mates_sorted + [c for c in overall_rest if c not in mates_sorted]

for mk in ["â–³","Ã—","Î±"]:
    if mk in result_marks:
        continue
    if not tail_priority:
        break
    no = int(tail_priority.pop(0))
    result_marks[mk] = no
    reasons[no] = f"{mk}ï¼ˆâ—ãƒ©ã‚¤ãƒ³å„ªå…ˆâ†’æ®‹ã‚Šã‚¹ã‚³ã‚¢é †ï¼‰"

# === ç„¡å°ã®é›†åˆï¼ˆï¼ä¸Šã®å°ãŒä»˜ã‹ãªã‹ã£ãŸæ®‹ã‚Šå…¨å“¡ï¼‰
marked_ids = set(result_marks.values())
no_mark_ids = [int(c) for c in USED_IDS if int(c) not in marked_ids]
# è¡¨ç¤ºã¯Tå„ªå…ˆãƒ»åŒç‚¹ã¯sb_base
no_mark_ids = sorted(
    no_mark_ids,
    key=lambda x: (-_race_t_val(int(x)), -sb_base.get(int(x), float("-inf")), int(x))
)

# ===== ä»¥é™ã®UIå‡ºåŠ›ã§ã®ä½¿ã„æ–¹ ==============================================
# ãƒ»å°ã®ä¸€è¡Œï¼ˆnoteç”¨ï¼‰: æ—¢å­˜ã® join ã‚’å·®ã—æ›¿ãˆ
#   ä¾‹ï¼‰(' '.join(f'{m}{result_marks[m]}' for m in ['â—','ã€‡','â–²','â–³','Ã—','Î±'] if m in result_marks))
#   ã®ç›´å¾Œãªã©ã«ã€Œç„¡ã€ã‚’è¿½åŠ 
#   ä¾‹ï¼‰
#   ('ç„¡ã€€' + (' '.join(map(str, no_mark_ids)) if no_mark_ids else 'â€”'))
#
# ãƒ»ä»¥é™ã®ãƒ­ã‚¸ãƒƒã‚¯ã§ã¯ã€ŒÎ²ã€ã¸ã®å‚ç…§ã‚’æ®‹ã•ãªã„ã“ã¨ï¼ˆNoneãƒã‚§ãƒƒã‚¯å«ã‚å…¨å‰Šé™¤OKï¼‰
#   ã‚‚ã— `if i != result_marks.get("Î²")` ã®ã‚ˆã†ãªè¡ŒãŒæ®‹ã£ã¦ã„ãŸã‚‰ã€å˜ã«å‰Šé™¤ã—ã¦ãã ã•ã„ã€‚


if "Î±" not in result_marks:
    used_now = set(result_marks.values())
    pool = [i for i in USED_IDS if i not in used_now]
    if pool:
        alpha_pick = pool[-1]
        result_marks["Î±"] = alpha_pick
        reasons[alpha_pick] = reasons.get(alpha_pick, "Î±ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šç¦æ­¢æ¡ä»¶å…¨æ»…â†’æœ€å¼±ã‚’æ¡ç”¨ï¼‰")


# -*- coding: utf-8 -*-
import streamlit as st
import numpy as np
import pandas as pd
import math
from statistics import mean, pstdev



# ===== åŸºæœ¬ãƒ‡ãƒ¼ã‚¿ =====
S_TRIFECTA_MIN = globals().get("S_TRIFECTA_MIN", 164.0)  # ä¸‰é€£å˜åŸºæº–

# ===== å¯å¤‰ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆç·©ã‚è¨­å®šï¼šé€šéæ•°â†‘ï¼‰=====
TRIO_SIG_DIV        = float(globals().get("TRIO_SIG_DIV", 5.5))   # ä¸‰é€£è¤‡ï¼š1.5â†’2.0ã§ã»ã‚“ã®ã‚Šç·©ã‚
TRIFECTA_SIG_DIV    = float(globals().get("TRIFECTA_SIG_DIV", 5.5))# ä¸‰é€£å˜ï¼š2.5â†’3.5ã§ç·©ã‚

# L3 / ä¸‰é€£å˜ã®å›ºå®šã‚²ãƒ¼ãƒˆã‚‚å°‘ã—ç·©ã‚ã‚‹ï¼ˆè²·ã„ç›®å¢—ã‚„ã—ãŸã„ãªã‚‰ä¸‹ã’ã‚‹ï¼‰
TRIO_L3_MIN         = float(globals().get("TRIO_L3_MIN", 155.0))   # 160.0â†’155.0
S_TRIFECTA_MIN      = float(globals().get("S_TRIFECTA_MIN", 160.0))# 164.0â†’160.0

# ï¼ˆã‚‚ã—ãƒ•ã‚¡ã‚¤ãƒ«å†…ã«ã‚ã‚‹ãªã‚‰ï¼‰äºŒè»Šç³»ã‚‚åŒæ§˜ã«å°‘ã—ç·©ã‚ã‚‹
QN_SIG_DIV          = float(globals().get("QN_SIG_DIV", 3.5))      # 3.0â†’3.5 ãªã©
NIT_SIG_DIV         = float(globals().get("NIT_SIG_DIV", 3.5))     # 3.0â†’3.5 ãªã©


from statistics import mean, pstdev
from itertools import product, combinations

# ===== ã‚¹ã‚³ã‚¢ï¼ˆåå·®å€¤Tåˆè¨ˆï¼‰ =====
S_BASE_MAP = {int(i): float(race_t.get(int(i), 50.0)) for i in USED_IDS}
def _pair_score(a, b):   return S_BASE_MAP.get(a, 0.0) + S_BASE_MAP.get(b, 0.0)
def _trio_score(a, b, c): return S_BASE_MAP.get(a, 0.0) + S_BASE_MAP.get(b, 0.0) + S_BASE_MAP.get(c, 0.0)

# Î²/Ã— ã‚’å®‰å…¨ã«æ‹¾ã†ï¼ˆç„¡ã‘ã‚Œã° Noneï¼‰
mark_beta = (result_marks["Î²"] if ("result_marks" in globals() and "Î²" in result_marks) else None)
mark_x    = (result_marks["Ã—"] if ("result_marks" in globals() and "Ã—" in result_marks) else None)

def _santan_score(a:int, b:int, c:int) -> float:
    base = _trio_score(a,b,c)
    bonus = 0.0
    if 'anchor_no' in globals() and a == anchor_no:  # 1ç€ã«â—ãªã‚‰åŠ ç‚¹
        bonus += 2.0
    if c is not None and (c == mark_beta or c == mark_x):  # 3ç€ã«Î²/Ã—ãªã‚‰æ¸›ç‚¹
        bonus -= 1.0
    return base + bonus


def _top_k_unique(seq, k):
    out, seen = [], set()
    for x in seq:
        if x in seen: continue
        seen.add(x); out.append(x)
        if len(out) >= k: break
    return out

# ---------- L1/L2ï¼ˆNã‚²ãƒ¼ãƒˆï¼‹Tã‚²ãƒ¼ãƒˆã®åˆæµï¼‰ ----------
# Nã‚²ãƒ¼ãƒˆï¼šäºŒè»Šå˜ rows_nitan ã‹ã‚‰ 1ç€/2ç€ã®é †ã«å€™è£œã‚’æŠ½å‡º
n1_list, n2_list = [], []
for k,_s in (rows_nitan if 'rows_nitan' in globals() and rows_nitan else []):
    try:
        a,b = map(int, k.split("-"))
        n1_list.append(a); n2_list.append(b)
    except Exception:
        pass
L1N = _top_k_unique(n1_list, 3)
L2N = _top_k_unique(n2_list, 4)

# Tã‚²ãƒ¼ãƒˆï¼šåå·®å€¤Tä¸Šä½ï¼ˆâ—ãƒ»ã€‡ã‚’ç¨®ã«åŠ ãˆã‚‹ï¼‰
T_sorted = sorted(USED_IDS, key=lambda i: (-S_BASE_MAP.get(i,50.0), i))
L1T_seed = [result_marks.get("â—")] if result_marks.get("â—") is not None else []
L2T_seed = [result_marks.get("ã€‡")] if result_marks.get("ã€‡") is not None else []
L1T = _top_k_unique(L1T_seed + T_sorted, 3)
L2T = _top_k_unique(L2T_seed + [i for i in T_sorted if i not in L1T], 4)

# åˆæµ
L1 = sorted(set(L1N) | set(L1T))
L2 = sorted(set(L2N) | set(L2T))

# ---------- L3ï¼ˆ3åˆ—ç›®å€™è£œï¼‰ ----------
# æ—¢å­˜ã®ä¸‰é€£å˜ rows_trifecta ãŒã‚ã‚Œã°ã€ãã®3åˆ—ç›®ã®ã¿ã‚’æ¡ç”¨
def _collect_l3_from_trifecta(rows):
    s = set()
    for k,_sv in rows:
        try:
            a,b,c = map(int, k.split("-"))
            s.add(c)
        except Exception:
            pass
    return s

trifecta_ok = bool(('rows_trifecta' in globals()) and rows_trifecta)
L3_from_tri = _collect_l3_from_trifecta(rows_trifecta) if trifecta_ok else set()

# â˜…ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šL1Ã—L2 ã¨ä»»æ„ã® c ã§ S â‰¥ TRIO_L3_MIN ã‚’æº€ãŸã™ c ã‚’æŠ½å‡ºï¼ˆé‡è¤‡æ’é™¤ï¼‰
L3_from_160 = set()
for a in L1:
    for b in L2:
        if a == b: continue
        for c in USED_IDS:
            if c in (a,b): continue
            if _trio_score(a,b,c) >= TRIO_L3_MIN:
                L3_from_160.add(int(c))

# æœ€çµ‚L3ã¯ã€Œä¸‰å˜ç”±æ¥ âˆª 160ã—ãã„å€¤ã€ã®å’Œé›†åˆ
L3 = sorted(L3_from_tri | L3_from_160)

# --- ã“ã“ã‹ã‚‰å·®ã—è¾¼ã¿ï¼ˆL3ãŒå…¨è»ŠåŒ–ã™ã‚‹ã®ã‚’é˜²ãï¼‰ ---
L3_TMIN = float(globals().get("L3_TMIN", 52.0))  # ä¾‹: 52.0ã§ä½Tã‚’åˆ‡ã‚‹ï¼ˆè¦èª¿æ•´ï¼‰
L3_TOPK = int(globals().get("L3_TOPK", 5))       # ä¾‹: ä¸Šä½5åã¾ã§
L3 = [c for c in L3 if race_t.get(int(c), 50.0) >= L3_TMIN]
L3 = sorted(L3, key=lambda c: (-race_t.get(int(c), 50.0), int(c)))[:L3_TOPK]
# --- å·®ã—è¾¼ã¿ã“ã“ã¾ã§ ---


# =========================
#  ãƒ•ã‚©ãƒ¼ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³è¡¨ç¤º
# =========================
def _fmt_form(col):
    return "".join(str(x) for x in col) if col else "â€”"

form_L1 = _fmt_form(L1)
form_L2 = _fmt_form(L2)
form_L3 = _fmt_form(L3)
formation_label = f"{form_L1}-{form_L2}-{form_L3}"
st.markdown(f"**ãƒ•ã‚©ãƒ¼ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³**ï¼š{formation_label}")

# æ—¢å­˜ï¼šä¸‰é€£è¤‡/ä¸‰é€£å˜ã®åŸºç¤ã‚¹ã‚³ã‚¢è¨ˆç®—é–¢æ•°ãŒç„¡ã„å ´åˆã®ä¿é™º
if '_trio_score' not in globals():
    S_BASE_MAP = {int(i): float(race_t.get(int(i), 50.0)) for i in USED_IDS}
    def _trio_score(a, b, c):
        return S_BASE_MAP.get(int(a), 0.0) + S_BASE_MAP.get(int(b), 0.0) + S_BASE_MAP.get(int(c), 0.0)

# æ—¢å­˜ï¼šä¸‰é€£å˜ã®é †åºä»˜ãã‚¹ã‚³ã‚¢ãŒç„¡ã„å ´åˆã®ä¿é™º
if '_santan_score' not in globals():
    def _santan_score(a:int, b:int, c:int) -> float:
        base = _trio_score(a,b,c)
        bonus = 0.0
        if 'anchor_no' in globals() and a == anchor_no:
            bonus += 2.0
        return base + bonus

# =========================
#  å°ã®å–å¾—
# =========================
mark_star   = result_marks.get("â—")
mark_circle = result_marks.get("ã€‡")



# ----------------------------
# çµ±ä¸€ç‰ˆï¼šãƒ•ã‚©ãƒ¼ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³â†’ä¸‰é€£è¤‡/ä¸‰é€£å˜/äºŒè»Šè¤‡/äºŒè»Šå˜â†’note å‡ºåŠ›
# ç›®çš„ï¼šÎ¼ + Ïƒ/div ã¨ ä¸Šä½å‰²åˆ(top-q) ã®ä¸¡æ–¹ã‚’ç®—å‡ºã—ã¦ã€Œé«˜ã„æ–¹ã€ã‚’é–¾å€¤æ¡ç”¨ï¼ˆå…¨ã‚»ã‚¯ã‚·ãƒ§ãƒ³çµ±ä¸€ï¼‰
# ----------------------------

from statistics import mean, pstdev
from itertools import product
import numpy as np

# å¯å¤‰ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆã‚°ãƒ­ãƒ¼ãƒãƒ«æŒ‡å®šãŒã‚ã‚Œã°ãã‚Œã‚’å„ªå…ˆï¼‰
TRIO_SIG_DIV      = float(globals().get("TRIO_SIG_DIV", 3.0))
TRIO_L3_MIN       = float(globals().get("TRIO_L3_MIN", 160.0))
TRIO_TOP_FRAC     = float(globals().get("TRIO_TOP_FRAC", 0.20))   # ä¸Šä½æ¯”ç‡ï¼ˆä¾‹ 0.2 = 1/5ï¼‰
TRIFECTA_SIG_DIV  = float(globals().get("TRIFECTA_SIG_DIV", 8.0))
TRIFECTA_TOP_FRAC = float(globals().get("TRIFECTA_TOP_FRAC", 1/8))# 1/8 ç­‰
QN_TOP_FRAC       = float(globals().get("QN_TOP_FRAC", 0.20))     # äºŒè»Šè¤‡ ä¸Šä½æ¯”ç‡
NIT_TOP_FRAC      = float(globals().get("NIT_TOP_FRAC", 1/8))     # äºŒè»Šå˜ ä¸Šä½æ¯”ç‡

# safety defaults
anchor_no   = globals().get("anchor_no", result_marks.get("â—") if 'result_marks' in globals() else None)
mark_circle = globals().get("mark_circle", result_marks.get("ã€‡") if 'result_marks' in globals() else None)
gid         = car_to_group.get(anchor_no, None) if anchor_no is not None else None

# ------------ ãƒ•ã‚©ãƒ¼ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³è¡¨ç¤ºï¼ˆæ—¢å­˜ã® formation_label ã‚’ãã®ã¾ã¾ï¼‰ ------------
def _fmt_form(col):
    return "".join(str(x) for x in col) if col else "â€”"
form_L1 = _fmt_form(L1)
form_L2 = _fmt_form(L2)
form_L3 = _fmt_form(L3)
formation_label = f"{form_L1}-{form_L2}-{form_L3}"
st.markdown(f"**ãƒ•ã‚©ãƒ¼ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³**ï¼š{formation_label}")

# ------------ ãƒ˜ãƒ«ãƒ‘ï¼šé–¾å€¤ç®—å‡ºï¼ˆÎ¼+Ïƒ/div ã¨ ä¸Šä½q ã‚’æ¯”è¼ƒã—ã¦é«˜ã„æ–¹ã‚’è¿”ã™ï¼‰ ------------
def cutoff_mu_sig_vs_top(xs, sig_div, top_frac):
    """xs: list of scores, sig_div: denominator for sigma, top_frac: fraction retained (0<top_frac<=1)."""
    if not xs:
        return 0.0
    mu = float(mean(xs))
    sig = float(pstdev(xs)) if len(xs) > 1 else 0.0
    cutoff_mu_sig = mu + (sig / sig_div if sig > 0 else 0.0)
    q = max(1, int(len(xs) * top_frac))
    cutoff_topq = float(np.partition(xs, -q)[-q]) if xs else cutoff_mu_sig
    return max(cutoff_mu_sig, cutoff_topq)

# ---- ãƒ¦ãƒ‹ãƒ¼ã‚¯åŒ– & è‡ªå·±é‡è¤‡ã‚¬ãƒ¼ãƒ‰ï¼ˆå…±é€šãƒ˜ãƒ«ãƒ‘ï¼šä¸€åº¦ã ã‘èª­ã¿è¾¼ã‚ã°OKï¼‰ ----
if "_uniq_trio" not in globals():

    def _uniq_trio(rows):
        """ä¸‰é€£è¤‡: (a,b,c,s,tag) â†’ ä¸‰è€…ç›¸é• & æ˜‡é †ã‚­ãƒ¼ã§ä¸€æ„åŒ–"""
        seen, out = set(), []
        for a,b,c,s,tag in rows:
            a, b, c = int(a), int(b), int(c)
            if len({a,b,c}) < 3:
                continue
            key = tuple(sorted((a,b,c)))
            if key in seen:
                continue
            seen.add(key)
            out.append((key[0], key[1], key[2], s, tag))
        return out

    def _uniq_trifecta(rows):
        """ä¸‰é€£å˜: (a,b,c,s,tag) â†’ ä¸‰è€…ç›¸é• & ä¸¦ã³å›ºå®šã§ä¸€æ„åŒ–"""
        seen, out = set(), []
        for a,b,c,s,tag in rows:
            a, b, c = int(a), int(b), int(c)
            if len({a,b,c}) < 3:
                continue
            key = (a,b,c)
            if key in seen:
                continue
            seen.add(key)
            out.append((a,b,c,s,tag))
        return out

    def _uniq_qn(rows):
        """äºŒè»Šè¤‡: (a,b,s,tag) â†’ a!=bã€æ˜‡é †ã‚­ãƒ¼ã§ä¸€æ„åŒ–"""
        seen, out = set(), []
        for a,b,s,tag in rows:
            a, b = int(a), int(b)
            if a == b:
                continue
            key = tuple(sorted((a,b)))
            if key in seen:
                continue
            seen.add(key)
            out.append((key[0], key[1], s, tag))
        return out

    def _uniq_nitan(rows):
        """äºŒè»Šå˜: ("a-b", s, tag) â†’ a!=bã€ä¸¦ã³å›ºå®šã§ä¸€æ„åŒ–"""
        seen, out = set(), []
        for k, s, tag in rows:
            try:
                a, b = map(int, str(k).split("-"))
            except Exception:
                continue
            if a == b:
                continue
            key = f"{a}-{b}"
            if key in seen:
                continue
            seen.add(key)
            out.append((key, s, tag))
        return out


# ===== ä¸‰é€£è¤‡ï¼ˆä¸Šä½1/5 + ãƒ©ã‚¤ãƒ³æ ï¼‰ï¼œLOCKä»˜ãï¼ =====
# å…ˆé ­ã«ã“ã‚Œã‚’ç½®ãï¼šäºŒé‡å®šç¾©ã‚¬ãƒ¼ãƒ‰
if globals().get("__TRIO_LOCK__", False):
    # ã™ã§ã«ä¸‰é€£è¤‡ã‚’è¨ˆç®—æ¸ˆã¿ãªã‚‰ã€å†è¨ˆç®—ã—ãªã„
    pass
else:
    __TRIO_LOCK__ = True  # â† ãƒ­ãƒƒã‚¯

    trios_filtered_display, cutoff_trio = [], 0.0
    if L1 and L2 and L3:
        trio_keys = set()
        for a, b, c in product(L1, L2, L3):
            if len({a,b,c}) != 3:
                continue
            trio_keys.add(tuple(sorted((int(a), int(b), int(c)))))
        trios_from_cols = [(a,b,c,_trio_score(a,b,c)) for (a,b,c) in sorted(trio_keys)]
        if trios_from_cols:
            xs = [s for (*_,s) in trios_from_cols]
            mu, sig = mean(xs), pstdev(xs)
            TRIO_SIG_DIV = float(globals().get("TRIO_SIG_DIV", 3.0))
            cutoff_mu_sig = mu + (sig/TRIO_SIG_DIV if sig > 0 else 0.0)
            q = max(1, int(len(xs)*0.20))  # ä¸Šä½1/5
            cutoff_topQ = np.partition(xs, -q)[-q]
            cutoff_trio = max(cutoff_mu_sig, float(cutoff_topQ))
            trios_filtered_display = [
                (a,b,c,s,"é€šå¸¸") for (a,b,c,s) in trios_from_cols if s >= cutoff_trio
            ]

# === ãƒ©ã‚¤ãƒ³ãƒ‘ãƒ¯ãƒ¼æ ï¼ˆä¸‰é€£è¤‡ï¼šæœ€å¤§2ç‚¹ï¼‰ ===
line_power_added = []
gid = car_to_group.get(anchor_no, None) if 'anchor_no' in globals() else None
if gid in line_def:
    mem = [int(x) for x in line_def.get(gid, [])]
    if anchor_no in mem:
        others = [x for x in mem if x != anchor_no]

        # A) â—-ã€‡-ï¼ˆâ—ãƒ©ã‚¤ãƒ³ã®èª°ã‹ï¼‰ã‚’å„ªå…ˆ
        mark_star   = result_marks.get("â—")
        mark_circle = result_marks.get("ã€‡")
        if mark_circle:
            for extra in others:
                if extra in {anchor_no, mark_circle}:  # è‡ªå·±é‡è¤‡é˜²æ­¢
                    continue
                k = tuple(sorted((int(anchor_no), int(mark_circle), int(extra))))
                if not any(set(k) == {a,b,c} for (a,b,c,_,_) in trios_filtered_display + line_power_added):
                    line_power_added.append((k[0],k[1],k[2],_trio_score(*k),"ãƒ©ã‚¤ãƒ³æ "))
                if len(line_power_added) >= 2:
                    break

        # B) ç´”ãƒ©ã‚¤ãƒ³å®Œçµï¼ˆâ—ï¼‹åŒãƒ©ã‚¤ãƒ³ä¸Šä½2åï¼‰
        if len(line_power_added) < 2 and len(others) >= 2:
            a,b = sorted(others, key=lambda x: float(race_t.get(int(x),50.0)), reverse=True)[:2]
            if a != b and anchor_no not in {a,b}:
                k = tuple(sorted((int(anchor_no), int(a), int(b))))
                if not any(set(k) == {a,b,c} for (a,b,c,_,_) in trios_filtered_display + line_power_added):
                    line_power_added.append((k[0],k[1],k[2],_trio_score(*k),"ãƒ©ã‚¤ãƒ³æ "))

trios_filtered_display.extend(line_power_added[:2])
# é‡è¤‡ãƒ»è‡ªå·±é‡è¤‡ã‚’æœ€çµ‚é™¤å»
trios_filtered_display = _uniq_trio(trios_filtered_display)
n_trio = len(trios_filtered_display)

# ============================================================
# æˆ¦è¡“ï¼šä¸‰é€£è¤‡ã€Œâ—å…¥ã‚Š3ç‚¹ / â—æŠœã3ç‚¹ï¼ˆå°åˆ¥3ç€ç‡3ä½ã®å°ã‚’è»¸ï¼‰ã€å…¨é¢äº¤æ›ç‰ˆ
# ============================================================

import itertools

# ---------------- ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ ----------------

def _is_valid_trio(a, b, c) -> bool:
    """ä¸‰é€£è¤‡å€™è£œã¨ã—ã¦åŒä¸€ç•ªå·ã‚’æ’é™¤ï¼ˆä¾‹: 1-5-5 ã‚’å¼¾ãï¼‰"""
    try:
        aa, bb, cc = int(a), int(b), int(c)
    except Exception:
        return False
    return len({aa, bb, cc}) == 3

def _trio_key(a, b, c):
    """é †ä¸åŒã®ä¸€æ„ã‚­ãƒ¼ï¼ˆ1-3-4 ã¨ 4-3-1 ã‚’åŒä¸€è¦–ï¼‰"""
    aa, bb, cc = sorted(map(int, (a, b, c)))
    return (aa, bb, cc)

def _ensure_top3(primary_rows, fallback_rows, need=3):
    """
    primary_rows / fallback_rows: [(a,b,c,score,tag), ...]
    1) primary ã‹ã‚‰ã‚¹ã‚³ã‚¢å„ªå…ˆã§æ¡ç”¨
    2) è¶³ã‚Šãªã„åˆ†ã‚’ fallback ã‹ã‚‰è£œå®Œ
    3) 1-5-5 ç­‰ã¯ç„¡åŠ¹ã€é‡è¤‡ã¯1ç‚¹åŒ–
    4) åŒç‚¹ã¯åå·®å€¤Tåˆè¨ˆã§ã‚¿ã‚¤ãƒ–ãƒ¬ãƒ¼ã‚¯
    """
    def _rank_tuple(row):
        a, b, c, s, _ = row
        # åŒç‚¹æ™‚ã®ã‚¿ã‚¤ãƒ–ãƒ¬ãƒ¼ã‚¯ã«åå·®å€¤Tåˆè¨ˆã‚’ä½¿ç”¨ï¼ˆrace_t ãŒç„¡ã„æ™‚ã¯ 150 æ‰±ã„ï¼‰
        tsum = (
            float((race_t.get(int(a), 50.0) if 'race_t' in globals() and isinstance(race_t, dict) else 50.0)) +
            float((race_t.get(int(b), 50.0) if 'race_t' in globals() and isinstance(race_t, dict) else 50.0)) +
            float((race_t.get(int(c), 50.0) if 'race_t' in globals() and isinstance(race_t, dict) else 50.0))
        )
        return (float(s), float(tsum))

    out, seen = [], set()
    for src in (
        sorted(primary_rows or [], key=_rank_tuple, reverse=True),
        sorted(fallback_rows or [], key=_rank_tuple, reverse=True),
    ):
        for a, b, c, s, tag in src:
            if not _is_valid_trio(a, b, c):
                continue
            k = _trio_key(a, b, c)
            if k in seen:
                continue
            seen.add(k)
            out.append((int(a), int(b), int(c), float(s), str(tag)))
            if len(out) >= int(need):
                return out
    return out

def _safe_iter(lst):
    return lst if isinstance(lst, (list, tuple)) else []

def _get_used_ids():
    try:
        return sorted(map(int, globals().get("USED_IDS", [])))
    except Exception:
        return []

def _trio_score_safe(a, b, c):
    # æ—¢å­˜ã® _trio_score ãŒã‚ã‚Œã°ä½¿ã„ã€ç„¡ã‘ã‚Œã°åå·®å€¤Tåˆè¨ˆã§ä»£æ›¿
    try:
        if "_trio_score" in globals() and callable(globals()["_trio_score"]):
            return float(globals()["_trio_score"](int(a), int(b), int(c)))
    except Exception:
        pass
    rt = globals().get("race_t", {}) if isinstance(globals().get("race_t", {}), dict) else {}
    return float(rt.get(int(a), 50.0)) + float(rt.get(int(b), 50.0)) + float(rt.get(int(c), 50.0))

# -------- å°åˆ¥3ç€ç‡ã€Œ3ç•ªæ‰‹ã®å°ã€ã‚’å¾—ã‚‹ï¼ˆå¯å¤‰ï¼šRANK_STATS_*ã‚’å‚ç…§ï¼‰ --------

def _third_symbol_by_top3(stats: dict) -> str:
    """
    å°åˆ¥é›†è¨ˆ(stats)ã‹ã‚‰3ç€å†…ç‡pTop3ã§3ç•ªæ‰‹ã®å°ã‚’è¿”ã™ã€‚
    stats ä¾‹:
      {"â—":{"pTop3":0.714}, "ã€‡":{"pTop3":0.524}, ...}
    """
    if not isinstance(stats, dict):
        return "â–³"
    cand = []
    for k, v in stats.items():
        if k in ("â—", "ã€‡", "â–²", "â–³", "Ã—", "Î±", "ç„¡"):
            try:
                cand.append((k, float(v.get("pTop3", 0.0))))
            except Exception:
                cand.append((k, 0.0))
    cand.sort(key=lambda x: x[1], reverse=True)
    return cand[2][0] if len(cand) >= 3 else ("â–³" if cand else "â–³")

def _active_rank_stats():
    # å„ªå…ˆé †ï¼šRANK_STATS_CURRENT > RANK_STATS_F2 > RANK_STATS
    if "RANK_STATS_CURRENT" in globals() and isinstance(RANK_STATS_CURRENT, dict):
        return RANK_STATS_CURRENT
    if "RANK_STATS_F2" in globals() and isinstance(RANK_STATS_F2, dict):
        return RANK_STATS_F2
    return globals().get("RANK_STATS", {}) if isinstance(globals().get("RANK_STATS", {}), dict) else {}

def _pick_axis_id_for_symbol(symbol: str):
    """
    ä¸ãˆã‚‰ã‚ŒãŸå°(symbol)ã®é¸æ‰‹ç¾¤ã‹ã‚‰ã€race_tå„ªå…ˆã§â€œè»¸ã¨ãªã‚‹1é ­â€ã‚’è¿”ã™ã€‚
    """
    rm = globals().get("result_marks", {})
    if not isinstance(rm, dict):
        return None
    cand_ids = []
    for k, v in rm.items():
        try:
            if str(v) == str(symbol):
                cand_ids.append(int(k))
        except Exception:
            continue
    if not cand_ids:
        return None
    def _axis_score(i):
        t = float(globals().get("race_t", {}).get(int(i), 50.0)) if isinstance(globals().get("race_t", {}), dict) else 50.0
        return (t, -int(i))  # åå·®å€¤Tå„ªå…ˆãƒ»åŒç‚¹ã¯ç•ªå·å°ã•ã„æ–¹
    cand_ids.sort(key=_axis_score, reverse=True)
    return cand_ids[0]

# -------- ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”Ÿæˆï¼ˆâ—å´ãŒ2ç‚¹ä»¥ä¸‹ãªã©ä¸è¶³æ™‚ã«ä½¿ç”¨ï¼‰ --------

def _gen_anchor_trios_fallback(anchor_id: int, max_take: int = 12):
    """
    â—(anchor_id)ã‚’å¿…ãšå«ã‚€ä¸‰é€£è¤‡å€™è£œã‚’ç”Ÿæˆã€‚
    1) L1-L2-L3 ãŒã‚ã‚Œã°ãã‚Œã‚’å„ªå…ˆ
    2) ç„¡ã‘ã‚Œã° USED_IDS ã‹ã‚‰ C(n-1, 2)ï¼ˆâ—+2é ­ï¼‰ã‚’å…¨åˆ—æŒ™
    æˆ»ã‚Šå€¤: [(a,b,c,score,"FBâ—"), ...] ã‚¹ã‚³ã‚¢é™é †
    """
    pool = set()
    L1 = globals().get("L1"); L2 = globals().get("L2"); L3 = globals().get("L3")
    try:
        if L1 and L2 and L3:
            for a in _safe_iter(L1):
                for b in _safe_iter(L2):
                    for c in _safe_iter(L3):
                        tup = tuple(sorted(map(int, (a, b, c))))
                        if anchor_id in tup and _is_valid_trio(*tup):
                            pool.add(tup)
        else:
            ids = _get_used_ids()
            others = [i for i in ids if i != int(anchor_id)]
            for x, y in itertools.combinations(others, 2):
                tup = tuple(sorted((int(anchor_id), int(x), int(y))))
                if _is_valid_trio(*tup):
                    pool.add(tup)
    except Exception:
        pool = set()

    rows = []
    for a, b, c in pool:
        s = _trio_score_safe(a, b, c)
        rows.append((int(a), int(b), int(c), float(s), "FBâ—"))

    rows.sort(key=lambda t: (-t[3], t[0], t[1], t[2]))
    return rows[:max_take]




# ============================================================
# ä¸‰é€£è¤‡ã€Œâ—å…¥ã‚Š3ç‚¹ / â—æŠœã3ç‚¹ã€(çŸ­ç¸®ãƒ»è‡ªçµ¦è‡ªè¶³ãƒ»tri_inc/tri_excå›ºå®š)
# ============================================================
import itertools

# --- mini utils ---
def _is_valid_trio(a,b,c):
    try: return len({int(a),int(b),int(c)})==3
    except: return False

def _trio_key(a,b,c): return tuple(sorted(map(int,(a,b,c))))

def _trio_score_safe(a,b,c):
    try:
        return float(_trio_score(int(a),int(b),int(c)))
    except Exception:
        rt = globals().get("race_t", {}) if isinstance(globals().get("race_t", {}), dict) else {}
        return float(rt.get(int(a),50.0))+float(rt.get(int(b),50.0))+float(rt.get(int(c),50.0))

def _ensure_top3(primary_rows, fallback_rows, need=3):
    def _rank_tuple(row):
        a,b,c,s,_ = row
        rt = globals().get("race_t", {}) if isinstance(globals().get("race_t", {}), dict) else {}
        tsum = float(rt.get(int(a),50.0))+float(rt.get(int(b),50.0))+float(rt.get(int(c),50.0))
        return (float(s), tsum)
    out, seen = [], set()
    for src in (sorted(primary_rows or [], key=_rank_tuple, reverse=True),
                sorted(fallback_rows or [], key=_rank_tuple, reverse=True)):
        for a,b,c,s,tag in src:
            if not _is_valid_trio(a,b,c): continue
            k=_trio_key(a,b,c)
            if k in seen: continue
            out.append((int(a),int(b),int(c),float(s),str(tag))); seen.add(k)
            if len(out)>=need: return out
    return out

def _gen_anchor_trios_fallback(anchor_id, max_take=24):
    ids = sorted(map(int, globals().get("USED_IDS", []))) if "USED_IDS" in globals() else []
    pool=set()
    for x,y in itertools.combinations([i for i in ids if i!=int(anchor_id)],2):
        tup=tuple(sorted((int(anchor_id),int(x),int(y))))
        if _is_valid_trio(*tup): pool.add(tup)
    rows=[(a,b,c,_trio_score_safe(a,b,c),"FBâ—") for a,b,c in pool]
    rows.sort(key=lambda t:(-t[3],t[0],t[1],t[2]))
    return rows[:max_take]

def _active_rank_stats():
    if "RANK_STATS_CURRENT" in globals() and isinstance(RANK_STATS_CURRENT, dict): return RANK_STATS_CURRENT
    if "RANK_STATS_F2" in globals() and isinstance(RANK_STATS_F2, dict): return RANK_STATS_F2
    return globals().get("RANK_STATS", {}) if isinstance(globals().get("RANK_STATS", {}), dict) else {}

def _third_symbol_by_top3(stats: dict)->str:
    cand=[]
    for k,v in (stats or {}).items():
        if k in ("â—","ã€‡","â–²","â–³","Ã—","Î±","ç„¡"):
            try: cand.append((k,float(v.get("pTop3",0.0))))
            except: cand.append((k,0.0))
    cand.sort(key=lambda x:x[1], reverse=True)
    return cand[2][0] if len(cand)>=3 else "â–³"

def _pick_axis_id_for_symbol(symbol: str):
    rm = globals().get("result_marks", {})
    if not isinstance(rm, dict): return None
    cand=[int(k) for k,v in rm.items() if str(v)==str(symbol)]
    if not cand: return None
    rt = globals().get("race_t", {}) if isinstance(globals().get("race_t", {}), dict) else {}
    return max(cand, key=lambda i: float(rt.get(int(i),50.0)))

# --- main ---
try:
    anchor = int(result_marks.get("â—")) if (isinstance(result_marks, dict) and result_marks.get("â—") is not None) else int(anchor_no)
except Exception:
    anchor = int(globals().get("anchor_no",0) or 0)

prob_trio_rows  = globals().get("trios_prob_filtered",  [])
score_trio_rows = globals().get("trios_filtered_display", [])

# â—å…¥ã‚Šï¼šã¾ãšå€™è£œã‚’ä½œã‚‹
base_in = [(a,b,c,float(s),str(tag)) for (a,b,c,s,tag) in (prob_trio_rows or [])  if anchor in (a,b,c)]
fb_in   = [(a,b,c,float(s),str(tag)) for (a,b,c,s,tag) in (score_trio_rows or []) if anchor in (a,b,c)]
tri_inc = _ensure_top3(base_in, fb_in, need=3)

# â—å…¥ã‚ŠãŒ2ç‚¹ä»¥ä¸‹ãªã‚‰ã€â—å›ºå®šãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã§åŸ‹ã‚ã‚‹
if len(tri_inc)<3 and anchor:
    seen={_trio_key(a,b,c) for a,b,c,_,_ in tri_inc}
    for a,b,c,s,tag in _gen_anchor_trios_fallback(anchor):
        k=_trio_key(a,b,c)
        if k in seen: continue
        tri_inc.append((a,b,c,s,tag)); seen.add(k)
        if len(tri_inc)>=3: break

# â—æŠœãï¼šå°åˆ¥3ç€ç‡3ç•ªæ‰‹ã®å°ã‚’è»¸ï¼ˆå¯å¤‰ï¼‰ã€‚â—ã¯è»¸ã«ã‚‚ãƒ’ãƒ¢ã«ã‚‚å…¥ã‚Œãªã„
non_star_symbol = _third_symbol_by_top3(_active_rank_stats())
axis_id = _pick_axis_id_for_symbol(non_star_symbol)

if axis_id is not None:
    base_out = [(a,b,c,float(s),str(tag)) for (a,b,c,s,tag) in (prob_trio_rows or [])
                if (anchor not in (a,b,c)) and (axis_id in (a,b,c))]
    fb_out   = [(a,b,c,float(s),str(tag)) for (a,b,c,s,tag) in (score_trio_rows or [])
                if (anchor not in (a,b,c)) and (axis_id in (a,b,c))]
    tri_exc  = _ensure_top3(base_out, fb_out, need=3)
else:
    base_out = [(a,b,c,float(s),str(tag)) for (a,b,c,s,tag) in (prob_trio_rows or []) if anchor not in (a,b,c)]
    fb_out   = [(a,b,c,float(s),str(tag)) for (a,b,c,s,tag) in (score_trio_rows or []) if anchor not in (a,b,c)]
    tri_exc  = _ensure_top3(base_out, fb_out, need=3)

# å®‰å…¨ç¶²ï¼šä¸‡ä¸€æ··å…¥ã—ãŸâ—ã‚’é™¤å»ã—ã€è¶³ã‚Šãªã‘ã‚Œã°â—æŠœãå…¨åˆ—æŒ™ã§è£œå®Œï¼ˆå¯èƒ½ãªã‚‰ axis_id ã‚’å«ã‚€ã‚‚ã®å„ªå…ˆï¼‰
tri_exc = [r for r in tri_exc if anchor not in r[:3]]
if len(tri_exc)<3:
    used_ids = sorted(map(int, globals().get("USED_IDS", []))) if "USED_IDS" in globals() else []
    seen={_trio_key(a,b,c) for a,b,c,_,_ in tri_exc}
    pool=[]
    for a,b,c in itertools.combinations(used_ids,3):
        if anchor in (a,b,c): continue
        if axis_id is None or axis_id in (a,b,c):
            pool.append((a,b,c))
    if not pool:
        pool=[t for t in itertools.combinations(used_ids,3) if anchor not in t]
    cand=[(a,b,c,_trio_score_safe(a,b,c),"FBâ—æŠœã") for (a,b,c) in pool]
    cand.sort(key=lambda t:(-t[3],t[0],t[1],t[2]))
    for a,b,c,s,tag in cand:
        k=_trio_key(a,b,c)
        if k in seen: continue
        tri_exc.append((a,b,c,s,tag)); seen.add(k)
        if len(tri_exc)>=3: break

def _fmt_trio_list(rows): return " / ".join(f"{a}-{b}-{c}" for a,b,c,_,_ in rows) if rows else "â€”"
st.markdown(f"**æˆ¦è¡“ï¼ˆä¸‰é€£è¤‡ï¼‰** â—å…¥ã‚Š3ç‚¹: {_fmt_trio_list(tri_inc)}ã€€ï½œã€€â—æŠœã3ç‚¹: {_fmt_trio_list(tri_exc)}")
# st.write ã¯å‰Šé™¤



# ===== ä¸‰é€£å˜ï¼ˆâ—ã€‡å›ºå®šãƒ»2åˆ—ç›®â—ã€‡â–²ãƒ»3åˆ—ç›®=L3ï¼‰ =====
mark_star   = result_marks.get("â—")
mark_circle = result_marks.get("ã€‡")

santan_filtered_display, cutoff_san = [], 0.0
san_mu = san_sig = san_mu_sig = san_topq = 0.0
san_adopt = "Î¼+Ïƒ/div"

TRIFECTA_SIG_DIV  = float(globals().get("TRIFECTA_SIG_DIV", 8.0))
TRIFECTA_TOP_FRAC = float(globals().get("TRIFECTA_TOP_FRAC", 1/8))

# è¡¨ç¤ºç”¨ã«â€œå®Ÿéš›ã«ä½¿ã£ãŸå€¤â€ã‚’ä¿æŒ
san_sig_div_used  = TRIFECTA_SIG_DIV
san_top_frac_used = TRIFECTA_TOP_FRAC if TRIFECTA_TOP_FRAC > 0 else 1/8
san_top_den       = int(round(1.0 / san_top_frac_used))  # 1/8 â†’ 8


if L1 and L2 and L3:
    first_col  = [x for x in [mark_star, mark_circle] if x is not None]
    second_col = [x for x in [mark_star, mark_circle, result_marks.get("â–²")] if x is not None]
    third_col  = list(L3)


    # ä¸¦ã³ã®å„ªå…ˆåº¦ï¼ˆå®‰å®šã‚½ãƒ¼ãƒˆç”¨ï¼‰
    orderA = {n:i for i,n in enumerate(first_col)}
    orderB = {n:i for i,n in enumerate(second_col)}

    # å€™è£œç”Ÿæˆ
    san_rows, seen = [], set()
    for a in first_col:
        for b in second_col:
            for c in third_col:
                if len({a,b,c}) != 3:
                    continue
                key = (int(a), int(b), int(c))
                if key in seen:
                    continue
                seen.add(key)
                s = _santan_score(*key)
                san_rows.append((key[0], key[1], key[2], s, "é€šå¸¸"))

    if san_rows:
        xs = [row[3] for row in san_rows]
        san_mu  = float(mean(xs))
        san_sig = float(pstdev(xs)) if len(xs) > 1 else 0.0
        san_mu_sig = san_mu + (san_sig / TRIFECTA_SIG_DIV if san_sig > 0 else 0.0)

        q = max(1, int(len(xs) * TRIFECTA_TOP_FRAC))
        san_topq = float(np.partition(xs, -q)[-q])

        cutoff_san = max(san_mu_sig, san_topq)
        san_adopt  = "Î¼+Ïƒ/div" if cutoff_san == san_mu_sig else f"top-{int(1/TRIFECTA_TOP_FRAC)}åˆ†ä½"

        santan_filtered_display = [r for r in san_rows if r[3] >= cutoff_san]
        santan_filtered_display.sort(
            key=lambda t: (-t[3], orderA.get(t[0], 99), orderB.get(t[1], 99), int(t[2]))
        )

# === ãƒ©ã‚¤ãƒ³ãƒ‘ãƒ¯ãƒ¼æ ï¼ˆä¸‰é€£å˜ï¼šæœ€å¤§2ç‚¹ï¼‰ ===
santan_line_added = []
gid = car_to_group.get(anchor_no, None) if 'anchor_no' in globals() else None
if gid in line_def:
    mem = [int(x) for x in line_def.get(gid, [])]
    if anchor_no in mem:
        others = [x for x in mem if x != anchor_no]

        if mark_circle:
            for extra in others:
                if extra in {anchor_no, mark_circle}:
                    continue
                k = (int(anchor_no), int(mark_circle), int(extra))
                if not any((a,b,c)==k for (a,b,c,_,_) in santan_filtered_display + santan_line_added):
                    santan_line_added.append((k[0],k[1],k[2], _santan_score(*k), "ãƒ©ã‚¤ãƒ³æ "))
                if len(santan_line_added) >= 2:
                    break

        if len(santan_line_added) < 2 and len(others) >= 2:
            a,b = sorted(others, key=lambda x: float(race_t.get(int(x), 50.0)), reverse=True)[:2]
            if a != b and anchor_no not in {a,b}:
                k = (int(anchor_no), int(a), int(b))
                if not any((x,y,z)==k for (x,y,z,_,_) in santan_filtered_display + santan_line_added):
                    santan_line_added.append((k[0],k[1],k[2], _santan_score(*k), "ãƒ©ã‚¤ãƒ³æ "))

santan_filtered_display.extend(santan_line_added[:2])
# é‡è¤‡ãƒ»è‡ªå·±é‡è¤‡ã‚’æœ€çµ‚é™¤å»
santan_filtered_display = _uniq_trifecta(santan_filtered_display)
n_triS = len(santan_filtered_display)


# ========== äºŒè»Šè¤‡ï¼ˆæ–°æ–¹å¼ï¼‰ ==========
pairs_all_L12 = {}
for a in L1:
    for b in L2:
        if a == b: continue
        key = tuple(sorted((int(a), int(b))))
        if key in pairs_all_L12: continue
        s2 = float(race_t.get(int(a), 50.0)) + float(race_t.get(int(b), 50.0))
        pairs_all_L12[key] = round(s2, 1)

pairs_qn2_filtered, cutoff_qn2 = [], 0.0
qn2_mu = qn2_sig = qn2_mu_sig = qn2_topq = 0.0
qn2_adopt = "Î¼+Ïƒ/div"

QN_SIG_DIV  = float(globals().get("QN_SIG_DIV", 3.0))
QN_TOP_FRAC = float(globals().get("QN_TOP_FRAC", 0.20))

# è¡¨ç¤ºç”¨ã«â€œå®Ÿéš›ã«ä½¿ã£ãŸå€¤â€ã‚’ä¿æŒ
qn_sig_div_used  = QN_SIG_DIV
qn_top_frac_used = QN_TOP_FRAC if QN_TOP_FRAC > 0 else 0.20
qn_top_den       = int(round(1.0 / qn_top_frac_used))    # 0.2 â†’ 5


if pairs_all_L12:
    sc = list(pairs_all_L12.values())
    qn2_mu  = float(mean(sc))
    qn2_sig = float(pstdev(sc)) if len(sc) > 1 else 0.0
    qn2_mu_sig = qn2_mu + (qn2_sig / QN_SIG_DIV if qn2_sig > 0 else 0.0)

    q = max(1, int(len(sc) * QN_TOP_FRAC))
    qn2_topq = float(np.partition(sc, -q)[-q])

    cutoff_qn2 = max(qn2_mu_sig, qn2_topq)
    qn2_adopt  = "Î¼+Ïƒ/div" if cutoff_qn2 == qn2_mu_sig else f"top-{int(1/QN_TOP_FRAC)}åˆ†ä½"

    pairs_qn2_filtered = [(a, b, s, "é€šå¸¸")
                          for (a, b), s in pairs_all_L12.items()
                          if s >= cutoff_qn2]

# ãƒ©ã‚¤ãƒ³æ è¿½åŠ 
if gid in line_def and anchor_no is not None:
    mem = [int(x) for x in line_def.get(gid, [])]
    if anchor_no in mem:
        others = [x for x in mem if x != anchor_no]
        qn_line_added = []
        if mark_circle:
            for extra in others:
                k = tuple(sorted((int(anchor_no), int(extra))))
                if not any((k[0]==a and k[1]==b) for (a,b,_,_) in pairs_qn2_filtered + qn_line_added):
                    s_line = float(race_t.get(k[0],50.0)) + float(race_t.get(k[1],50.0))
                    qn_line_added.append((k[0], k[1], round(s_line,1), "ãƒ©ã‚¤ãƒ³æ "))
                if len(qn_line_added) >= 2: break
        if len(qn_line_added) < 2 and len(others) >= 1:
            best = max(others, key=lambda x: float(race_t.get(int(x),50.0)))
            k = tuple(sorted((int(anchor_no), int(best))))
            if not any((k[0]==a and k[1]==b) for (a,b,_,_) in pairs_qn2_filtered + qn_line_added):
                s_line = float(race_t.get(k[0],50.0)) + float(race_t.get(k[1],50.0))
                qn_line_added.append((k[0], k[1], round(s_line,1), "ãƒ©ã‚¤ãƒ³æ "))
        pairs_qn2_filtered.extend(qn_line_added[:2])

pairs_qn2_filtered = _uniq_qn(pairs_qn2_filtered)
n_qn = len(pairs_qn2_filtered)


# ========== äºŒè»Šå˜ï¼ˆæ–°æ–¹å¼ï¼‰ ==========
rows_nitan_filtered, cutoff_nit = [], 0.0
nit_mu = nit_sig = nit_mu_sig = nit_topq = 0.0
nit_adopt = "Î¼+Ïƒ/div"

NIT_SIG_DIV  = float(globals().get("NIT_SIG_DIV", 3.0))
NIT_TOP_FRAC = float(globals().get("NIT_TOP_FRAC", 1/8))

# è¡¨ç¤ºç”¨ã«â€œå®Ÿéš›ã«ä½¿ã£ãŸå€¤â€ã‚’ä¿æŒ
nit_sig_div_used  = NIT_SIG_DIV
nit_top_frac_used = NIT_TOP_FRAC if NIT_TOP_FRAC > 0 else 1/8
nit_top_den       = int(round(1.0 / nit_top_frac_used))  # 1/8 â†’ 8


rows_nitan = []
if L1 and L2:
    for a in L1:
        for b in L2:
            if a == b: continue
            k = f"{int(a)}-{int(b)}"
            s1 = float(race_t.get(int(a),50.0)) + float(race_t.get(int(b),50.0))
            rows_nitan.append((k, s1))

if rows_nitan:
    xs = [s for (_,s) in rows_nitan]
    nit_mu  = float(mean(xs))
    nit_sig = float(pstdev(xs)) if len(xs) > 1 else 0.0
    nit_mu_sig = nit_mu + (nit_sig / NIT_SIG_DIV if nit_sig > 0 else 0.0)

    q = max(1, int(len(xs) * NIT_TOP_FRAC))
    nit_topq = float(np.partition(xs, -q)[-q])

    cutoff_nit = max(nit_mu_sig, nit_topq)
    nit_adopt  = "Î¼+Ïƒ/div" if cutoff_nit == nit_mu_sig else f"top-{int(1/NIT_TOP_FRAC)}åˆ†ä½"

    for k,s1 in rows_nitan:
        if float(s1) >= cutoff_nit:
            rows_nitan_filtered.append((k, round(float(s1),1), "é€šå¸¸"))

# ãƒ©ã‚¤ãƒ³æ è¿½åŠ 
if gid in line_def and anchor_no is not None:
    mem = [int(x) for x in line_def.get(gid, [])]
    if anchor_no in mem:
        others = [x for x in mem if x != anchor_no]
        for extra in others[:2]:
            k = f"{anchor_no}-{extra}"
            s_approx = next((v for (kk,v,tag) in rows_nitan_filtered if kk==k), None)
            if s_approx is None:
                s_approx = float(race_t.get(anchor_no,50.0)) + float(race_t.get(extra,50.0))
            rows_nitan_filtered.append((k, round(float(s_approx),1), "ãƒ©ã‚¤ãƒ³æ "))

rows_nitan_filtered = _uniq_nitan(rows_nitan_filtered)
n_nit = len(rows_nitan_filtered)

# =========================
#  å®‰å…¨ã‚¬ãƒ¼ãƒ‰ & ãƒ˜ãƒ«ãƒ‘ï¼ˆå…¨éƒ¨ã“ã“ã‹ã‚‰è²¼ã‚‹ï¼‰
# =========================
import math
import pandas as pd

# æ—¢ã«ã‚ã‚‹ã‹ã‚‚ã—ã‚Œãªã„ã®ã§ä¸Šæ›¸ãå®šç¾©OK
def _hdr(name: str, cutoff: float, basis: str, n: int | None = None) -> str:
    tail = f"ï½œ{n}ç‚¹" if isinstance(n, (int, float)) else ""
    return f"{name}ï¼ˆæ–°æ–¹å¼ï½œã—ãã„å€¤ {cutoff:.1f}ç‚¹ï¼åŸºæº– {basis}{tail}ï¼‰"

def _basis_trio(TRIO_L3_MIN: float) -> str:
    return f"L3åŸºæº– {TRIO_L3_MIN:.1f}"

def _basis_combo(sig_div_used: float, mu_sig: float, top_den: int, topq: float, adopt: str) -> str:
    return (
        f"Î¼+Ïƒ/{sig_div_used:g}â†’{mu_sig:.1f}ã€"
        f"top-{int(top_den)}åˆ†ä½â†’{topq:.1f}ï½œæ¡ç”¨={adopt}"
    )

# è¡¨ç¤ºç”¨DFï¼ˆNameErrorå¯¾ç­–ï¼šå¿…ãšå®šç¾©ï¼‰
def _df_trio(rows, star_id=None):
    out = []
    for (a, b, c, s, tag) in rows:
        mark = "â˜†" if (star_id is not None and star_id in (a, b, c)) else ""
        note = f"ï½œ{tag}" if str(tag) == "ãƒ©ã‚¤ãƒ³æ " else ""
        out.append({"è²·ã„ç›®": f"{a}-{b}-{c}{mark}", "ã‚¹ã‚³ã‚¢": f"{float(s):.1f}{note}"})
    return pd.DataFrame(out)

def _df_pairs(rows):
    out = []
    for (a, b, s, tag) in rows:
        note = f"ï½œ{tag}" if str(tag) == "ãƒ©ã‚¤ãƒ³æ " else ""
        out.append({"è²·ã„ç›®": f"{a}-{b}", "ã‚¹ã‚³ã‚¢": f"{float(s):.1f}{note}"})
    return pd.DataFrame(out)

def _df_nitan(rows):
    out = []
    for (k, v, tag) in rows:  # k="a-b"
        note = f"ï½œ{tag}" if str(tag) == "ãƒ©ã‚¤ãƒ³æ " else ""
        out.append({"è²·ã„ç›®": str(k), "ã‚¹ã‚³ã‚¢": f"{float(v):.1f}{note}"})
    return pd.DataFrame(out)

# ä½¿ã†å€¤ã‚’å®‰å…¨ã«æ‹¾ã†ï¼ˆæœªå®šç¾©ã§ã‚‚è½ã¡ãªã„ã‚ˆã†ã«ï¼‰
def _g(name, default):
    return globals()[name] if name in globals() else default

# ä¸‰é€£è¤‡ å›ºæœ‰
TRIO_L3_MIN       = float(_g("TRIO_L3_MIN", 160.0))
cutoff_trio       = float(_g("cutoff_trio", 0.0))
trios_filtered_display = _g("trios_filtered_display", [])
n_trio            = int(_g("n_trio", len(trios_filtered_display)))
has_trio          = bool(_g("has_trio", bool(trios_filtered_display)))

# ä¸‰é€£å˜
san_sig_div_used  = float(_g("san_sig_div_used", _g("TRIFECTA_SIG_DIV", 8.0)))
san_mu_sig        = float(_g("san_mu_sig", 0.0))
san_top_den       = int(_g("san_top_den", 8))
san_topq          = float(_g("san_topq", 0.0))
san_adopt         = str(_g("san_adopt", "Î¼+Ïƒ/div"))
cutoff_san        = float(_g("cutoff_san", 0.0))
santan_filtered_display = _g("santan_filtered_display", [])
n_triS            = int(_g("n_triS", len(santan_filtered_display)))
has_tri           = bool(_g("has_tri", bool(santan_filtered_display)))

# äºŒè»Šè¤‡
qn_sig_div_used   = float(_g("qn_sig_div_used", _g("QN_SIG_DIV", 3.0)))
qn2_mu_sig        = float(_g("qn2_mu_sig", 0.0))
qn_top_den        = int(_g("qn_top_den", 5))
qn2_topq          = float(_g("qn2_topq", 0.0))
qn2_adopt         = str(_g("qn2_adopt", "Î¼+Ïƒ/div"))
cutoff_qn2        = float(_g("cutoff_qn2", 0.0))
pairs_qn2_filtered = _g("pairs_qn2_filtered", [])
n_qn              = int(_g("n_qn", len(pairs_qn2_filtered)))
has_qn            = bool(_g("has_qn", bool(pairs_qn2_filtered)))

# äºŒè»Šå˜
nit_sig_div_used  = float(_g("nit_sig_div_used", _g("NIT_SIG_DIV", 3.0)))
nit_mu_sig        = float(_g("nit_mu_sig", 0.0))
nit_top_den       = int(_g("nit_top_den", 8))
nit_topq          = float(_g("nit_topq", 0.0))
nit_adopt         = str(_g("nit_adopt", "Î¼+Ïƒ/div"))
cutoff_nit        = float(_g("cutoff_nit", 0.0))
rows_nitan_filtered = _g("rows_nitan_filtered", [])
n_nit             = int(_g("n_nit", len(rows_nitan_filtered)))
has_nit           = bool(_g("has_nit", bool(rows_nitan_filtered)))

# ãã®ã»ã‹å‚ç…§ã™ã‚‹å¯èƒ½æ€§ã®ã‚ã‚‹å€¤
formation_label   = str(_g("formation_label", "â€”"))
result_marks      = _g("result_marks", {})
star_id           = result_marks.get("â—") if isinstance(result_marks, dict) else None
race_t            = _g("race_t", {})
USED_IDS          = _g("USED_IDS", [])
track             = str(_g("track", ""))
race_no           = str(_g("race_no", ""))
confidence        = str(_g("confidence", ""))
race_time         = str(_g("race_time", ""))
race_class        = str(_g("race_class", ""))
xs_base_raw       = _g("xs_base_raw", [])
line_inputs       = _g("line_inputs", [])
_format_rank_from_array = _g("_format_rank_from_array", lambda ids, xs: " ".join(map(str, ids)))

# === Trioè£œåŠ©ï¼ˆé‡è¤‡/åŒä¸€ç•ªå·ã®æ’é™¤ï¼‹ä¸è¶³åˆ†ã®è£œå®Œï¼‰ =========================
def _trip_valid(a, b, c) -> bool:
    # 3é€£è¤‡ã®åŒä¸€ç•ªå·(ä¾‹:1-5-5)ã‚’æ’é™¤
    return len({int(a), int(b), int(c)}) == 3

def _ensure_top3(base_rows, fallback_rows, need=3):
    """
    base_rows: å„ªå…ˆãƒ—ãƒ¼ãƒ«ï¼ˆç¢ºç‡æ ï¼‰ [(a,b,c,score,tag), ...]
    fallback_rows: è£œå®Œãƒ—ãƒ¼ãƒ«ï¼ˆåå·®å€¤æ /ãƒ©ã‚¤ãƒ³æ ãªã©ï¼‰ åŒå½¢å¼
    - a,b,c ã¯é †ä¸åŒOKã€‚å†…éƒ¨ã§æ˜‡é †ã‚­ãƒ¼åŒ–ã—ã¦é‡è¤‡çµ±ä¸€
    - ç„¡åŠ¹(åŒä¸€ç•ªå·)ã¯ã‚¹ã‚­ãƒƒãƒ—
    - scoreé™é †â†’a,b,cæ˜‡é †ã§æ¡ç”¨
    """
    def _norm_rows(rows):
        uniq = {}
        for a,b,c,s,tag in rows or []:
            if not _trip_valid(a,b,c):
                continue
            key = tuple(sorted((int(a),int(b),int(c))))
            rec = (key[0], key[1], key[2], float(s), str(tag))
            if (key not in uniq) or (rec[3] > uniq[key][3]):
                uniq[key] = rec
        return sorted(uniq.values(), key=lambda r:(-r[3], r[0], r[1], r[2]))

    base_uni = _norm_rows(base_rows)
    fb_uni   = _norm_rows(fallback_rows)

    picked, seen = [], set()
    for r in base_uni:
        k=(r[0],r[1],r[2])
        if k in seen: 
            continue
        picked.append(r); seen.add(k)
        if len(picked) >= need: 
            return picked[:need]

    for r in fb_uni:
        k=(r[0],r[1],r[2])
        if k in seen: 
            continue
        picked.append(r); seen.add(k)
        if len(picked) >= need: 
            break

    return picked[:need]


# =========================
#  ç”»é¢å‡ºåŠ›ï¼ˆé †ç•ªå›ºå®šï¼‰
# =========================
st.markdown(f"**ãƒ•ã‚©ãƒ¼ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³**ï¼š{formation_label}")

# ä¸‰é€£è¤‡
st.markdown("#### " + _hdr("ä¸‰é€£è¤‡", cutoff_trio, _basis_trio(TRIO_L3_MIN), n_trio))
if has_trio:
    st.dataframe(_df_trio(trios_filtered_display, star_id), use_container_width=True)
else:
    st.markdown("å¯¾è±¡å¤–")

# ä¸‰é€£å˜
_basis_tri = _basis_combo(san_sig_div_used, san_mu_sig, san_top_den, san_topq, san_adopt)
st.markdown("#### " + _hdr("ä¸‰é€£å˜", cutoff_san, _basis_tri, n_triS))
if has_tri:
    st.dataframe(_df_trio(santan_filtered_display, star_id), use_container_width=True)
else:
    st.markdown("å¯¾è±¡å¤–")

# äºŒè»Šè¤‡
_basis_qn = _basis_combo(qn_sig_div_used, qn2_mu_sig, qn_top_den, qn2_topq, qn2_adopt)
st.markdown("#### " + _hdr("äºŒè»Šè¤‡", cutoff_qn2, _basis_qn, n_qn))
if has_qn:
    st.dataframe(_df_pairs(pairs_qn2_filtered), use_container_width=True)
else:
    st.markdown("å¯¾è±¡å¤–")

# äºŒè»Šå˜
_basis_nit = _basis_combo(nit_sig_div_used, nit_mu_sig, nit_top_den, nit_topq, nit_adopt)
st.markdown("#### " + _hdr("äºŒè»Šå˜", cutoff_nit, _basis_nit, n_nit))
if has_nit:
    st.dataframe(_df_nitan(rows_nitan_filtered), use_container_width=True)
else:
    st.markdown("å¯¾è±¡å¤–")

# =========================
#  å°ã®å®Ÿæ¸¬ç‡ â†’ ã‚°ãƒ¬ãƒ¼ãƒ‰åˆ¥ã®ç¢ºç‡ãƒ¢ãƒ‡ãƒ« â†’ è²·ã„ç›®æŠ½å‡ºï¼ˆçš„ä¸­ç‡ã—ãã„å€¤ï¼‰
#  æ—¢å­˜ã®è²·ã„ç›®ã¨é‡è¤‡ã—ãŸã‚‚ã® = ã€Œã‚ªã‚¹ã‚¹ãƒ¡è²·ç›®ã€
# =========================

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼šã‚°ãƒ¬ãƒ¼ãƒ‰é¸æŠï¼†ã—ãã„å€¤ï¼ˆåˆæœŸ10%ï¼‰ ---
st.sidebar.markdown("### å°å®Ÿæ¸¬ç‡ã®ã‚°ãƒ¬ãƒ¼ãƒ‰/ã—ãã„å€¤")
grade_for_marks = st.sidebar.selectbox(
    "ã‚°ãƒ¬ãƒ¼ãƒ‰ï¼ˆå°ã®å®Ÿæ¸¬ç‡ãƒ†ãƒ¼ãƒ–ãƒ«ï¼‰",
    ["TOTAL","F2","F1","G","GIRLS"],
    index=0,
    key="grade_mark_stats"
)
hit_threshold = float(st.sidebar.slider("çš„ä¸­ç‡ã—ãã„å€¤", 0.01, 0.50, 0.10, 0.01, key="hit_threshold"))

# --- ãƒ†ãƒ¼ãƒ–ãƒ«é¸æŠï¼ˆã‚ãªãŸãŒè²¼ã£ãŸãƒ†ãƒ¼ãƒ–ãƒ«ç¾¤ã‚’å‰æï¼‰ ---
RANK_TABLE = RANK_STATS_BY_GRADE.get(grade_for_marks, RANK_STATS_TOTAL)

# --- è»Šç•ªâ†’å° ã‚’ä½œã‚‹ï¼ˆæœªæŒ‡å®šã¯ã€Œç„¡ã€ï¼‰
marks_of_car = {int(i): "ç„¡" for i in USED_IDS}
if isinstance(result_marks, dict):
    for mk, no in result_marks.items():
        if no is None: 
            continue
        if mk in {"â—","ã€‡","â–²","â–³","Ã—","Î±","Î²"}:
            marks_of_car[int(no)] = mk

# --- å°â†’å®Ÿæ¸¬ç‡ã‚’å¼•ããƒ˜ãƒ«ãƒ‘ï¼ˆç„¡ã‘ã‚Œã°ã€Œç„¡ã€ã‚’ä½¿ã†ï¼‰
def _get_stats(mark: str) -> dict:
    d = RANK_TABLE.get(mark)
    if not d:
        d = RANK_TABLE.get("ç„¡", {"p1":0.0,"pTop2":0.0,"pTop3":0.0})
    return {"p1": float(d["p1"]), "pTop2": float(d["pTop2"]), "pTop3": float(d["pTop3"])}

# --- ç¢ºç‡ãƒ¢ãƒ‡ãƒ«ï¼ˆç‹¬ç«‹è¿‘ä¼¼ï¼å¾Œã§å…¨å€™è£œã§æ­£è¦åŒ–ï¼‰ ---
from itertools import permutations, combinations

# å…¨å€™è£œã®æ¯é›†å›£ï¼ˆæ­£è¦åŒ–ç”¨ï¼‰
ALL_PAIRS_UNORDERED   = [tuple(sorted(t)) for t in combinations(USED_IDS, 2)]
ALL_PAIRS_ORDERED     = [t for t in permutations(USED_IDS, 2)]
ALL_TRIPLES_UNORDERED = [tuple(sorted(t)) for t in combinations(USED_IDS, 3)]
ALL_TRIPLES_ORDERED   = [t for t in permutations(USED_IDS, 3)]

# é‡è¤‡é™¤å»
ALL_PAIRS_UNORDERED   = sorted(set(ALL_PAIRS_UNORDERED))
ALL_TRIPLES_UNORDERED = sorted(set(ALL_TRIPLES_UNORDERED))

# ã‚¦ã‚§ã‚¤ãƒˆå®šç¾©
def w_qn_pair(a,b):
    sa, sb = _get_stats(marks_of_car[a]), _get_stats(marks_of_car[b])
    return max(0.0, sa["pTop2"]*sb["pTop2"])

def w_nit_pair(a,b):
    sa, sb = _get_stats(marks_of_car[a]), _get_stats(marks_of_car[b])
    return max(0.0, sa["p1"]*sb["pTop2"])

def w_trio(a,b,c):
    sa, sb, sc = _get_stats(marks_of_car[a]), _get_stats(marks_of_car[b]), _get_stats(marks_of_car[c])
    return max(0.0, sa["pTop3"]*sb["pTop3"]*sc["pTop3"])

def w_trifecta(a,b,c):
    sa, sb, sc = _get_stats(marks_of_car[a]), _get_stats(marks_of_car[b]), _get_stats(marks_of_car[c])
    return max(0.0, sa["p1"]*sb["pTop2"]*sc["pTop3"])

# æ­£è¦åŒ–ï¼ˆå…¨ä½“åˆè¨ˆ=1ï¼‰
def _normalize(weights: dict) -> dict:
    tot = float(sum(weights.values()))
    if tot <= 0:
        return {k: 0.0 for k in weights}
    return {k: (v/tot) for k,v in weights.items()}

# å…¨å€™è£œã«å¯¾ã™ã‚‹ç¢ºç‡åˆ†å¸ƒï¼ˆå°ã®å®Ÿæ¸¬ç‡ãƒ™ãƒ¼ã‚¹ï¼‰
QN_UNI   = _normalize({k: w_qn_pair(*k)   for k in ALL_PAIRS_UNORDERED})
NIT_UNI  = _normalize({k: w_nit_pair(*k)  for k in ALL_PAIRS_ORDERED})
TRIO_UNI = _normalize({k: w_trio(*k)      for k in ALL_TRIPLES_UNORDERED})
TRI_UNI  = _normalize({k: w_trifecta(*k)  for k in ALL_TRIPLES_ORDERED})

# --- ç”»é¢ã«ç¾åœ¨ã®å°ã®å†…è¨³ï¼ˆå‚è€ƒï¼‰ ---
with st.expander("å°ã®å†…è¨³ï¼ˆä»Šå›ã®ã‚°ãƒ¬ãƒ¼ãƒ‰å®Ÿæ¸¬ç‡ã‚’ä½¿ã†ï¼‰", expanded=False):
    dfm = pd.DataFrame({
        "è»Š": USED_IDS,
        "å°": [marks_of_car[i] for i in USED_IDS],
        "p1": [ _get_stats(marks_of_car[i])["p1"] for i in USED_IDS ],
        "pTop2": [ _get_stats(marks_of_car[i])["pTop2"] for i in USED_IDS ],
        "pTop3": [ _get_stats(marks_of_car[i])["pTop3"] for i in USED_IDS ],
    })
    st.dataframe(dfm, use_container_width=True)

# --- æ—¢å­˜ã®å€™è£œç¾¤ã‹ã‚‰ã€Œç¢ºç‡ã—ãã„å€¤ä»¥ä¸Šã€ã ã‘æŠ½å‡º ---
def _safe_list(x): 
    return x if isinstance(x, list) else []

# ä¸‰é€£è¤‡ï¼ˆæ—¢å­˜ã® trios_filtered_display â†’ k=(a,b,c) ã‚’æ˜‡é †ã‚¿ãƒ—ãƒ«ã§ç…§åˆï¼‰
trios_source = [(int(a),int(b),int(c),float(s),str(tag)) for (a,b,c,s,tag) in _safe_list(trios_filtered_display)]
trio_prob_hits = []
for a,b,c,s,tag in trios_source:
    key = tuple(sorted((a,b,c)))
    p = float(TRIO_UNI.get(key, 0.0))
    if p >= hit_threshold:
        trio_prob_hits.append((a,b,c,p,tag))

# ä¸‰é€£å˜ï¼ˆæ—¢å­˜ã® santan_filtered_display â†’ k=(a,b,c) é †åºãã®ã¾ã¾ç…§åˆï¼‰
tri_source = [(int(a),int(b),int(c),float(s),str(tag)) for (a,b,c,s,tag) in _safe_list(santan_filtered_display)]
tri_prob_hits = []
for a,b,c,s,tag in tri_source:
    key = (a,b,c)
    p = float(TRI_UNI.get(key, 0.0))
    if p >= hit_threshold:
        tri_prob_hits.append((a,b,c,p,tag))

# äºŒè»Šè¤‡ï¼ˆæ—¢å­˜ã® pairs_qn2_filtered â†’ k=(a,b) æ˜‡é †ï¼‰
qn_source = [(int(a),int(b),float(s),str(tag)) for (a,b,s,tag) in _safe_list(pairs_qn2_filtered)]
qn_prob_hits = []
for a,b,s,tag in qn_source:
    key = tuple(sorted((a,b)))
    p = float(QN_UNI.get(key, 0.0))
    if p >= hit_threshold:
        qn_prob_hits.append((a,b,p,tag))

# äºŒè»Šå˜ï¼ˆæ—¢å­˜ã® rows_nitan_filtered â†’ k ã¯ "a-b" æ–‡å­—åˆ—ï¼‰
nit_source = []
for k,v,tag in _safe_list(rows_nitan_filtered):
    try:
        a,b = map(int, str(k).split("-"))
        nit_source.append((a,b,float(v),str(tag)))
    except Exception:
        pass
nit_prob_hits = []
for a,b,s,tag in nit_source:
    p = float(NIT_UNI.get((a,b), 0.0))
    if p >= hit_threshold:
        nit_prob_hits.append((a,b,p,tag))

# --- ã€Œã‚ªã‚¹ã‚¹ãƒ¡è²·ç›®ã€= æ—¢å­˜ãƒ­ã‚¸ãƒƒã‚¯ã®å€™è£œ âˆ© ç¢ºç‡ã—ãã„å€¤ã‚¯ãƒªã‚¢ï¼ˆ=ã“ã“ã§æ—¢ã«äº¤ã‚ã£ã¦ã‚‹ï¼‰ ---
def _df_prob_trio(rows):
    return pd.DataFrame([{"è²·ã„ç›®": f"{a}-{b}-{c}", "ç¢ºç‡(æ¨å®š)": f"{p*100:.1f}%", "ç”±æ¥": tag} 
                         for (a,b,c,p,tag) in sorted(rows, key=lambda t:(-t[3], t[0], t[1], t[2]))])

def _df_prob_tri(rows):
    return pd.DataFrame([{"è²·ã„ç›®": f"{a}-{b}-{c}", "ç¢ºç‡(æ¨å®š)": f"{p*100:.1f}%", "ç”±æ¥": tag} 
                         for (a,b,c,p,tag) in sorted(rows, key=lambda t:(-t[3], t[0], t[1], t[2]))])

def _df_prob_qn(rows):
    return pd.DataFrame([{"è²·ã„ç›®": f"{a}-{b}", "ç¢ºç‡(æ¨å®š)": f"{p*100:.1f}%", "ç”±æ¥": tag}
                         for (a,b,p,tag) in sorted(rows, key=lambda t:(-t[2], t[0], t[1]))])

def _df_prob_nit(rows):
    return pd.DataFrame([{"è²·ã„ç›®": f"{a}-{b}", "ç¢ºç‡(æ¨å®š)": f"{p*100:.1f}%", "ç”±æ¥": tag}
                         for (a,b,p,tag) in sorted(rows, key=lambda t:(-t[2], t[0], t[1]))])

st.markdown("## ğŸ¯ å°ã®å®Ÿæ¸¬ç‡ãƒ™ãƒ¼ã‚¹ï½œç¢ºç‡ã—ãã„å€¤ã‚¯ãƒªã‚¢")
c1, c2 = st.columns(2)
with c1:
    st.markdown("#### ä¸‰é€£è¤‡ï¼ˆé‡è¤‡=ãŠã™ã™ã‚ï¼‰")
    st.dataframe(_df_prob_trio(trio_prob_hits), use_container_width=True)
with c2:
    st.markdown("#### ä¸‰é€£å˜ï¼ˆé‡è¤‡=ãŠã™ã™ã‚ï¼‰")
    st.dataframe(_df_prob_tri(tri_prob_hits), use_container_width=True)

c3, c4 = st.columns(2)
with c3:
    st.markdown("#### äºŒè»Šè¤‡ï¼ˆé‡è¤‡=ãŠã™ã™ã‚ï¼‰")
    st.dataframe(_df_prob_qn(qn_prob_hits), use_container_width=True)
with c4:
    st.markdown("#### äºŒè»Šå˜ï¼ˆé‡è¤‡=ãŠã™ã™ã‚ï¼‰")
    st.dataframe(_df_prob_nit(nit_prob_hits), use_container_width=True)

# === ãŠã™ã™ã‚è²·ç›®ï¼ˆè¡¨ç¤ºã‚’åˆ†ã‘ãŸã„å ´åˆã®è¦‹å‡ºã—ã ã‘ï¼‰
st.markdown("## âœ… ã‚ªã‚¹ã‚¹ãƒ¡è²·ç›®ï¼ˆåå·®å€¤ãƒ­ã‚¸ãƒƒã‚¯ or ãƒ©ã‚¤ãƒ³æ  ã¨é‡è¤‡ï¼‰")
st.caption("ä¸Šã®4è¡¨ã¯æ—¢å­˜å€™è£œã¨â€œã—ãã„å€¤ã‚¯ãƒªã‚¢â€ã®äº¤å·®æ¸ˆã¿ï¼ãã®ã¾ã¾ã€ãŠã™ã™ã‚ã€ã§ã™ã€‚")


# =========================
#  Tesla369ï½œå‡ºåŠ›çµ±åˆãƒ»æœ€çµ‚ãƒ–ãƒ­ãƒƒã‚¯ï¼ˆå®‰å®šç‰ˆãƒ»é‡è¤‡ãªã— / 3è»Šãƒ©ã‚¤ãƒ³åšã‚å¯¾å¿œï¼‰
# =========================
import re, json, hashlib, math
from typing import List, Dict, Any, Optional

# ---------- åŸºæœ¬ãƒ˜ãƒ«ãƒ‘ ----------
def _t369_norm(s) -> str:
    return (str(s) if s is not None else "").replace("ã€€", " ").strip()

def _t369_safe_mean(xs, default: float = 0.0) -> float:
    try:
        return sum(xs) / len(xs) if xs else default
    except Exception:
        return default

def _t369_sigmoid(x: float) -> float:
    try:
        return 1.0 / (1.0 + math.exp(-2.0 * x))
    except OverflowError:
        return 0.0 if x < 0 else 1.0

# ---------- æ–‡è„ˆâ†’ãƒ©ã‚¤ãƒ³/å°/ã‚¹ã‚³ã‚¢å¾©å…ƒ ----------
def _t369_parse_lines_from_context() -> List[List[int]]:
    # _groups å„ªå…ˆ
    try:
        _gs = globals().get("_groups") or []
        if _gs:
            out: List[List[int]] = []
            for g in _gs:
                ln = [int(x) for x in g if str(x).strip()]
                if ln: out.append(ln)
            if out: return out
    except Exception:
        pass
    # line_inputsï¼ˆä¾‹ï¼š"16","524","37"...ï¼‰
    try:
        arr = [_t369_norm(x) for x in (globals().get("line_inputs") or []) if _t369_norm(x)]
        out: List[List[int]] = []
        for s in arr:
            nums = [int(ch) for ch in s if ch.isdigit()]
            if nums: out.append(nums)
        return out
    except Exception:
        return []

def _t369_lines_str(lines: List[List[int]]) -> str:
    return " ".join("".join(str(n) for n in ln) for ln in lines)

def _t369_buckets(lines: List[List[int]]) -> Dict[int, str]:
    m: Dict[int, str] = {}
    lid = 0
    for ln in lines:
        if len(ln) == 1:
            m[ln[0]] = f"S{ln[0]}"
        else:
            lid += 1
            for n in ln: m[n] = f"L{lid}"
    return m

# ãƒ©ã‚¤ãƒ³
_lines_list: List[List[int]] = _t369_parse_lines_from_context()
lines_str: str = globals().get("lines_str") or _t369_lines_str(_lines_list)

# å°ï¼ˆresult_marks â†’ {"â—":3,...}ï¼‰
_result_marks_raw = (globals().get("result_marks", {}) or {})
marks: Dict[str, int] = {}
for k, v in _result_marks_raw.items():
    m = re.search(r"\d+", str(v))
    if m:
        try: marks[str(k)] = int(m.group(0))
        except Exception: pass

# ã‚¹ã‚³ã‚¢ï¼ˆrace_t / USED_IDSï¼‰
race_t   = dict(globals().get("race_t", {}) or {})
USED_IDS = list(globals().get("USED_IDS", []) or [])

def _t369_num(v) -> float:
    try: return float(v)
    except Exception:
        try: return float(str(v).replace("%","").strip())
        except Exception: return 0.0

def _t369_get_score_from_entry(e: Any) -> float:
    if isinstance(e, (int, float)): return float(e)
    if isinstance(e, dict):
        for k in ("åå·®å€¤","hensachi","dev","score","sc","S","s","val","value"):
            if k in e: return _t369_num(e[k])
    return 0.0

scores: Dict[int, float] = {}
ids_source = USED_IDS[:] or [n for ln in _lines_list for n in ln]
for n in ids_source:
    e = race_t.get(n, race_t.get(int(n), race_t.get(str(n), {})))
    scores[int(n)] = _t369_get_score_from_entry(e)
for n in [x for ln in _lines_list for x in ln]:
    scores.setdefault(int(n), 0.0)

# ---------- æµã‚ŒæŒ‡æ¨™ï¼ˆç°¡æ½”ãƒ»å®‰å®šç‰ˆï¼‰ ----------
def compute_flow_indicators(lines_str, marks, scores):
    parts = [_t369_norm(p) for p in str(lines_str).split() if _t369_norm(p)]
    lines = [[int(ch) for ch in p if ch.isdigit()] for p in parts if any(ch.isdigit() for ch in p)]
    if not lines:
        return {
            "VTX": 0.0, "FR": 0.0, "U": 0.0,
            "note": "ã€æµã‚Œæœªå¾ªç’°ã€‘ãƒ©ã‚¤ãƒ³ãªã— â†’ ã‚±ãƒ³",
            "waves": {}, "vtx_bid": "", "lines": [], "dbg": {}
        }

    buckets = _t369_buckets(lines)
    bucket_to_members = {buckets[ln[0]]: ln for ln in lines}

    def mean(xs, d=0.0):
        try:
            return sum(xs)/len(xs) if xs else d
        except Exception:
            return d

    def avg_score(mem):
        return mean([scores.get(n, 50.0) for n in mem], 50.0)

    muA = mean([avg_score(ln) for ln in lines], 50.0)/100.0
    star_id = marks.get("â—", -999)
    none_id = marks.get("ç„¡", -999)

    def est(mem):
        A = max(10.0, min(avg_score(mem), 90.0))/100.0
        if star_id in mem:
            phi0, d = -0.8, +1
        elif none_id in mem:
            phi0, d = +0.8, -1
        else:
            phi0, d = +0.2, +1
        phi = phi0 + 1.2*(A - muA)
        return A, phi, d

    def S_end(A, phi, t=0.9, f=0.9, gamma=0.12):
        return A*math.exp(-gamma*t)*(2*math.pi*f*math.cos(2*math.pi*f*t+phi) - gamma*math.sin(2*math.pi*f*t+phi))

    waves = {}
    for bid, mem in bucket_to_members.items():
        A, phi, d = est(mem)
        waves[bid] = {"A": A, "phi": phi, "d": d, "S": S_end(A, phi, t=0.9)}

    def bucket_of(x):
        try:
            return buckets.get(int(x), "")
        except Exception:
            return ""

    def I(bi, bj):
        if not bi or not bj or bi not in waves or bj not in waves:
            return 0.0
        return math.cos(waves[bi]["phi"] - waves[bj]["phi"])

    # --- â—ï¼ˆé †æµï¼‰ã¨ ç„¡ï¼ˆé€†æµï¼‰ã®æ±ºå®š ---
    b_star = bucket_of(star_id)
    if not b_star:
        try:
            b_star = max(
                bucket_to_members.keys(),
                key=lambda bid: _t369_safe_mean(
                    [scores.get(n, 50.0) for n in bucket_to_members[bid]], 50.0
                )
            )
        except Exception:
            b_star = ""

    all_buckets = list(bucket_to_members.keys())
    cand_buckets = [bid for bid in all_buckets if bid != b_star]

    b_none = bucket_of(none_id)
    if (not b_none) or (b_none == b_star):
        b_none = None

    if b_none is None:
        posS = [
            (waves.get(bid, {}).get("S", -1e9), bid)
            for bid in cand_buckets
            if waves.get(bid, {}).get("S", -1e9) > 0
        ]
        if posS:
            b_none = max(posS)[1]
    if b_none is None:
        low_mu = sorted(
            cand_buckets,
            key=lambda bid: _t369_safe_mean(
                [scores.get(n, 50.0) for n in bucket_to_members[bid]], 50.0
            )
        )
        if low_mu:
            b_none = low_mu[0]
    if b_none is None:
        anyS = [(waves.get(bid, {}).get("S", -1e9), bid) for bid in cand_buckets]
        if anyS:
            b_none = max(anyS)[1]
    if (not b_none) or (b_none == b_star):
        b_none = cand_buckets[0] if cand_buckets else ""

    # --- VTXï¼ˆä½ç›¸å·®Ã—æŒ¯å¹…ï¼‰ ---
    vtx_list = []
    for bid, mem in bucket_to_members.items():
        if bid in (b_star, b_none):
            continue
        if waves.get(bid, {}).get("S", -1e9) < -0.02:
            continue
        wA = 0.5 + 0.5*waves[bid]["A"]
        v = (0.6*abs(I(bid, b_star)) + 0.4*abs(I(bid, b_none))) * wA
        vtx_list.append((v, bid))
    vtx_list.sort(reverse=True, key=lambda x: x[0])
    VTX     = vtx_list[0][0] if vtx_list else 0.0
    VTX_bid = vtx_list[0][1] if vtx_list else ""

    # --- FRï¼ˆâ—ä¸‹å‘ãÃ—ç„¡ä¸Šå‘ãï¼‰ ---
    ws, wn = waves.get(b_star, {}), waves.get(b_none, {})
    def S_point(w, t=0.95, f=0.9, gamma=0.12):
        if not w:
            return 0.0
        A, phi = w.get("A", 0.0), w.get("phi", 0.0)
        return A * math.exp(-gamma * t) * (
            2*math.pi*f*math.cos(2*math.pi*f*t + phi) - gamma*math.sin(2*math.pi*f*t + phi)
        )
    blend_star = 0.6 * S_point(ws) + 0.4 * ws.get("S", 0.0)
    blend_none = 0.6 * S_point(wn) + 0.4 * wn.get("S", 0.0)
    def sig(x, k=3.0):
        try:
            return 1.0/(1.0+math.exp(-k*x))
        except OverflowError:
            return 0.0 if x < 0 else 1.0
    sd_raw = (sig(-blend_star, 3.0) - 0.5) * 2.0
    nu_raw = (sig( blend_none, 3.0) - 0.5) * 2.0
    sd = max(0.0, sd_raw)
    nu = max(0.05, nu_raw)
    FR = sd * nu

    # --- Uï¼ˆé€†æµåœ§ï¼‰ ---
    vtx_vals = [v for v, _ in vtx_list] or [0.0]
    vtx_mu = _t369_safe_mean(vtx_vals, 0.0)
    vtx_sd = (_t369_safe_mean([(x - vtx_mu)**2 for x in vtx_vals], 0.0))**0.5
    vtx_hi = max(0.60, vtx_mu + 0.35*vtx_sd)
    VTX_high = 1.0 if VTX >= vtx_hi else 0.0
    FR_high  = 1.0 if FR  >= 0.12 else 0.0
    S_max = max(1e-6, max(abs(w["S"]) for w in waves.values()))
    S_noneN = max(0.0, wn.get("S", 0.0)) / S_max
    U_raw = sig(I(b_none, b_star), k=2.0)
    U = max(0.05, (0.6*U_raw + 0.4*S_noneN) * (1.0 if VTX_high > 0 else 0.8))

    def label(bid):
        mem = bucket_to_members.get(bid, [])
        return "".join(map(str, mem)) if mem else "â€”"

    tag = "ç‚¹ç¯" if (VTX_high > 0 and FR_high > 0) else "åˆ¤å®šåŸºæº–å†…"
    note = "\n".join([
        f"ã€é †æµã€‘â—ãƒ©ã‚¤ãƒ³ {label(b_star)}ï¼šå¤±é€Ÿå±é™º {'é«˜' if FR>=0.15 else ('ä¸­' if FR>=0.05 else 'ä½')}",
        f"ã€æ¸¦ã€‘å€™è£œãƒ©ã‚¤ãƒ³ï¼š{label(VTX_bid)}ï¼ˆVTX={VTX:.2f}ï¼‰",
        f"ã€é€†æµã€‘ç„¡ãƒ©ã‚¤ãƒ³ {label(b_none)}ï¼šU={U:.2f}ï¼ˆâ€»åˆ¤å®šåŸºæº–å†…ï¼‰",
    ])

    dbg = {"blend_star": blend_star, "blend_none": blend_none, "sd": sd, "nu": nu, "vtx_hi": vtx_hi}
    return {"VTX": VTX, "FR": FR, "U": U, "note": note, "waves": waves,
            "vtx_bid": VTX_bid, "lines": lines, "dbg": dbg}


# === v2.2: ç›¸æ‰‹4æ ãƒ­ã‚¸ãƒƒã‚¯ï¼ˆ3è»Šåšã‚â€œå¼·åˆ¶ä¿è¨¼â€ï¼†Ué«˜åŸŸã§ã‚‚æœ€å¤§2æšã¾ã§è¨±å®¹ï¼‰===
def select_tri_opponents_v2(
    axis: int,
    lines_str: str,
    hens: Dict[int, float],              # åå·®å€¤/ã‚¹ã‚³ã‚¢ã®ãƒãƒƒãƒ—
    vtx: float,                          # æ¸¦ã®å¼·ã•ï¼ˆ0ã€œ1ï¼‰
    u: float,                            # é€†æµã®å¼·ã•ï¼ˆ0ã€œ1ï¼‰
    marks: Dict[str, int],               # å°ï¼ˆ{'â—':5, ...}ï¼‰
    shissoku_label: str = "ä¸­",         # â—ãƒ©ã‚¤ãƒ³ã®ã€Œå¤±é€Ÿå±é™ºã€ãƒ©ãƒ™ãƒ«ï¼š'ä½'/'ä¸­'/'é«˜'
    vtx_line_str: Optional[str] = None,  # æ¸¦å€™è£œãƒ©ã‚¤ãƒ³æ–‡å­—åˆ—ï¼ˆä¾‹ '375'ï¼‰
    u_line_str: Optional[str] = None,    # é€†æµãƒ©ã‚¤ãƒ³æ–‡å­—åˆ—ï¼ˆä¾‹ '63'ï¼‰
    n_opps: int = 4
) -> List[int]:
    U_HIGH = 0.90  # â† 0.85â†’0.90ã«å¼•ãä¸Šã’ï¼ˆä»£è¡¨1æšåŒ–ã®ç™ºå‹•ã‚’çµã‚‹ï¼‰

    groups     = _t369p_parse_groups(lines_str)
    axis_line  = _t369p_find_line_of(int(axis), groups)
    others_all = [x for g in groups for x in g if x != axis]

    vtx_group = _t369p_parse_groups(vtx_line_str)[0] if vtx_line_str else []
    u_group   = _t369p_parse_groups(u_line_str)[0]   if u_line_str   else []

    # FRãƒ©ã‚¤ãƒ³ï¼ˆâ—ã®ãƒ©ã‚¤ãƒ³ã€‚ãªã‘ã‚Œã°å¹³å‡æœ€å¤§ãƒ©ã‚¤ãƒ³ï¼‰
    g_star  = marks.get("â—")
    FR_line = _t369p_find_line_of(int(g_star), groups) if isinstance(g_star, int) else []
    if not FR_line and groups:
        FR_line = max(groups, key=lambda g: _t369p_line_avg(g, hens))

    thick_groups = [g for g in groups if len(g) >= 3]  # 3è»Š(ä»¥ä¸Š)ãƒ©ã‚¤ãƒ³
    # è»¸ãƒ©ã‚¤ãƒ³ä»¥å¤–ã®â€œæœ€åšâ€ã‚’ç‰¹å®šï¼ˆå¹³å‡åå·®ã§æœ€å¤§ï¼‰
    thick_others = [g for g in thick_groups if g != (axis_line or [])]
    best_thick_other = max(thick_others, key=lambda g: _t369p_line_avg(g, hens), default=None)

    # å¿…é ˆå€™è£œ
    picks_must: List[int] = []

    # â‘  è»¸ç›¸æ–¹ï¼ˆç•ªæ‰‹ï¼‰ã‚’å¼·æ¡ç”¨
    axis_partner = _t369p_best_in_group(axis_line, hens, exclude=axis) if axis_line else None
    if axis_partner is not None:
        picks_must.append(axis_partner)

    # â‘¡ å¯¾æŠ—ãƒ©ã‚¤ãƒ³ä»£è¡¨ï¼ˆå¹³å‡åå·®æœ€å¤§ãƒ©ã‚¤ãƒ³ã®ä»£è¡¨ï¼‰
    other_lines = [g for g in groups if g != axis_line]
    best_other_line = max(other_lines, key=lambda g: _t369p_line_avg(g, hens), default=None)
    opp_rep = _t369p_best_in_group(best_other_line, hens, exclude=None) if best_other_line else None
    if opp_rep is not None:
        picks_must.append(opp_rep)

    # â‘¢ é€†æµä»£è¡¨ï¼ˆUé«˜åŸŸã®ã¿â€œä»£è¡¨â€ï¼‰ã€‚â€»3è»Šu_groupã¯æœ€å¤§2æšã¾ã§è¨±å®¹
    u_rep = None
    if u >= U_HIGH:
        if u_group:
            u_rep = _t369p_best_in_group(u_group, hens, exclude=None)
        else:
            pool = [x for x in others_all if x not in (axis_line or [])]
            u_rep = max(pool, key=lambda x: hens.get(x, 0.0), default=None) if pool else None
        if u_rep is not None:
            picks_must.append(u_rep)

    # â‘£ ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°
    scores_local: Dict[int, float] = {x: 0.0 for x in others_all}
    for x in scores_local:
        scores_local[x] += hens.get(x, 0.0) / 100.0  # åœŸå°

    # è»¸ãƒ©ã‚¤ãƒ³ï¼šç›¸æ–¹å¼·åŒ–ï¼‹åŒãƒ©ã‚¤ãƒ³æ§ãˆã‚
    if axis_partner is not None and axis_partner in scores_local:
        scores_local[axis_partner] += 1.50
    for x in (axis_line or []):
        if x not in (axis, axis_partner) and x in scores_local:
            scores_local[x] += 0.20

    # å¯¾æŠ—ä»£è¡¨ã‚’åŠ ç‚¹
    if opp_rep is not None and opp_rep in scores_local:
        scores_local[opp_rep] += 1.20

    # Ué«˜åŸŸï¼šä»£è¡¨å¼·åŒ–ï¼‹â€œ2æšç›®æŠ‘åˆ¶ï¼ˆ3è»Šãªã‚‰è¨±å®¹2ã¾ã§ï¼‰â€
    if u >= U_HIGH and u_rep is not None and u_rep in scores_local:
        scores_local[u_rep] += 1.00
        if u_group:
            # 3è»Šä»¥ä¸Šãªã‚‰ãƒšãƒŠãƒ«ãƒ†ã‚£ç·©å’Œï¼ˆ-0.15ï¼‰ã€ãã‚Œä»¥å¤–ã¯å¾“æ¥ï¼ˆ-0.40ï¼‰
            penalty = 0.15 if len(u_group) >= 3 else 0.40
            for x in u_group:
                if x != u_rep and x in scores_local:
                    scores_local[x] -= penalty

    # VTXå¢ƒç•Œã®èª¿å¾‹
    if vtx <= 0.55:
        if opp_rep is not None and opp_rep in scores_local:
            scores_local[opp_rep] += 0.40
        for x in (vtx_group or []):
            if x in scores_local:
                scores_local[x] -= 0.20
    elif vtx >= 0.60:
        best_vtx = _t369p_best_in_group(vtx_group, hens, exclude=None) if vtx_group else None
        if best_vtx is not None and best_vtx in scores_local:
            scores_local[best_vtx] += 0.50

    # â—ã€Œå¤±é€Ÿ=é«˜ã€â†’ â—æœ¬äººã‚’æ¸›ç‚¹ãƒ»ç•ªæ‰‹ã‚’åŠ ç‚¹
    if isinstance(g_star, int) and shissoku_label == "é«˜":
        g_line = _t369p_find_line_of(g_star, groups)
        g_ban  = _t369p_best_in_group(g_line, hens, exclude=g_star) if g_line else None
        if g_star in scores_local: scores_local[g_star] -= 0.60
        if g_ban is not None and g_ban in scores_local:
            scores_local[g_ban] += 0.70

    # â˜… 3è»Š(ä»¥ä¸Š)ãƒ©ã‚¤ãƒ³ã¯åšã‚ï¼ˆåŸºç¤åŠ ç‚¹ï¼‰
    for g3 in thick_groups:
        for x in g3:
            if x != axis and x in scores_local:
                scores_local[x] += 0.25
    #  è»¸ãŒ3è»Š(ä»¥ä¸Š)ãªã‚‰â€œåŒãƒ©ã‚¤ãƒ³2æšä½“åˆ¶â€ã‚’æœ€ä½ä¿è¨¼ï¼ˆå¾Œæ®µã§å¼·åˆ¶è£œæ­£ã‚‚å…¥ã‚Œã‚‹ï¼‰
    if axis_line and len(axis_line) >= 3:
        for x in axis_line:
            if x not in (axis, axis_partner) and x in scores_local:
                scores_local[x] += 0.35
    #  æ¸¦/FRãŒ3è»Š(ä»¥ä¸Š)ãªã‚‰ä¸­æ ¸ã‚’å°‘ã—åšã‚
    if vtx_group and len(vtx_group) >= 3:
        best_vtx = _t369p_best_in_group(vtx_group, hens, exclude=None)
        if best_vtx is not None and best_vtx in scores_local:
            scores_local[best_vtx] += 0.30
    if FR_line and len(FR_line) >= 3:
        add_fr = 0.30 if shissoku_label != "é«˜" else 0.15
        for x in FR_line:
            if x != axis and x in scores_local:
                scores_local[x] += add_fr

    # ã¾ãšã¯å¿…é ˆæ ã‚’æ¡ç”¨ï¼ˆé †åºç¶­æŒï¼‰
    def _unique_keep_order(xs: List[int]) -> List[int]:
        seen, out = set(), []
        for x in xs:
            if x not in seen:
                out.append(x); seen.add(x)
        return out
    picks = [x for x in _unique_keep_order(picks_must) if x in scores_local and x != axis]

    # è£œå……ï¼šã‚¹ã‚³ã‚¢é«˜ã„é †ã€‚ãŸã ã—Ué«˜åŸŸã§ã¯ u_group ã®äººæ•°ä¸Šé™ï¼ˆ1 or 2ï¼‰ã‚’å®ˆã‚‹
    def _same_group(a: int, b: int, group: List[int]) -> bool:
        return bool(group and a in group and b in group)

    for x, _sc in sorted(scores_local.items(), key=lambda kv: kv[1], reverse=True):
        if x in picks or x == axis:
            continue
        if u >= U_HIGH and u_group:
            limit = 2 if len(u_group) >= 3 else 1
            cnt_u = sum(1 for y in picks if y in u_group)
            if cnt_u >= limit and any(_same_group(x, y, u_group) for y in picks):
                continue
        picks.append(x)
        if len(picks) >= n_opps:
            break

    # â˜… å¼·åˆ¶ä¿è¨¼ï¼‘ï¼šè»¸ãŒ3è»Š(ä»¥ä¸Š)ãªã‚‰ã€ç›¸æ‰‹4æ ã«åŒãƒ©ã‚¤ãƒ³2æšï¼ˆç›¸æ–¹ï¼‹ã‚‚ã†1æšï¼‰ã‚’å¿…ãšç¢ºä¿
    if axis_line and len(axis_line) >= 3:
        axis_members = [x for x in axis_line if x != axis]
        present = [x for x in picks if x in axis_members]
        if len(present) < 2 and len(axis_members) >= 2:
            cand = max([x for x in axis_members if x not in picks], key=lambda x: hens.get(x, 0.0), default=None)
            if cand is not None:
                drop_cands = [x for x in picks if x not in axis_members]
                if drop_cands:
                    worst = min(drop_cands, key=lambda x: scores_local.get(x, -1e9))
                    picks = [x for x in picks if x != worst] + [cand]

    # â˜… å¼·åˆ¶ä¿è¨¼ï¼’ï¼šè»¸ãƒ©ã‚¤ãƒ³ä»¥å¤–ã§â€œæœ€åšâ€ã®3è»Š(ä»¥ä¸Š)ãƒ©ã‚¤ãƒ³ã¯ã€ç›¸æ‰‹4æ ã«æœ€ä½2æšã‚’ç¢ºä¿
    if best_thick_other:
        have = [x for x in picks if x in best_thick_other]
        need = min(2, len(best_thick_other))  # 2æšï¼ˆã‚°ãƒ«ãƒ¼ãƒ—äººæ•°ãŒ2ãªã‚‰ãã®äººæ•°ï¼‰
        while len(have) < need and len(picks) > 0:
            cand = max([x for x in best_thick_other if x not in picks and x != axis],
                       key=lambda x: hens.get(x, 0.0), default=None)
            if cand is None:
                break
            # è½ã¨ã—ï¼šãã®åšã‚ã‚°ãƒ«ãƒ¼ãƒ—å¤–ã§æœ€ã‚‚ã‚¹ã‚³ã‚¢ã®ä½ã„1å
            drop_cands = [x for x in picks if x not in best_thick_other]
            if not drop_cands:
                break
            worst = min(drop_cands, key=lambda x: scores_local.get(x, -1e9))
            if worst == cand:
                break
            picks = [x for x in picks if x != worst] + [cand]
            have = [x for x in picks if x in best_thick_other]

    # æœ€çµ‚ä¿é™ºï¼šä¸è¶³åˆ†ãŒã‚ã‚Œã°åå·®é †ã§åŸ‹ã‚ã‚‹
    if len(picks) < n_opps:
        rest = [x for x in others_all if x not in picks and x != axis]
        rest_sorted = sorted(rest, key=lambda x: hens.get(x, 0.0), reverse=True)
        for x in rest_sorted:
            picks.append(x)
            if len(picks) >= n_opps:
                break

    # ãƒ¦ãƒ‹ãƒ¼ã‚¯ï¼†ã‚µã‚¤ã‚ºèª¿æ•´
    seen = set()
    picks = [x for x in picks if not (x in seen or seen.add(x))][:n_opps]
    return picks
# === /v2.2 ===


def format_tri_1x4(axis: int, opps: List[int]) -> str:
    opps_sorted = ''.join(str(x) for x in sorted(opps))
    return f"{axis}-{opps_sorted}-{opps_sorted}"

# === PATCHï¼ˆgenerate_tesla_bets ã®ç›´å‰ã«æŒ¿å…¥ï¼‰==============================
# â€» re ã¯ä¸Šã§ import æ¸ˆã¿ã®æƒ³å®šã€‚æœªã‚¤ãƒ³ãƒãƒ¼ãƒˆãªã‚‰ `import re` ã‚’å…ˆé ­ã«è¿½åŠ ã€‚

# è»¸é¸å®šç”¨ï¼ˆgenerate_tesla_bets ã‹ã‚‰å‘¼ã°ã‚Œã‚‹ï¼‰
def _topk(line, k, scores):
    line = list(line or [])
    return sorted(line, key=lambda x: (scores.get(x, -1.0), -int(x)), reverse=True)[:k]

# ---- ç›¸æ‰‹4æ ãƒ­ã‚¸ãƒƒã‚¯ v2.3ï¼ˆ3è»Šåšã‚â€œå¼·åˆ¶ä¿è¨¼â€ï¼‹3åˆ—ç›®ãƒ–ãƒ¼ã‚¹ãƒˆï¼‹Ué«˜åŸŸã§ã‚‚æœ€å¤§2æšè¨±å®¹ï¼‰----
from typing import List, Dict, Optional

def _t369p_parse_groups(lines_str: str) -> List[List[int]]:
    parts = re.findall(r'[0-9]+', str(lines_str or ""))
    groups: List[List[int]] = []
    for p in parts:
        g = [int(ch) for ch in p]
        if g: groups.append(g)
    return groups

def _t369p_find_line_of(num: int, groups: List[List[int]]) -> List[int]:
    for g in groups:
        if num in g:
            return g
    return []

def _t369p_line_avg(g: List[int], hens: Dict[int, float]) -> float:
    if not g: return -1e9
    return sum(hens.get(x, 0.0) for x in g) / len(g)

def _t369p_best_in_group(g: List[int], hens: Dict[int, float], exclude: Optional[int] = None) -> Optional[int]:
    cand = [x for x in (g or []) if x != exclude]
    if not cand: return None
    return max(cand, key=lambda x: hens.get(x, 0.0), default=None)

def select_tri_opponents_v2(
    axis: int,
    lines_str: str,
    hens: Dict[int, float],              # åå·®å€¤/ã‚¹ã‚³ã‚¢ã®ãƒãƒƒãƒ—
    vtx: float,                          # æ¸¦ã®å¼·ã•ï¼ˆ0ã€œ1ï¼‰
    u: float,                            # é€†æµã®å¼·ã•ï¼ˆ0ã€œ1ï¼‰
    marks: Dict[str, int],               # å°ï¼ˆ{'â—':5, ...}ï¼‰
    shissoku_label: str = "ä¸­",         # â—ãƒ©ã‚¤ãƒ³ã®ã€Œå¤±é€Ÿå±é™ºã€ï¼š'ä½'/'ä¸­'/'é«˜'
    vtx_line_str: Optional[str] = None,  # æ¸¦å€™è£œãƒ©ã‚¤ãƒ³ï¼ˆä¾‹ '375'ï¼‰
    u_line_str: Optional[str] = None,    # é€†æµãƒ©ã‚¤ãƒ³ï¼ˆä¾‹ '63'ï¼‰
    n_opps: int = 4
) -> List[int]:
    # ã—ãã„å€¤/ãƒ–ãƒ¼ã‚¹ãƒˆï¼ˆå¿…è¦ãªã‚‰ã“ã“ã ã‘èª¿æ•´ï¼‰
    U_HIGH       = 0.90   # é€†æµâ€œä»£è¡¨1æšåŒ–â€ã®ç™ºå‹•ã—ãã„å€¤ï¼ˆå¾“æ¥0.85â†’çµã‚Šè¾¼ã¿ï¼‰
    THIRD_BOOST  = 0.18   # â˜…3åˆ—ç›®ï¼ˆ3è»Šãƒ©ã‚¤ãƒ³ã®ä¸‰ç•ªæ‰‹ï¼‰æ•‘æ¸ˆãƒ–ãƒ¼ã‚¹ãƒˆ
    THICK_BASE   = 0.25   # 3è»Š(ä»¥ä¸Š)ãƒ©ã‚¤ãƒ³ã®åŸºç¤åŠ ç‚¹
    AXIS_LINE_2P = 0.35   # è»¸ãŒ3è»Šä»¥ä¸Šã®ã¨ãã€ç›¸æ–¹ä»¥å¤–ã®åŒãƒ©ã‚¤ãƒ³åŠ ç‚¹

    groups     = _t369p_parse_groups(lines_str)
    axis_line  = _t369p_find_line_of(int(axis), groups)
    others_all = [x for g in groups for x in g if x != axis]

    vtx_group = _t369p_parse_groups(vtx_line_str)[0] if vtx_line_str else []
    u_group   = _t369p_parse_groups(u_line_str)[0]   if u_line_str   else []

    # FRãƒ©ã‚¤ãƒ³ï¼ˆâ—ã®ãƒ©ã‚¤ãƒ³ã€‚ãªã‘ã‚Œã°å¹³å‡æœ€å¤§ï¼‰
    g_star  = marks.get("â—")
    FR_line = _t369p_find_line_of(int(g_star), groups) if isinstance(g_star, int) else []
    if not FR_line and groups:
        FR_line = max(groups, key=lambda g: _t369p_line_avg(g, hens))

    # 3è»Š(ä»¥ä¸Š)ãƒ©ã‚¤ãƒ³ç¾¤
    thick_groups     = [g for g in groups if len(g) >= 3]
    thick_others     = [g for g in thick_groups if g != (axis_line or [])]
    best_thick_other = max(thick_others, key=lambda g: _t369p_line_avg(g, hens), default=None)

    # å¿…é ˆæ 
    picks_must: List[int] = []

    # â‘  è»¸ç›¸æ–¹ï¼ˆç•ªæ‰‹ï¼‰
    axis_partner = _t369p_best_in_group(axis_line, hens, exclude=axis) if axis_line else None
    if axis_partner is not None:
        picks_must.append(axis_partner)

    # â‘¡ å¯¾æŠ—ãƒ©ã‚¤ãƒ³ä»£è¡¨ï¼ˆå¹³å‡åå·®æœ€å¤§ãƒ©ã‚¤ãƒ³ï¼‰
    other_lines = [g for g in groups if g != axis_line]
    best_other_line = max(other_lines, key=lambda g: _t369p_line_avg(g, hens), default=None)
    opp_rep = _t369p_best_in_group(best_other_line, hens, exclude=None) if best_other_line else None
    if opp_rep is not None:
        picks_must.append(opp_rep)

    # â‘¢ é€†æµä»£è¡¨ï¼ˆUé«˜åŸŸã®ã¿ï¼‰ã€‚â€»3è»Šu_groupã¯æœ€å¤§2æšã¾ã§è¨±å®¹
    u_rep = None
    if u >= U_HIGH:
        if u_group:
            u_rep = _t369p_best_in_group(u_group, hens, exclude=None)
        else:
            pool = [x for x in others_all if x not in (axis_line or [])]
            u_rep = max(pool, key=lambda x: hens.get(x, 0.0), default=None) if pool else None
        if u_rep is not None:
            picks_must.append(u_rep)

    # â‘£ ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°
    scores_local: Dict[int, float] = {x: 0.0 for x in others_all}
    for x in scores_local:
        scores_local[x] += hens.get(x, 0.0) / 100.0  # åœŸå°

    # è»¸ãƒ©ã‚¤ãƒ³ï¼šç›¸æ–¹ã‚’å¼·åŒ–ã€åŒãƒ©ã‚¤ãƒ³ä»–ã¯æ§ãˆã‚
    if axis_partner is not None and axis_partner in scores_local:
        scores_local[axis_partner] += 1.50
    for x in (axis_line or []):
        if x not in (axis, axis_partner) and x in scores_local:
            scores_local[x] += 0.20

    # å¯¾æŠ—ä»£è¡¨ã®åº•ä¸Šã’
    if opp_rep is not None and opp_rep in scores_local:
        scores_local[opp_rep] += 1.20

    # Ué«˜åŸŸï¼šä»£è¡¨å¼·åŒ–ï¼‹â€œ2æšç›®æŠ‘åˆ¶ï¼ˆ3è»Šã¯ãƒšãƒŠãƒ«ãƒ†ã‚£ç·©å’Œï¼‰â€
    if u >= U_HIGH and u_rep is not None and u_rep in scores_local:
        scores_local[u_rep] += 1.00
        if u_group:
            penalty = 0.15 if len(u_group) >= 3 else 0.40
            for x in u_group:
                if x != u_rep and x in scores_local:
                    scores_local[x] -= penalty

    # VTXå¢ƒç•Œã®èª¿å¾‹
    if vtx <= 0.55:
        if opp_rep is not None and opp_rep in scores_local:
            scores_local[opp_rep] += 0.40
        for x in (vtx_group or []):
            if x in scores_local:
                scores_local[x] -= 0.20
    elif vtx >= 0.60:
        best_vtx = _t369p_best_in_group(vtx_group, hens, exclude=None) if vtx_group else None
        if best_vtx is not None and best_vtx in scores_local:
            scores_local[best_vtx] += 0.50

    # â—ã€Œå¤±é€Ÿ=é«˜ã€â†’ â—ã‚ˆã‚Šç•ªæ‰‹å¯„ã‚Š
    if isinstance(g_star, int) and shissoku_label == "é«˜":
        g_line = _t369p_find_line_of(g_star, groups)
        g_ban  = _t369p_best_in_group(g_line, hens, exclude=g_star) if g_line else None
        if g_star in scores_local: scores_local[g_star] -= 0.60
        if g_ban is not None and g_ban in scores_local:
            scores_local[g_ban] += 0.70

    # â˜… 3è»Š(ä»¥ä¸Š)ãƒ©ã‚¤ãƒ³åšã‚ï¼šåŸºç¤åŠ ç‚¹ï¼‹â€œ3åˆ—ç›®â€ãƒ–ãƒ¼ã‚¹ãƒˆ
    for g3 in thick_groups:
        for x in g3:
            if x != axis and x in scores_local:
                scores_local[x] += THICK_BASE
        g_sorted = sorted(g3, key=lambda x: hens.get(x, 0.0), reverse=True)
        if len(g_sorted) >= 3:
            third = g_sorted[2]
            if third != axis and third in scores_local:
                scores_local[third] += THIRD_BOOST

    # è»¸ãŒ3è»Š(ä»¥ä¸Š)ï¼šåŒãƒ©ã‚¤ãƒ³2æšä½“åˆ¶ã‚’å¼·åŒ–
    if axis_line and len(axis_line) >= 3:
        for x in axis_line:
            if x not in (axis, axis_partner) and x in scores_local:
                scores_local[x] += AXIS_LINE_2P

    # æ¸¦/FRãŒ3è»Š(ä»¥ä¸Š)ï¼šä¸­æ ¸ã‚’å°‘ã—åšã‚
    if vtx_group and len(vtx_group) >= 3:
        best_vtx = _t369p_best_in_group(vtx_group, hens, exclude=None)
        if best_vtx is not None and best_vtx in scores_local:
            scores_local[best_vtx] += 0.30
    if FR_line and len(FR_line) >= 3:
        add_fr = 0.30 if shissoku_label != "é«˜" else 0.15
        for x in FR_line:
            if x != axis and x in scores_local:
                scores_local[x] += add_fr

    # å¿…é ˆï¼ˆé †åºç¶­æŒï¼‰
    def _unique_keep_order(xs: List[int]) -> List[int]:
        seen, out = set(), []
        for x in xs:
            if x not in seen:
                out.append(x); seen.add(x)
        return out
    picks = [x for x in _unique_keep_order(picks_must) if x in scores_local and x != axis]

    # è£œå……ï¼šã‚¹ã‚³ã‚¢é †ã€‚Ué«˜åŸŸã§ã¯ u_group ã®äººæ•°ä¸Šé™ï¼ˆ1 or 2ï¼‰ã‚’å®ˆã‚‹
    def _same_group(a: int, b: int, group: List[int]) -> bool:
        return bool(group and a in group and b in group)

    for x, _sc in sorted(scores_local.items(), key=lambda kv: kv[1], reverse=True):
        if x in picks or x == axis:
            continue
        if u >= U_HIGH and u_group:
            limit = 2 if len(u_group) >= 3 else 1
            cnt_u = sum(1 for y in picks if y in u_group)
            if cnt_u >= limit and any(_same_group(x, y, u_group) for y in picks):
                continue
        picks.append(x)
        if len(picks) >= n_opps:
            break

    # â˜… å¼·åˆ¶ä¿è¨¼ï¼‘ï¼šè»¸ãŒ3è»Š(ä»¥ä¸Š)â†’ç›¸æ‰‹4æ ã«åŒãƒ©ã‚¤ãƒ³2æšï¼ˆç›¸æ–¹ï¼‹ã‚‚ã†1æšï¼‰ã‚’ç¢ºä¿
    if axis_line and len(axis_line) >= 3:
        axis_members = [x for x in axis_line if x != axis]
        present = [x for x in picks if x in axis_members]
        if len(present) < 2 and len(axis_members) >= 2:
            cand = max([x for x in axis_members if x not in picks], key=lambda x: hens.get(x, 0.0), default=None)
            if cand is not None:
                drop_cands = [x for x in picks if x not in axis_members]
                if drop_cands:
                    worst = min(drop_cands, key=lambda x: scores_local.get(x, -1e9))
                    picks = [x for x in picks if x != worst] + [cand]

    # â˜… å¼·åˆ¶ä¿è¨¼ï¼’ï¼šè»¸ä»¥å¤–ã§â€œæœ€åšâ€ã®3è»Š(ä»¥ä¸Š)ãƒ©ã‚¤ãƒ³â†’ç›¸æ‰‹4æ ã«æœ€ä½2æšã‚’ç¢ºä¿
    if best_thick_other:
        have = [x for x in picks if x in best_thick_other]
        need = min(2, len(best_thick_other))
        while len(have) < need and len(picks) > 0:
            cand = max([x for x in best_thick_other if x not in picks and x != axis],
                       key=lambda x: hens.get(x, 0.0), default=None)
            if cand is None:
                break
            drop_cands = [x for x in picks if x not in best_thick_other]
            if not drop_cands:
                break
            worst = min(drop_cands, key=lambda x: scores_local.get(x, -1e9))
            if worst == cand:
                break
            picks = [x for x in picks if x != worst] + [cand]
            have = [x for x in picks if x in best_thick_other]

    # æœ€çµ‚ä¿é™º
    if len(picks) < n_opps:
        rest = [x for x in others_all if x not in picks and x != axis]
        rest_sorted = sorted(rest, key=lambda x: hens.get(x, 0.0), reverse=True)
        for x in rest_sorted:
            picks.append(x)
            if len(picks) >= n_opps:
                break

    # ãƒ¦ãƒ‹ãƒ¼ã‚¯ï¼†ã‚µã‚¤ã‚ºèª¿æ•´
    seen = set()
    picks = [x for x in picks if not (x in seen or seen.add(x))][:n_opps]
    return picks
# === /PATCH ==============================================================

# ======================= T369ï½œFREE-ONLY å®Œå…¨ç½®æ›ãƒ–ãƒ­ãƒƒã‚¯ =======================

# ---- å°ãƒ˜ãƒ«ãƒ‘ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«åã§è¡çªå›é¿ï¼‰ -----------------------------------------
def _free_fmt_nums(arr):
    if isinstance(arr, list):
        return "".join(str(x) for x in arr) if arr else "â€”"
    return "â€”"

def _free_fmt_hens(ts_map: dict, ids) -> str:
    ids = list(ids or [])
    ts_map = ts_map or {}
    lines = []
    for n in ids:
        v = ts_map.get(n, "â€”")
        lines.append(f"{n}: {float(v):.1f}" if isinstance(v, (int, float)) else f"{n}: â€”")
    return "\n".join(lines)

def _free_fmt_marks_line(marks_dict: dict, used_ids: list) -> tuple[str, str]:
    ids_set = set(used_ids or [])
    marks_dict = marks_dict or {}
    used_marks = set(marks_dict.values())
    try:
        no_mark_ids = [int(i) for i in ids_set if int(i) not in used_marks]
    except Exception:
        no_mark_ids = []
    marks_str = ' '.join(f'{m}{marks_dict[m]}' for m in ['â—','ã€‡','â–²','â–³','Ã—','Î±'] if m in marks_dict) or ""
    no_str = ' ã‚’é™¤ãæœªæŒ‡åï¼š' + (' '.join(map(str, sorted(no_mark_ids))) if no_mark_ids else 'â€”')
    return marks_str, f"ç„¡{('â€”' if 'ç„¡' in marks_dict else '')}{no_str}"

def _free_infer_eval(flow):
    FRv = float((flow or {}).get("FR", 0.0))
    return f"FR={FRv:.3f}"


def _free_risk_out(fr):
    fr = float(fr or 0.0)
    if fr >= 0.55: return "é«˜"
    if fr >= 0.25: return "ä¸­"
    return "ä½"

def _free_norm_marks(marks_any):
    marks_any = dict(marks_any or {})
    if not marks_any:
        return {}
    # å€¤ãŒå…¨éƒ¨ int â†’ {å°:è»Šç•ª} ã¨åˆ¤æ–­ã—åè»¢
    if all(isinstance(v, int) for v in marks_any.values()):
        out = {}
        for k, v in marks_any.items():
            try:
                out[int(v)] = str(k)
            except Exception:
                pass
        return out
    # ãã‚Œä»¥å¤–ã¯ {è»Šç•ª:å°}
    out = {}
    for k, v in marks_any.items():
        try:
            out[int(k)] = str(v)
        except Exception:
            pass
    return out

def trio_free_completion(scores, marks_any, risk_label="", flow_ctx=None) -> str:
    """
    é€†æµè£œå®Œå‹ï¼ˆæµã‚Œå´©å£Šå›ºå®šï¼‰
    è»¸ï¼š
      - å¤±é€Ÿå±é™ºã€Œé«˜ã€ã‹ã¤ å±é™ºãƒ©ã‚¤ãƒ³=â—ãƒ©ã‚¤ãƒ³ â†’ â—ã‚’é¿ã‘ã¦ã€Œéâ—ãƒˆãƒƒãƒ—ã€
      - å¤±é€Ÿå±é™ºã€Œé«˜ã€ã‹ã¤ å±é™ºãƒ©ã‚¤ãƒ³=ã€‡ãƒ©ã‚¤ãƒ³ â†’ è»¸=â—ï¼ˆã‚ã‚Œã°ï¼‰
      - ãã‚Œä»¥å¤– â†’ ã€Œéâ—ãƒˆãƒƒãƒ—ã€ï¼ˆâ—ä¸åœ¨ãªã‚‰å…¨ä½“ãƒˆãƒƒãƒ—ï¼‰
    ç›¸æ‰‹4ï¼šè»¸ã‚’é™¤ãåå·®å€¤ä¸Šä½4ï¼ˆÎ±è£œå®Œã¯æœ€ä¸‹ä½ç½®æ›ï¼†æœ«å°¾ï¼‰
    å‡ºåŠ›ï¼š<è»¸>-<ç›¸æ‰‹4>-<ç›¸æ‰‹4>
    """
    hens = {int(k): float(v) for k, v in (scores or {}).items() if str(k).isdigit()}
    if not hens:
        return "â€”"

    # å°æ­£è¦åŒ–
    def _norm(m):
        m = dict(m or {})
        if m and all(isinstance(v, int) for v in m.values()):
            out = {}
            for k, v in m.items():
                try: out[int(v)] = str(k)
                except: pass
            return out
        out = {}
        for k, v in m.items():
            try: out[int(k)] = str(v)
            except: pass
        return out

    marks = _norm(marks_any)
    natural = sorted(hens.keys(), key=lambda k: (hens[k], k), reverse=True)

    star_id    = next((cid for cid, m in marks.items() if str(m).strip() == "â—"), None)
    circle_id  = next((cid for cid, m in marks.items() if str(m).strip() == "ã€‡"), None)

    # å±é™ºãƒ©ã‚¤ãƒ³ï¼ˆgenerate_tesla_bets å´ã§ FR_line ã‚’å…¥ã‚Œã¦æ¸¡ã™ï¼‰
    risky_line = list(((flow_ctx or {}).get("risky_line") or []))

    # ---- è»¸æ±ºå®šï¼ˆå¯¾ç§°ãƒ«ãƒ¼ãƒ«å¯¾å¿œï¼‰----
    axis = None
    if str(risk_label) == "é«˜":
        # å±é™ºãƒ©ã‚¤ãƒ³ãŒã€‡å´ â†’ è»¸=â—ï¼ˆã‚ã‚Œã°ï¼‰
        if isinstance(circle_id, int) and (circle_id in risky_line) and isinstance(star_id, int):
            axis = star_id
        # å±é™ºãƒ©ã‚¤ãƒ³ãŒâ—å´ â†’ â—ã‚’é¿ã‘ã¦éâ—ãƒˆãƒƒãƒ—
        elif isinstance(star_id, int) and (star_id in risky_line):
            axis = next((n for n in natural if n != star_id), None)

    # é€šå¸¸ï¼ˆã¾ãŸã¯æœªæ±ºï¼‰â†’ éâ—ãƒˆãƒƒãƒ—ï¼ˆâ—ãŒç„¡ã‘ã‚Œã°å…¨ä½“ãƒˆãƒƒãƒ—ï¼‰
    if axis is None:
        if isinstance(star_id, int):
            axis = next((n for n in natural if n != star_id), None)
        if axis is None:
            axis = natural[0]

    # ç›¸æ‰‹4
    base = [n for n in natural if n != axis][:4]

    # Î±è£œå®Œï¼ˆæœ€ä¸‹ä½ã¨ç½®æ›â†’Î±ã‚’æœ«å°¾ï¼‰
    alpha_id = next((cid for cid, m in marks.items() if str(m).strip() == "Î±"), None)
    if isinstance(alpha_id, int) and (alpha_id in hens):
        if alpha_id != axis and alpha_id not in base:
            if base:
                drop = min(base, key=lambda x: hens.get(x, 0.0))
                base = [x for x in base if x != drop] + [alpha_id]
            else:
                base = [alpha_id]

    group = ''.join(str(x) for x in base)
    return f"{axis}-{group}-{group}"

# ---- generate_tesla_betsï¼ˆè£œå®Œã®ã¿ï¼æ—§ä¸‰é€£è¤‡ãƒ­ã‚¸ãƒƒã‚¯ã¯ä½¿ã‚ãªã„ï¼‰ -----------------
def generate_tesla_bets(flow, lines_str, marks_any, scores):
    flow   = dict(flow or {})
    scores = {int(k): float(v) for k, v in (scores or {}).items() if str(k).isdigit()}
    marks  = _free_norm_marks(marks_any)

    # è¡¨ç¤ºç”¨ï¼ˆFR/VTX/U ã¨å„ãƒ©ã‚¤ãƒ³ã¯â€œè¦‹ã›ã‚‹ã ã‘â€ï¼‰
    FRv  = float(flow.get("FR", 0.0) or 0.0)
    VTXv = float(flow.get("VTX", 0.0) or 0.0)
    Uv   = float(flow.get("U", 0.0) or 0.0)

    lines = list(flow.get("lines") or [])
    def _avg(ln):
        xs = [scores.get(n, 0.0) for n in (ln or [])]
        return (sum(xs) / len(xs)) if xs else -1e9

    star_id = next((cid for cid, m in marks.items() if m == "â—"), None)
    FR_line = next((ln for ln in lines if isinstance(star_id, int) and star_id in ln), [])

    vtx_bid = str(flow.get("vtx_bid") or "")
    VTX_line = next((ln for ln in lines if "".join(map(str, ln)) == vtx_bid), [])
    if not VTX_line:
        VTX_line = next((ln for ln in sorted([g for g in lines if g != FR_line], key=_avg, reverse=True)), [])

    none_id = next((cid for cid, m in marks.items() if m == "ç„¡"), None)
    U_line  = next((ln for ln in lines if isinstance(none_id, int) and none_id in ln), [])
    if not U_line:
        remain = [g for g in lines if g not in (FR_line, VTX_line)]
        remain.sort(key=_avg)
        U_line = remain[0] if remain else []

        # â€¦ï¼ˆFR_line / VTX_line / U_line / FRv ãªã©ã®ç®—å‡ºã¯ãã®ã¾ã¾ï¼‰

        note_lines = ["ã€è²·ã„ç›®ã€‘"]
        risk_lbl = _free_risk_out(FRv)  # â† è¿½åŠ ï¼š'ä½'/'ä¸­'/'é«˜'
        trio_text = trio_free_completion(
            scores,                      # åå·®å€¤
            marks,                       # å°ï¼ˆæ­£è¦åŒ–å‰ã§ã‚‚OKï¼‰
            risk_label=risk_lbl,         # â† è¿½åŠ 
            flow_ctx={"risky_line": FR_line}  # â† è¿½åŠ ï¼šå¤±é€Ÿåˆ¤å®šãƒ©ã‚¤ãƒ³ã‚’æ¸¡ã™
        )
        note_lines.append(f"ä¸‰é€£è¤‡ï¼š{trio_text}")


    return {
        "FR_line": FR_line, "VTX_line": VTX_line, "U_line": U_line,
        "FRv": FRv, "VTXv": VTXv, "Uv": Uv,
        "trios": [],  # ä½¿ã‚ãªã„
        "note": "\n".join(note_lines),
    }

# ---- _safe_flow/_safe_generateï¼ˆæ—¢å­˜ãŒå£Šã‚Œã¦ã„ã¦ã‚‚ä¸Šæ›¸ãå®‰å…¨ï¼‰ -------------------
def _safe_flow(lines_str, marks, scores):
    try:
        fr = compute_flow_indicators(lines_str, marks, scores)
        return fr if isinstance(fr, dict) else {}
    except Exception:
        return {}

def _safe_generate(flow, lines_str, marks, scores):
    try:
        res = generate_tesla_bets(flow, lines_str, marks, scores)
        return res if isinstance(res, dict) else {"note": "ã€è²·ã„ç›®ã€‘å‡ºåŠ›ãªã—"}
    except Exception as e:
        return {"note": f"âš  generate_tesla_betsã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e}"}

# ---- å‡ºåŠ›æœ¬ä½“ï¼ˆãƒ˜ãƒƒãƒ€â†’åå·®å€¤â†’FR/VTX/Uâ†’è£œå®Œã®è²·ã„ç›® ã®é †ã§1å›ã ã‘æç”»ï¼‰ --------
# æ—§ã®äºŒé‡æç”»ã‚¬ãƒ¼ãƒ‰ã¯æ’¤å»ï¼ˆæ¯å›æãï¼‰
_flow = _safe_flow(globals().get("lines_str", ""), globals().get("marks", {}), globals().get("scores", {}))
_bets = _safe_generate(_flow, globals().get("lines_str", ""), globals().get("marks", {}), globals().get("scores", {}))

if 'note_sections' not in globals() or not isinstance(note_sections, list):
    note_sections = []

# æ—§ã®ã‚¬ãƒ™ãƒ¼ã‚¸ï¼ˆãƒ•ã‚©ãƒ¼ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³å‡ºåŠ›/DBGè¡Œãªã©ï¼‰ã‚’å‰Šé™¤
def _free_kill_old(s: str) -> bool:
    if not isinstance(s, str): return False
    t = s.strip()
    return (t.startswith("DBG:") or
            t.startswith("ã€è²·ã„ç›®ã€‘") or
            t.startswith("ä¸‰é€£è¤‡ï¼š") or
            "ä¸‰é€£è¤‡ãƒ•ã‚©ãƒ¼ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³" in t or
            "ãƒ•ã‚©ãƒ¼ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆå›ºå®š" in t)
note_sections = [s for s in note_sections if not _free_kill_old(s)]

# è¦‹å‡ºã—
venue   = str(globals().get("track") or globals().get("place") or "").strip()
race_no = str(globals().get("race_no") or "").strip()
if venue or race_no:
    _rn = race_no if (race_no.endswith("R") or race_no == "") else f"{race_no}R"
    note_sections.append(f"{venue}{_rn}")

note_sections.append(f"å±•é–‹è©•ä¾¡ï¼š{_free_infer_eval(_flow)}")

race_time  = str(globals().get('race_time', '') or '')
race_class = str(globals().get('race_class', '') or '')
hdr = f"{race_time}ã€€{race_class}".strip()
if hdr:
    note_sections.append(hdr)

# ãƒ©ã‚¤ãƒ³
line_inputs = globals().get('line_inputs', [])
if isinstance(line_inputs, list) and any(str(x).strip() for x in line_inputs):
    note_sections.append(f"ãƒ©ã‚¤ãƒ³ã€€{'ã€€'.join([x for x in line_inputs if str(x).strip()])}")

# ã‚¹ã‚³ã‚¢é †ï¼ˆSBãªã—ï¼‰
_fmt_rank_fn = globals().get('_format_rank_from_array', None)
USED_IDS    = list(globals().get('USED_IDS', []))
xs_base_raw = globals().get('xs_base_raw', [])
if callable(_fmt_rank_fn):
    try:
        note_sections.append(f"ã‚¹ã‚³ã‚¢é †ï¼ˆSBãªã—ï¼‰ã€€{_fmt_rank_fn(USED_IDS, xs_base_raw)}")
    except Exception:
        note_sections.append(f"ã‚¹ã‚³ã‚¢é †ï¼ˆSBãªã—ï¼‰ã€€{' '.join(map(str, USED_IDS))}")
else:
    note_sections.append(f"ã‚¹ã‚³ã‚¢é †ï¼ˆSBãªã—ï¼‰ã€€{' '.join(map(str, USED_IDS))}")

# å°ï¼‹æœªæŒ‡å
try:
    result_marks = globals().get('result_marks', {})
    marks_str, no_str = _free_fmt_marks_line(result_marks, USED_IDS)
    mline = f"{marks_str} {no_str}".strip()
    if mline:
        note_sections.append(mline)
except Exception:
    pass

# åå·®å€¤
try:
    race_t = dict(globals().get('race_t', {}))
    note_sections.append("\nåå·®å€¤ï¼ˆé¢¨ãƒ»ãƒ©ã‚¤ãƒ³è¾¼ã¿ï¼‰")
    note_sections.append(_free_fmt_hens(race_t, USED_IDS))
    note_sections.append("\n")
except Exception:
    note_sections.append("åå·®å€¤ãƒ‡ãƒ¼ã‚¿ãªã—\n")

# ===================== /T369ï½œFREE-ONLY å®Œå…¨ç½®æ›ãƒ–ãƒ­ãƒƒã‚¯ =====================

# FR/VTX/Uï¼ˆè¡¨ç¤ºï¼‰
_FR_line  = _bets.get("FR_line", _flow.get("FR_line"))
_VTX_line = _bets.get("VTX_line", _flow.get("VTX_line"))
_U_line   = _bets.get("U_line",  _flow.get("U_line"))
_FRv      = float(_bets.get("FRv",  _flow.get("FR", 0.0)) or 0.0)
_VTXv     = float(_bets.get("VTXv", _flow.get("VTX", 0.0)) or 0.0)
_Uv       = float(_bets.get("Uv",   _flow.get("U", 0.0)) or 0.0)

if (_FR_line is not None) or (_VTX_line is not None) or (_U_line is not None):
    note_sections.append(f"ã€é †æµã€‘â—ãƒ©ã‚¤ãƒ³ {_free_fmt_nums(_FR_line)}ï¼šFR={_FRv:.3f}")
    note_sections.append(f"ã€æ¸¦ã€‘å€™è£œãƒ©ã‚¤ãƒ³ï¼š{_free_fmt_nums(_VTX_line)}ï¼ˆVTX={_VTXv:.3f}ï¼‰")
    note_sections.append(f"ã€é€†æµã€‘ç„¡ãƒ©ã‚¤ãƒ³ {_free_fmt_nums(_U_line)}ï¼šU={_Uv:.3f}ï¼ˆâ€»åˆ¤å®šåŸºæº–å†…ï¼‰")
else:
    note_sections.append(_flow.get("note", "ã€æµã‚Œã€‘å‡ºåŠ›ãªã—"))

# è£œå®Œã®è²·ã„ç›®ï¼ˆã“ã‚Œã ã‘ã‚’å‡ºã™ï¼‰
note_sections.append(_bets.get("note", "ã€è²·ã„ç›®ã€‘å‡ºåŠ›ãªã—"))

# ==== è¨ºæ–­ï¼ˆå®‰å…¨ã‚¬ãƒ¼ãƒ‰ä»˜ãï¼‰ ====
try:
    _dbg_lines_list = globals().get('_lines_list') or globals().get('lines_list') or 'â€”'
    _dbg_marks      = globals().get('marks', {}) or 'â€”'
    _dbg_scores_all = globals().get('scores', {})
    try:
        _dbg_scores_keys = sorted((_dbg_scores_all or {}).keys())
    except Exception:
        _dbg_scores_keys = 'â€”'

    _dbg_lines_str = globals().get('lines_str', '')
    _flow_diag_raw = compute_flow_indicators(_dbg_lines_str, _dbg_marks, _dbg_scores_all)
    _flow_diag     = _flow_diag_raw if isinstance(_flow_diag_raw, dict) else {}

    note_sections.append(
        "ã€Tesla369è¨ºæ–­ã€‘"
        f"\nFR={_flow_diag.get('FR',0.0):.3f}  "
        f"VTX={_flow_diag.get('VTX',0.0):.3f}  "
        f"U={_flow_diag.get('U',0.0):.3f}"
    )

    _dbg = _flow_diag.get("dbg", {}) if isinstance(_flow_diag, dict) else {}
    if isinstance(_dbg, dict) and _dbg:
        note_sections.append(
            f"[FRå†…è¨³] blend_star={_dbg.get('blend_star',0.0):.3f} "
            f"blend_none={_dbg.get('blend_none',0.0):.3f} "
            f"sd={_dbg.get('sd',0.0):.3f} "
            f"nu={_dbg.get('nu',0.0):.3f}"
        )
except Exception as _e:
    note_sections.append(f"âš  compute_flow_indicators(è¨ºæ–­)ã‚¨ãƒ©ãƒ¼: {type(_e).__name__}: {str(_e)}")

# ===================== /T369ï½œFREE-ONLY å®Œå…¨ç½®æ›ãƒ–ãƒ­ãƒƒã‚¯ =====================


# ===== /Tesla369ï½œå‡ºåŠ›çµ±åˆãƒ»å®Œå…¨ç‰ˆ =====

# =========================
note_text = "\n".join(note_sections)
st.markdown("### ğŸ“‹ noteç”¨ï¼ˆã‚³ãƒ”ãƒ¼ã‚¨ãƒªã‚¢ï¼‰")
st.text_area("ã“ã“ã‚’é¸æŠã—ã¦ã‚³ãƒ”ãƒ¼", note_text, height=560)
# =========================


# =========================
#  ä¸€æ‹¬ç½®æ›ãƒ–ãƒ­ãƒƒã‚¯ ã“ã“ã¾ã§
# =========================
