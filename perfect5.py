# -*- coding: utf-8 -*-
import streamlit as st
import pandas as pd
import numpy as np
import unicodedata, re, math, random, json
import itertools
from typing import Optional

# ==============================
# ãƒšãƒ¼ã‚¸è¨­å®š
# ==============================
st.set_page_config(page_title="ãƒ´ã‚§ãƒ­ãƒ“ï¼šç´šåˆ¥Ã—æ—¥ç¨‹ãƒ€ã‚¤ãƒŠãƒŸã‚¯ã‚¹ï¼ˆ5ã€œ9è»Šãƒ»è²·ã„ç›®ä»˜ãï¼‰", layout="wide")

# ==============================
# å®šæ•°
# ==============================
WIND_COEFF = {
    "å·¦ä¸Š": -0.03, "ä¸Š": -0.05, "å³ä¸Š": -0.035,
    "å·¦": +0.05,  "å³": -0.05,
    "å·¦ä¸‹": +0.035, "ä¸‹": +0.05, "å³ä¸‹": +0.035,
    "ç„¡é¢¨": 0.0
}
BASE_BY_KAKU = {"é€ƒ":1.58, "æ²":1.65, "å·®":1.79, "ãƒ":1.45}

KEIRIN_DATA = {
    "å‡½é¤¨":{"bank_angle":30.6,"straight_length":51.3,"bank_length":400},
    "é’æ£®":{"bank_angle":32.3,"straight_length":58.9,"bank_length":400},
    "ã„ã‚ãå¹³":{"bank_angle":32.9,"straight_length":62.7,"bank_length":400},
    "å¼¥å½¦":{"bank_angle":32.4,"straight_length":63.1,"bank_length":400},
    "å‰æ©‹":{"bank_angle":36.0,"straight_length":46.7,"bank_length":335},
    "å–æ‰‹":{"bank_angle":31.5,"straight_length":54.8,"bank_length":400},
    "å®‡éƒ½å®®":{"bank_angle":25.8,"straight_length":63.3,"bank_length":500},
    "å¤§å®®":{"bank_angle":26.3,"straight_length":66.7,"bank_length":500},
    "è¥¿æ­¦åœ’":{"bank_angle":29.4,"straight_length":47.6,"bank_length":400},
    "äº¬ç‹é–£":{"bank_angle":32.2,"straight_length":51.5,"bank_length":400},
    "ç«‹å·":{"bank_angle":31.2,"straight_length":58.0,"bank_length":400},
    "æ¾æˆ¸":{"bank_angle":29.8,"straight_length":38.2,"bank_length":333},
    "å·å´":{"bank_angle":32.2,"straight_length":58.0,"bank_length":400},
    "å¹³å¡š":{"bank_angle":31.5,"straight_length":54.2,"bank_length":400},
    "å°ç”°åŸ":{"bank_angle":35.6,"straight_length":36.1,"bank_length":333},
    "ä¼Šæ±":{"bank_angle":34.7,"straight_length":46.6,"bank_length":333},
    "é™å²¡":{"bank_angle":30.7,"straight_length":56.4,"bank_length":400},
    "åå¤å±‹":{"bank_angle":34.0,"straight_length":58.8,"bank_length":400},
    "å²é˜œ":{"bank_angle":32.3,"straight_length":59.3,"bank_length":400},
    "å¤§å£":{"bank_angle":30.6,"straight_length":56.0,"bank_length":400},
    "è±Šæ©‹":{"bank_angle":33.8,"straight_length":60.3,"bank_length":400},
    "å¯Œå±±":{"bank_angle":33.7,"straight_length":43.0,"bank_length":333},
    "æ¾å‚":{"bank_angle":34.4,"straight_length":61.5,"bank_length":400},
    "å››æ—¥å¸‚":{"bank_angle":32.3,"straight_length":62.4,"bank_length":400},
    "ç¦äº•":{"bank_angle":31.5,"straight_length":52.8,"bank_length":400},
    "å¥ˆè‰¯":{"bank_angle":33.4,"straight_length":38.0,"bank_length":333},
    "å‘æ—¥ç”º":{"bank_angle":30.5,"straight_length":47.3,"bank_length":400},
    "å’Œæ­Œå±±":{"bank_angle":32.3,"straight_length":59.9,"bank_length":400},
    "å²¸å’Œç”°":{"bank_angle":30.9,"straight_length":56.7,"bank_length":400},
    "ç‰é‡":{"bank_angle":30.6,"straight_length":47.9,"bank_length":400},
    "åºƒå³¶":{"bank_angle":30.8,"straight_length":57.9,"bank_length":400},
    "é˜²åºœ":{"bank_angle":34.7,"straight_length":42.5,"bank_length":333},
    "é«˜æ¾":{"bank_angle":33.3,"straight_length":54.8,"bank_length":400},
    "å°æ¾å³¶":{"bank_angle":29.8,"straight_length":55.5,"bank_length":400},
    "é«˜çŸ¥":{"bank_angle":24.5,"straight_length":52.0,"bank_length":500},
    "æ¾å±±":{"bank_angle":34.0,"straight_length":58.6,"bank_length":400},
    "å°å€‰":{"bank_angle":34.0,"straight_length":56.9,"bank_length":400},
    "ä¹…ç•™ç±³":{"bank_angle":31.5,"straight_length":50.7,"bank_length":400},
    "æ­¦é›„":{"bank_angle":32.0,"straight_length":64.4,"bank_length":400},
    "ä½ä¸–ä¿":{"bank_angle":31.5,"straight_length":40.2,"bank_length":400},
    "åˆ¥åºœ":{"bank_angle":33.7,"straight_length":59.9,"bank_length":400},
    "ç†Šæœ¬":{"bank_angle":34.3,"straight_length":60.3,"bank_length":400},
    "æ‰‹å…¥åŠ›":{"bank_angle":30.0,"straight_length":52.0,"bank_length":400},
}

# --- ç›´è¿‘é›†è¨ˆï¼šå°åˆ¥ã®å®Ÿæ¸¬ç‡ï¼ˆ%â†’å°æ•°ï¼‰ ---
RANK_STATS = {
    "â—": {"p1": 0.200, "pTop2": 0.480, "pTop3": 0.610},
    "ã€‡": {"p1": 0.200, "pTop2": 0.390, "pTop3": 0.470},
    "â–²": {"p1": 0.100, "pTop2": 0.260, "pTop3": 0.430},
    "â–³": {"p1": 0.130, "pTop2": 0.240, "pTop3": 0.400},
    "Ã—": {"p1": 0.190, "pTop2": 0.240, "pTop3": 0.410},
    "Î±": {"p1": 0.133, "pTop2": 0.184, "pTop3": 0.347},  # N=98
    "Î²": {"p1": 0.108, "pTop2": 0.269, "pTop3": 0.409},  # N=93
}

# å°ãŒä»˜ã‹ãªã„è»Šï¼ˆ8ã€œ9è»Šæ™‚ã®ä½™ã‚Šï¼‰ã¸ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
RANK_FALLBACK_MARK = "Î±"

# ===== æœŸå¾…å€¤ãƒ«ãƒ¼ãƒ«ï¼ˆå›ºå®šï¼‰ =====
P_FLOOR = {
    "sanpuku": 0.06,  # ä¸‰é€£è¤‡
    "nifuku" : 0.12,  # äºŒè»Šè¤‡ï¼ˆ7è»Šï¼‰
    "wide"   : 0.25,  # ãƒ¯ã‚¤ãƒ‰
    "nitan"  : 0.07,  # äºŒè»Šå˜
}
E_MIN, E_MAX = 0.10, 0.60  # EV +10% ï½ +60%ï¼ˆè²·ãˆã‚‹å¸¯ï¼‰

# ==============================
# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
# ==============================
def clamp(x,a,b): return max(a, min(b, x))

def zscore_list(arr):
    arr = np.array(arr, dtype=float)
    m, s = float(np.mean(arr)), float(np.std(arr))
    return np.zeros_like(arr) if s==0 else (arr-m)/s

def zscore_val(x, xs):
    xs = np.array(xs, dtype=float); m, s = float(np.mean(xs)), float(np.std(xs))
    return 0.0 if s==0 else (float(x)-m)/s

def extract_car_list(s, nmax):
    s = str(s or "").strip()
    return [int(c) for c in s if c.isdigit() and 1 <= int(c) <= nmax]

def build_line_maps(lines):
    labels = "ABCDEFG"
    line_def = {labels[i]: lst for i,lst in enumerate(lines) if lst}
    car_to_group = {c:g for g,mem in line_def.items() for c in mem}
    return line_def, car_to_group

def role_in_line(car, line_def):
    for g, mem in line_def.items():
        if car in mem:
            if len(mem)==1: return 'single'
            idx = mem.index(car)
            return ['head','second','thirdplus'][idx] if idx<3 else 'thirdplus'
    return 'single'

def pos_coeff(role, line_factor):
    base = {'head':1.0,'second':0.7,'thirdplus':0.5,'single':0.9}.get(role,0.9)
    return base * line_factor

def tenscore_correction(tenscores):
    n = len(tenscores)
    if n<=2: return [0.0]*n
    df = pd.DataFrame({"å¾—ç‚¹":tenscores})
    df["é †ä½"] = df["å¾—ç‚¹"].rank(ascending=False, method="min").astype(int)
    hi = min(n,8); baseline = df[df["é †ä½"].between(2,hi)]["å¾—ç‚¹"].mean()
    def corr(row): return round(abs(baseline-row["å¾—ç‚¹"])*0.03, 3) if row["é †ä½"] in [2,3,4] else 0.0
    return df.apply(corr, axis=1).tolist()

def wind_adjust(wind_dir, wind_speed, role, prof_escape):
    if wind_dir=="ç„¡é¢¨" or wind_speed==0: return 0.0
    wd = WIND_COEFF.get(wind_dir,0.0)
    pos_multi = {'head':0.32,'second':0.30,'thirdplus':0.25,'single':0.30}.get(role,0.30)
    coeff = 0.4 + 0.6*prof_escape
    val = wind_speed * wd * pos_multi * coeff
    return round(clamp(val, -0.05, 0.05), 3)

def bank_character_bonus(bank_angle, straight_length, prof_escape, prof_sashi):
    straight_factor = (float(straight_length)-40.0)/10.0
    angle_factor = (float(bank_angle)-25.0)/5.0
    total = clamp(-0.1*straight_factor + 0.1*angle_factor, -0.05, 0.05)
    return round(total*prof_escape - 0.5*total*prof_sashi, 3)

def bank_length_adjust(bank_length, prof_oikomi):
    delta = clamp((float(bank_length)-411.0)/100.0, -0.05, 0.05)
    return round(delta*prof_oikomi, 3)

def compute_lineSB_bonus(line_def, S, B, line_factor=1.0, exclude=None, cap=0.06, enable=True):
    if not enable or not line_def:
        return {g:0.0 for g in line_def.keys()} if line_def else {}, {}
    w_pos_base = {'head':1.0,'second':0.4,'thirdplus':0.2,'single':0.7}
    Sg, Bg = {}, {}
    for g, mem in line_def.items():
        s=b=0.0
        for car in mem:
            if exclude is not None and car==exclude: continue
            w = w_pos_base[role_in_line(car, line_def)] * line_factor
            s += w*float(S.get(car,0)); b += w*float(B.get(car,0))
        Sg[g]=s; Bg[g]=b
    raw={}
    for g in line_def.keys():
        s, b = Sg[g], Bg[g]
        ratioS = s/(s+b+1e-6)
        raw[g] = (0.6*b + 0.4*s) * (0.6 + 0.4*ratioS)
    zz = zscore_list(list(raw.values())) if raw else []
    bonus={g: clamp(0.02*float(zz[i]), -cap, cap) for i,g in enumerate(raw.keys())}
    return bonus, raw

def input_float_text(label: str, key: str, placeholder: str = "") -> Optional[float]:
    s = st.text_input(label, value=st.session_state.get(key, ""), key=key, placeholder=placeholder)
    ss = unicodedata.normalize("NFKC", str(s)).replace(",", "").strip()
    if ss == "": return None
    if not re.fullmatch(r"[+-]?\d+(\.\d+)?", ss):
        st.warning(f"{label} ã¯æ•°å€¤ã§å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆå…¥åŠ›å€¤: {s}ï¼‰")
        return None
    return float(ss)

# ==== ã‚¾ãƒ¼ãƒ³å‡ºåŠ›ãƒ˜ãƒ«ãƒ‘ãƒ¼ï¼ˆæ–‡ç« å½¢å¼ãƒ»è»Šç•ªé †ï¼‰ ====
def _zone_from_p(p: float) -> tuple[float,float,float]:
    needed = 1.0 / max(p, 1e-12)
    return needed, needed*(1.0+E_MIN), needed*(1.0+E_MAX)

def _format_line_zone(name: str, bet_type: str, p: float) -> str | None:
    """pãŒPãƒ•ãƒ­ã‚¢æœªæº€ãªã‚‰ Noneï¼ˆéè¡¨ç¤ºï¼‰ã€‚ä»¥ä¸Šãªã‚‰ '3â€“4ï¼šx.xã€œy.yå€ãªã‚‰è²·ã„' ã‚’è¿”ã™"""
    floor = P_FLOOR[bet_type]
    if p < floor:
        return None
    _, low, high = _zone_from_p(p)
    return f"{name}ï¼š{low:.1f}ã€œ{high:.1f}å€ãªã‚‰è²·ã„"

def _sort_key_by_numbers(name: str) -> list[int]:
    return list(map(int, re.findall(r"\d+", str(name))))

# ==============================
# ã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼šé–‹å‚¬æƒ…å ± / ãƒãƒ³ã‚¯ãƒ»é¢¨ãƒ»é ­æ•°
# ==============================
st.sidebar.header("é–‹å‚¬æƒ…å ± / ãƒãƒ³ã‚¯ãƒ»é¢¨ãƒ»é ­æ•°")
n_cars = st.sidebar.selectbox("å‡ºèµ°æ•°ï¼ˆ5ã€œ9ï¼‰", [5,6,7,8,9], index=2)

track_names = list(KEIRIN_DATA.keys())
track = st.sidebar.selectbox("ç«¶è¼ªå ´ï¼ˆãƒ—ãƒªã‚»ãƒƒãƒˆï¼‰", track_names, index=track_names.index("å·å´") if "å·å´" in track_names else 0)
info = KEIRIN_DATA[track]

wind_dir = st.sidebar.selectbox("é¢¨å‘", ["ç„¡é¢¨","å·¦ä¸Š","ä¸Š","å³ä¸Š","å·¦","å³","å·¦ä¸‹","ä¸‹","å³ä¸‹"], 0)
wind_speed = st.sidebar.number_input("é¢¨é€Ÿ(m/s)", 0.0, 30.0, 3.0, 0.1)
straight_length = st.sidebar.number_input("ã¿ãªã—ç›´ç·š(m)", 30.0, 80.0, float(info["straight_length"]), 0.1)
bank_angle = st.sidebar.number_input("ãƒãƒ³ã‚¯è§’(Â°)", 20.0, 45.0, float(info["bank_angle"]), 0.1)
bank_length = st.sidebar.number_input("å‘¨é•·(m)", 300.0, 500.0, float(info["bank_length"]), 0.1)

base_laps = st.sidebar.number_input("å‘¨å›ï¼ˆé€šå¸¸4ï¼‰", 1, 10, 4, 1)
day_label = st.sidebar.selectbox("é–‹å‚¬æ—¥", ["åˆæ—¥","2æ—¥ç›®","æœ€çµ‚æ—¥"], 0)
eff_laps = int(base_laps) + {"åˆæ—¥":1,"2æ—¥ç›®":2,"æœ€çµ‚æ—¥":3}[day_label]

race_time = st.sidebar.selectbox("é–‹å‚¬åŒºåˆ†", ["ãƒ¢ãƒ¼ãƒ‹ãƒ³ã‚°","ãƒ‡ã‚¤","ãƒŠã‚¤ã‚¿ãƒ¼","ãƒŸãƒƒãƒ‰ãƒŠã‚¤ãƒˆ"], 1)
race_class = st.sidebar.selectbox("ç´šåˆ¥", ["ï¼³ç´š","ï¼¡ç´š","ï¼¡ç´šãƒãƒ£ãƒ¬ãƒ³ã‚¸","ã‚¬ãƒ¼ãƒ«ã‚º"], 0)

angles = [KEIRIN_DATA[k]["bank_angle"] for k in KEIRIN_DATA]
straights = [KEIRIN_DATA[k]["straight_length"] for k in KEIRIN_DATA]
lengths = [KEIRIN_DATA[k]["bank_length"] for k in KEIRIN_DATA]
angle_z = zscore_val(bank_angle, angles)
straight_z = zscore_val(straight_length, straights)
length_z = zscore_val(bank_length, lengths)
style_raw = clamp(0.50*angle_z - 0.35*straight_z - 0.30*length_z, -1.0, +1.0)

override = st.sidebar.slider("ä¼šå ´ãƒã‚¤ã‚¢ã‚¹è£œæ­£ï¼ˆâˆ’2å·®ã— â†â†’ +2å…ˆè¡Œï¼‰", -2.0, 2.0, 0.0, 0.1)
style = clamp(style_raw + 0.25*override, -1.0, +1.0)

CLASS_FACTORS = {
    "ï¼³ç´š":           {"spread":1.00, "line":1.00},
    "ï¼¡ç´š":           {"spread":0.90, "line":0.85},
    "ï¼¡ç´šãƒãƒ£ãƒ¬ãƒ³ã‚¸": {"spread":0.80, "line":0.70},
    "ã‚¬ãƒ¼ãƒ«ã‚º":       {"spread":0.85, "line":1.00},
}
cf = CLASS_FACTORS[race_class]

DAY_FACTOR = {"åˆæ—¥":1.00, "2æ—¥ç›®":0.60, "æœ€çµ‚æ—¥":0.85}
day_factor = DAY_FACTOR[day_label]

cap_base = clamp(0.06 + 0.02*style, 0.04, 0.08)
line_factor_eff = cf["line"] * day_factor
cap_SB_eff = cap_base * day_factor
if race_time == "ãƒŸãƒƒãƒ‰ãƒŠã‚¤ãƒˆ":
    line_factor_eff *= 0.95
    cap_SB_eff *= 0.95

line_sb_enable = (race_class != "ã‚¬ãƒ¼ãƒ«ã‚º")

st.sidebar.caption(
    f"ä¼šå ´ã‚¹ã‚¿ã‚¤ãƒ«: {style:+.2f}ï¼ˆraw {style_raw:+.2f}ï¼‰ / "
    f"ç´šåˆ¥: spread={cf['spread']:.2f}, line={cf['line']:.2f} / "
    f"æ—¥ç¨‹ä¿‚æ•°(line)={day_factor:.2f} â†’ lineä¿‚æ•°={line_factor_eff:.2f}, SBcapÂ±{cap_SB_eff:.2f}"
)

# ==============================
# ãƒ¡ã‚¤ãƒ³
# ==============================
st.title("â­ ãƒ´ã‚§ãƒ­ãƒ“ï¼ˆç´šåˆ¥Ã—æ—¥ç¨‹ãƒ€ã‚¤ãƒŠãƒŸã‚¯ã‚¹ / 5ã€œ9è»Šãƒ»è²·ã„ç›®ä»˜ãï¼‰â­")

# â–¼â–¼ ãƒ¬ãƒ¼ã‚¹ç•ªå· â–¼â–¼
st.subheader("ãƒ¬ãƒ¼ã‚¹ç•ªå·ï¼ˆç›´å‰ã«ã‚µã‚¯ãƒƒã¨å¤‰æ›´ï¼‰")
if "race_no_main" not in st.session_state:
    st.session_state["race_no_main"] = 1
c1, c2, c3 = st.columns([6,2,2])
with c1:
    race_no_input = st.number_input("R", min_value=1, max_value=12, step=1,
                                    value=int(st.session_state["race_no_main"]),
                                    key="race_no_input")
with c2:
    prev_clicked = st.button("â—€ å‰ã®R", use_container_width=True)
with c3:
    next_clicked = st.button("æ¬¡ã®R â–¶", use_container_width=True)
if prev_clicked:
    st.session_state["race_no_main"] = max(1, int(race_no_input) - 1); st.rerun()
elif next_clicked:
    st.session_state["race_no_main"] = min(12, int(race_no_input) + 1); st.rerun()
else:
    st.session_state["race_no_main"] = int(race_no_input)
race_no = int(st.session_state["race_no_main"])
# â–²â–²

# ãƒ©ã‚¤ãƒ³å…¥åŠ›
st.subheader("ãƒ©ã‚¤ãƒ³æ§‹æˆï¼ˆæœ€å¤§7ï¼šå˜é¨ã‚‚1ãƒ©ã‚¤ãƒ³ï¼‰")
line_inputs = [
    st.text_input("ãƒ©ã‚¤ãƒ³1ï¼ˆä¾‹ï¼š317ï¼‰", key="line_1", max_chars=9),
    st.text_input("ãƒ©ã‚¤ãƒ³2ï¼ˆä¾‹ï¼š6ï¼‰", key="line_2", max_chars=9),
    st.text_input("ãƒ©ã‚¤ãƒ³3ï¼ˆä¾‹ï¼š425ï¼‰", key="line_3", max_chars=9),
    st.text_input("ãƒ©ã‚¤ãƒ³4ï¼ˆä»»æ„ï¼‰", key="line_4", max_chars=9),
    st.text_input("ãƒ©ã‚¤ãƒ³5ï¼ˆä»»æ„ï¼‰", key="line_5", max_chars=9),
    st.text_input("ãƒ©ã‚¤ãƒ³6ï¼ˆä»»æ„ï¼‰", key="line_6", max_chars=9),
    st.text_input("ãƒ©ã‚¤ãƒ³7ï¼ˆä»»æ„ï¼‰", key="line_7", max_chars=9),
]
lines = [extract_car_list(x, n_cars) for x in line_inputs if str(x).strip()]
line_def, car_to_group = build_line_maps(lines)
active_cars = sorted({c for lst in lines for c in lst}) if lines else list(range(1, n_cars+1))

# å€‹äººãƒ‡ãƒ¼ã‚¿
st.subheader("å€‹äººãƒ‡ãƒ¼ã‚¿ï¼ˆç›´è¿‘4ã‹æœˆï¼šå›æ•°ï¼‰")
cols = st.columns(n_cars)
ratings, S, B = {}, {}, {}
k_esc, k_mak, k_sashi, k_mark = {}, {}, {}, {}
x1, x2, x3, x_out = {}, {}, {}, {}

for i, no in enumerate(active_cars):
    with cols[i]:
        st.markdown(f"**{no}ç•ª**")
        ratings[no] = input_float_text("å¾—ç‚¹ï¼ˆç©ºæ¬„å¯ï¼‰", key=f"pt_{no}", placeholder="ä¾‹: 55.0")
        S[no] = st.number_input("S", 0, 99, 0, key=f"s_{no}")
        B[no] = st.number_input("B", 0, 99, 0, key=f"b_{no}")
        k_esc[no]   = st.number_input("é€ƒ", 0, 99, 0, key=f"ke_{no}")
        k_mak[no]   = st.number_input("æ²", 0, 99, 0, key=f"km_{no}")
        k_sashi[no] = st.number_input("å·®", 0, 99, 0, key=f"ks_{no}")
        k_mark[no]  = st.number_input("ãƒ", 0, 99, 0, key=f"kk_{no}")
        x1[no]  = st.number_input("1ç€", 0, 99, 0, key=f"x1_{no}")
        x2[no]  = st.number_input("2ç€", 0, 99, 0, key=f"x2_{no}")
        x3[no]  = st.number_input("3ç€", 0, 99, 0, key=f"x3_{no}")
        x_out[no]= st.number_input("ç€å¤–", 0, 99, 0, key=f"xo_{no}")

# å¾—ç‚¹ã®å®Ÿæ•°ï¼ˆæœªå…¥åŠ›ã¯55.0ï¼‰
ratings_val = {no: (ratings[no] if ratings[no] is not None else 55.0) for no in active_cars}

# 1ç€ãƒ»2ç€ã®ç¸®ç´„ï¼ˆç´šåˆ¥Ã—ä¼šå ´ã®äº‹å‰åˆ†å¸ƒã‚’æ··ãœã‚‹ï¼‰
def prior_by_class(cls, style_adj):
    if "ã‚¬ãƒ¼ãƒ«" in cls: p1,p2 = 0.18,0.24
    elif "ï¼³ç´š" in cls: p1,p2 = 0.22,0.26
    elif "ãƒãƒ£ãƒ¬ãƒ³ã‚¸" in cls: p1,p2 = 0.18,0.22
    else: p1,p2 = 0.20,0.25
    p1 += 0.010*style_adj; p2 -= 0.005*style_adj
    return clamp(p1,0.05,0.60), clamp(p2,0.05,0.60)

def n0_by_n(n):
    if n<=6: return 12
    if n<=14: return 8
    if n<=29: return 5
    return 3

p1_eff, p2_eff = {}, {}
for no in active_cars:
    n = x1[no]+x2[no]+x3[no]+x_out[no]
    p1_prior, p2_prior = prior_by_class(race_class, style)
    n0 = n0_by_n(n)
    if n==0:
        p1_eff[no], p2_eff[no] = p1_prior, p2_prior
    else:
        p1_eff[no] = clamp((x1[no] + n0*p1_prior)/(n+n0), 0.0, 0.40)
        p2_eff[no] = clamp((x2[no] + n0*p2_prior)/(n+n0), 0.0, 0.50)

Form = {no: 0.7*p1_eff[no] + 0.3*p2_eff[no] for no in active_cars}

# è„šè³ªãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ï¼ˆä¼šå ´é©æ€§ï¼‰
prof_base, prof_escape, prof_sashi, prof_oikomi = {}, {}, {}, {}
for no in active_cars:
    tot = k_esc[no]+k_mak[no]+k_sashi[no]+k_mark[no]
    if tot==0: esc=mak=sashi=mark = 0.25
    else:
        esc=k_esc[no]/tot; mak=k_mak[no]/tot; sashi=k_sashi[no]/tot; mark=k_mark[no]/tot
    prof_escape[no]=esc; prof_sashi[no]=sashi; prof_oikomi[no]=mark
    base = esc*BASE_BY_KAKU["é€ƒ"] + mak*BASE_BY_KAKU["æ²"] + sashi*BASE_BY_KAKU["å·®"] + mark*BASE_BY_KAKU["ãƒ"]
    k = 0.06
    venue_bonus = k * style * ( +1.00*esc +0.40*mak -0.60*sashi -0.25*mark )
    prof_base[no] = base + clamp(venue_bonus, -0.06, +0.06)

# SBãªã—åˆè¨ˆï¼ˆç’°å¢ƒè£œæ­£ + å¾—ç‚¹å¾®è£œæ­£ï¼‰
tens_list = [ratings_val[no] for no in active_cars]
t_corr = tenscore_correction(tens_list) if active_cars else []
tens_corr = {no:t_corr[i] for i,no in enumerate(active_cars)} if active_cars else {}

rows=[]
for no in active_cars:
    role = role_in_line(no, line_def)
    wind = wind_adjust(wind_dir, wind_speed, role, prof_escape[no])
    extra = max(eff_laps-2, 0)
    fatigue_scale = 1.0 if race_class=="ï¼³ç´š" else (1.1 if race_class=="ï¼¡ç´š" else (1.2 if race_class=="ï¼¡ç´šãƒãƒ£ãƒ¬ãƒ³ã‚¸" else 1.05))
    laps_adj = (-0.10*extra*(1.0 if prof_escape[no]>0.5 else 0.0) + 0.05*extra*(1.0 if prof_oikomi[no]>0.4 else 0.0)) * fatigue_scale
    bank_b = bank_character_bonus(bank_angle, straight_length, prof_escape[no], prof_sashi[no])
    length_b = bank_length_adjust(bank_length, prof_oikomi[no])
    total_raw = (prof_base[no] + wind + cf["spread"]*tens_corr.get(no,0.0) + bank_b + length_b + laps_adj)
    rows.append([no, role, round(prof_base[no],3), wind, round(cf["spread"]*tens_corr.get(no,0.0),3),
                 round(bank_b,3), round(length_b,3), round(laps_adj,3), total_raw])

df = pd.DataFrame(rows, columns=["è»Šç•ª","å½¹å‰²","è„šè³ªåŸºæº–(ä¼šå ´)","é¢¨è£œæ­£","å¾—ç‚¹è£œæ­£","ãƒãƒ³ã‚¯è£œæ­£","å‘¨é•·è£œæ­£","å‘¨å›è£œæ­£","åˆè¨ˆ_SBãªã—_raw"])
mu = float(df["åˆè¨ˆ_SBãªã—_raw"].mean()) if not df.empty else 0.0
df["åˆè¨ˆ_SBãªã—"] = mu + 1.0*(df["åˆè¨ˆ_SBãªã—_raw"] - mu)
df_sorted_wo = df.sort_values("åˆè¨ˆ_SBãªã—", ascending=False).reset_index(drop=True)

# å€™è£œCï¼ˆå¾—ç‚¹Ã—2ç€ç‡ãƒ–ãƒ¬ãƒ³ãƒ‰ ä¸Šä½3ï¼‰
blend = {no: (ratings_val[no] + min(50.0, p2_eff[no]*100.0))/2.0 for no in active_cars}
C = [kv[0] for kv in sorted(blend.items(), key=lambda x:x[1], reverse=True)[:min(3,len(blend))]]

# ãƒ©ã‚¤ãƒ³SB
bonus_init,_ = compute_lineSB_bonus(line_def, S, B, line_factor=line_factor_eff, exclude=None, cap=cap_SB_eff, enable=line_sb_enable)
v_wo = dict(zip(df["è»Šç•ª"], df["åˆè¨ˆ_SBãªã—"]))

def anchor_score(no):
    g = car_to_group.get(no, None); role = role_in_line(no, line_def)
    sb = bonus_init.get(g,0.0) * (pos_coeff(role, 1.0) if line_sb_enable else 0.0)
    zt = zscore_list([ratings_val[n] for n in active_cars]) if active_cars else []
    zt_map = {n:float(zt[i]) for i,n in enumerate(active_cars)} if active_cars else {}
    return v_wo.get(no, -1e9) + sb + 0.01*zt_map.get(no, 0.0)

anchor_no_pre = max(C, key=lambda x: anchor_score(x)) if C else int(df_sorted_wo.loc[0,"è»Šç•ª"])

ratings_sorted = sorted(active_cars, key=lambda n: ratings_val[n], reverse=True)
ratings_rank = {no: i+1 for i, no in enumerate(ratings_sorted)}
ALLOWED_MAX_RANK = 4

C_hard = [no for no in C if ratings_rank.get(no, 999) <= ALLOWED_MAX_RANK]
C_use = C_hard if C_hard else ratings_sorted[:ALLOWED_MAX_RANK]
anchor_no = max(C_use, key=lambda x: anchor_score(x))

if anchor_no != anchor_no_pre:
    st.caption(f"â€» â—ã¯ã€ç«¶èµ°å¾—ç‚¹ ä¸Šä½{ALLOWED_MAX_RANK}ä½ä»¥å†…ã€ç¸›ã‚Šã«ã‚ˆã‚Š {anchor_no_pre}â†’{anchor_no} ã«èª¿æ•´ã—ã¦ã„ã¾ã™ã€‚")

cand_scores = [anchor_score(no) for no in C] if len(C)>=2 else [0,0]
cand_scores_sorted = sorted(cand_scores, reverse=True)
conf = cand_scores_sorted[0]-cand_scores_sorted[1] if len(cand_scores_sorted)>=2 else 0.0
spread = float(np.std(list(v_wo.values()))) if len(v_wo)>=2 else 0.0
norm = conf / (spread if spread>1e-6 else 1.0)
confidence = "å„ªä½" if norm>=1.0 else ("äº’è§’" if norm>=0.5 else "æ··ç·š")

bonus_re,_ = compute_lineSB_bonus(line_def, S, B, line_factor=line_factor_eff, exclude=anchor_no, cap=cap_SB_eff, enable=line_sb_enable)
def himo_score(no):
    g = car_to_group.get(no, None); role = role_in_line(no, line_def)
    sb = bonus_re.get(g,0.0) * (pos_coeff(role, 1.0) if line_sb_enable else 0.0)
    return v_wo.get(no, -1e9) + sb

restC = [no for no in C if no!=anchor_no]
o_no = max(restC, key=lambda x: himo_score(x)) if restC else None

def venue_match(no):
    tot = k_esc[no]+k_mak[no]+k_sashi[no]+k_mark[no]
    if tot==0: esc=mak=sashi=mark=0.25
    else:
        esc=k_esc[no]/tot; mak=k_mak[no]/tot; sashi=k_sashi[no]/tot; mark=k_mark[no]/tot
    return style * (1.00*esc + 0.40*mak - 0.60*sashi - 0.25*mark)

rank_wo = {int(df_sorted_wo.loc[i,"è»Šç•ª"]): i+1 for i in range(len(df_sorted_wo))}
lower_rank_threshold = max(5, int(np.ceil(len(df_sorted_wo)*0.6)))
lower_pool = [no for no in active_cars if rank_wo.get(no,99) >= lower_rank_threshold]

p2_C_mean = np.mean([p2_eff[no] for no in C]) if C else 0.0
min_p2 = 0.22 if race_class=="ï¼³ç´š" else 0.20

pool_filtered = [no for no in lower_pool
                 if no not in {anchor_no, o_no}
                 and ( p2_eff[no] >= min_p2 )
                 and ( p2_eff[no] <= p2_C_mean + 1e-9 )]

a_no = max(pool_filtered, key=lambda x: venue_match(x)) if pool_filtered else None
if a_no is None:
    fb = [no for no in lower_pool if no not in {anchor_no, o_no}]
    if fb: a_no = max(fb, key=lambda x: venue_match(x))

# å°é›†ç´„
result_marks, reasons = {}, {}
result_marks["â—"] = anchor_no; reasons[anchor_no] = "æœ¬å‘½(Cä¸Šä½3â†’å¾—ç‚¹4ä½ä»¥å†…ã‚²ãƒ¼ãƒˆâ†’ãƒ©ã‚¤ãƒ³SBé‡è¦–)"
if o_no is not None:
    result_marks["ã€‡"] = o_no; reasons[o_no] = "å¯¾æŠ—(Cæ®‹ã‚Šâ†’â—é™¤å¤–SBå†è¨ˆç®—)"
if a_no is not None:
    result_marks["â–²"] = a_no; reasons[a_no] = "å˜ç©´(SBãªã—ä¸‹ä½Ã—ä¼šå ´é©åˆÃ—2ç€%)"

used = set(result_marks.values())
for m,no in zip([m for m in ["â–³","Ã—","Î±","Î²"] if m not in result_marks],
                [int(df_sorted_wo.loc[i,"è»Šç•ª"]) for i in range(len(df_sorted_wo)) if int(df_sorted_wo.loc[i,"è»Šç•ª"]) not in used]):
    result_marks[m]=no

# å‡ºåŠ›ï¼ˆSBãªã—ãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼‰
st.markdown("### ãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼†å°ï¼ˆâ—=å¾—ç‚¹4ä½ä»¥å†…ã‚²ãƒ¼ãƒˆ / ã€‡=å®‰å®š / â–²=é€†è¥²ï¼‰")
velobi_wo = list(zip(df_sorted_wo["è»Šç•ª"].astype(int).tolist(), df_sorted_wo["åˆè¨ˆ_SBãªã—"].round(3).tolist()))

rows_out=[]
for r,(no,sc) in enumerate(velobi_wo, start=1):
    mark = "".join([m for m,v in result_marks.items() if v==no])
    n_tot = x1.get(no,0)+x2.get(no,0)+x3.get(no,0)+x_out.get(no,0)
    p1 = (x1.get(no,0)/(n_tot+1e-9))*100
    p2 = (x2.get(no,0)/(n_tot+1e-9))*100
    rows_out.append({
        "é †(SBãªã—)": r, "å°": mark, "è»Š": no,
        "SBãªã—ã‚¹ã‚³ã‚¢": sc,
        "å¾—ç‚¹": ratings_val.get(no, None),
        "1ç€å›": x1.get(no,0), "2ç€å›": x2.get(no,0), "3ç€å›": x3.get(no,0), "ç€å¤–": x_out.get(no,0),
        "1ç€%": round(p1,1), "2ç€%": round(p2,1),
        "ãƒ©ã‚¤ãƒ³": car_to_group.get(no,"-")
    })
st.dataframe(pd.DataFrame(rows_out), use_container_width=True)

st.markdown("#### è£œæ­£å†…è¨³ï¼ˆSBãªã—ï¼‰")
show=[]
for no,_ in velobi_wo:
    rec = df[df["è»Šç•ª"]==no].iloc[0]
    show.append({
        "è»Š":int(no),"ãƒ©ã‚¤ãƒ³":car_to_group.get(int(no),"-"),
        "è„šè³ªåŸºæº–(ä¼šå ´)":round(rec["è„šè³ªåŸºæº–(ä¼šå ´)"],3),
        "é¢¨è£œæ­£":rec["é¢¨è£œæ­£"],"å¾—ç‚¹è£œæ­£":rec["å¾—ç‚¹è£œæ­£"],
        "ãƒãƒ³ã‚¯è£œæ­£":rec["ãƒãƒ³ã‚¯è£œæ­£"],"å‘¨é•·è£œæ­£":rec["å‘¨é•·è£œæ­£"],
        "å‘¨å›è£œæ­£":rec["å‘¨å›è£œæ­£"],"åˆè¨ˆ_SBãªã—_raw":round(rec["åˆè¨ˆ_SBãªã—_raw"],3),
        "åˆè¨ˆ_SBãªã—":round(rec["åˆè¨ˆ_SBãªã—"],3)
    })
st.dataframe(pd.DataFrame(show), use_container_width=True)

st.caption(
    f"ç«¶è¼ªå ´ã€€{track}{race_no}R / {race_time}ã€€{race_class} / "
    f"é–‹å‚¬æ—¥ï¼š{day_label}ï¼ˆlineä¿‚æ•°={line_factor_eff:.2f}, SBcapÂ±{cap_SB_eff:.2f}ï¼‰ / "
    f"ä¼šå ´ã‚¹ã‚¿ã‚¤ãƒ«:{style:+.2f} / é¢¨:{wind_dir} / æœ‰åŠ¹å‘¨å›={eff_laps} / å±•é–‹è©•ä¾¡ï¼š**{confidence}**ï¼ˆNorm={norm:.2f}ï¼‰"
)

# ==============================
# è²·ã„ç›®ï¼ˆæƒ³å®šçš„ä¸­ç‡ â†’ å¿…è¦ã‚ªãƒƒã‚º=1/pï¼‰
# ==============================
st.markdown("### ğŸ¯ è²·ã„ç›®ï¼ˆæƒ³å®šçš„ä¸­ç‡ â†’ å¿…è¦ã‚ªãƒƒã‚º=1/pï¼‰")

one = result_marks.get("â—", None)
two = result_marks.get("ã€‡", None)
three = result_marks.get("â–²", None)

if one is None:
    st.warning("â—æœªæ±ºå®šã®ãŸã‚è²·ã„ç›®ã¯ã‚¹ã‚­ãƒƒãƒ—")
    trioC_df = wide_df = qn_df = ex_df = santan_df = None
else:
    # å¼·ã•ãƒ™ã‚¯ãƒˆãƒ«ï¼šSBãªã—ã‚¹ã‚³ã‚¢ â†’ æ¨™æº–åŒ–softmaxï¼ˆbaseï¼‰
    strength_map = dict(velobi_wo)
    xs = np.array([strength_map.get(i,0.0) for i in range(1, n_cars+1)], dtype=float)
    if xs.std() < 1e-12:
        base = np.ones_like(xs)/len(xs)
    else:
        z = (xs - xs.mean())/(xs.std()+1e-12)
        base = np.exp(z); base = base/base.sum()

    # --- åˆ¸ç¨®åˆ¥ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç”¨ï¼šå°â†’è»Šç•ª ---
    mark_by_car = {car: None for car in range(1, n_cars+1)}
    for mk, car in result_marks.items():
        if car is not None and 1 <= car <= n_cars:
            mark_by_car[car] = mk

    # å±•é–‹è©•ä¾¡ã§ã‚¹ã‚±ãƒ¼ãƒ«
    expo = 0.7 if confidence == "å„ªä½" else (1.0 if confidence == "äº’è§’" else 1.3)

    def calibrate_probs(base_vec: np.ndarray, stat_key: str) -> np.ndarray:
        """
        stat_key âˆˆ {'p1','pTop2','pTop3'}
        å°ã”ã¨ã®ç›®æ¨™ç‡ã§ base ã‚’ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã—ã¦æ­£è¦åŒ–
        """
        m = np.ones(n_cars, dtype=float)
        for idx, car in enumerate(range(1, n_cars+1)):
            mk = mark_by_car.get(car)
            if mk not in RANK_STATS:
                mk = RANK_FALLBACK_MARK
            tgt = float(RANK_STATS[mk][stat_key])
            ratio = tgt / max(float(base_vec[idx]), 1e-9)
            m[idx] = float(np.clip(ratio**(0.5*expo), 0.25, 2.5))
        probs = base_vec * m
        probs = probs / probs.sum()
        return probs

    # åˆ¸ç¨®ã”ã¨ã®åˆ†å¸ƒï¼šãƒ¯ã‚¤ãƒ‰/ä¸‰è¤‡=Top3ã€äºŒè¤‡=Top2ã€äºŒå˜/ä¸‰å˜=1ç€
    probs_p3 = calibrate_probs(base, "pTop3")  # ãƒ¯ã‚¤ãƒ‰ãƒ»ä¸‰é€£è¤‡
    probs_p2 = calibrate_probs(base, "pTop2")  # äºŒè»Šè¤‡
    probs_p1 = calibrate_probs(base, "p1")     # äºŒè»Šå˜ãƒ»ä¸‰é€£å˜

    # --- ã“ã“ã‚’æ¡ä»¶ä¾å­˜ã®ã‚·ãƒ¼ãƒ‰ã«å¤‰æ›´ï¼ˆå†ç¾æ€§Ã—å¤‰åŒ–ã®ä¸¡ç«‹ï¼‰ ---
    seed = abs(hash((track, race_no, n_cars, confidence))) % (2**32)
    rng = np.random.default_rng(seed)

    trials = st.slider("ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³è©¦è¡Œå›æ•°", 1000, 20000, 8000, 1000)

    def sample_order_from_probs(pvec: np.ndarray) -> list[int]:
        # Plackettâ€“Luceé¢¨ã®Gumbelãƒã‚¤ã‚ºé †ä½æ±ºå®š
        g = -np.log(-np.log(np.clip(rng.random(len(pvec)), 1e-12, 1-1e-12)))
        score = np.log(pvec+1e-12) + g
        return (np.argsort(-score)+1).tolist()

    mates = [x for x in [two, three] if x is not None]
    all_others = [i for i in range(1, n_cars+1) if i != one]

    # === ã‚«ã‚¦ãƒ³ãƒˆå™¨ ===
    trioC_counts = {}
    wide_counts = {k:0 for k in all_others}
    qn_counts   = {k:0 for k in all_others}
    ex_counts   = {k:0 for k in all_others}
    st3_counts  = {}  # ä¸‰é€£å˜ï¼ˆâ—â†’[ç›¸æ‰‹]â†’å…¨ï¼‰ï¼š key=(second,third) -> å›æ•°

    # ä¸‰é€£è¤‡Cã®çµ„ã¿åˆã‚ã›ï¼ˆâ—-[ç›¸æ‰‹]-å…¨ï¼‰
    trioC_list = []
    if len(mates) > 0:
        for a in all_others:
            for b in all_others:
                if a >= b: continue
                if (a in mates) or (b in mates):
                    t = tuple(sorted([a, b, one]))
                    trioC_list.append(t)
        trioC_list = sorted(set(trioC_list))

    # === ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ ===
    for _ in range(trials):
        # ãƒ¯ã‚¤ãƒ‰/ä¸‰é€£è¤‡ï¼šTop3ç‡ãƒ™ãƒ¼ã‚¹
        order_p3 = sample_order_from_probs(probs_p3)
        top3_p3 = set(order_p3[:3]); top2_p3 = set(order_p3[:2])

        if one in top3_p3:
            for k in wide_counts.keys():
                if k in top3_p3:
                    wide_counts[k] += 1
            if len(trioC_list) > 0:
                others = list(top3_p3 - {one})
                if len(others) == 2:
                    a, b = sorted(others)
                    if (a in mates) or (b in mates):
                        t = tuple(sorted([a, b, one]))
                        if t in trioC_list:
                            trioC_counts[t] = trioC_counts.get(t, 0) + 1

        # äºŒè»Šè¤‡ï¼šé€£å¯¾ç‡ãƒ™ãƒ¼ã‚¹
        order_p2 = sample_order_from_probs(probs_p2)
        top2_p2 = set(order_p2[:2])
        if one in top2_p2:
            for k in qn_counts.keys():
                if k in top2_p2:
                    qn_counts[k] += 1

        # äºŒè»Šå˜/ä¸‰é€£å˜ï¼š1ç€ç‡ãƒ™ãƒ¼ã‚¹
        order_p1 = sample_order_from_probs(probs_p1)
        if order_p1[0] == one:
            k2 = order_p1[1]
            if k2 in ex_counts:
                ex_counts[k2] += 1
            # ä¸‰é€£å˜ï¼ˆâ—â†’[ç›¸æ‰‹]â†’å…¨ï¼‰ï¼š2ç€ã¯ {ã€‡,â–²} é™å®šã€3ç€ã¯å…¨ï¼ˆãŸã ã—é‡è¤‡ä¸å¯ï¼‰
            if len(mates) > 0:
                k3 = order_p1[2]
                if (k2 in mates) and (k3 not in (one, k2)):
                    st3_counts[(k2, k3)] = st3_counts.get((k2, k3), 0) + 1

    # ====== Pãƒ•ãƒ­ã‚¢ï¼ˆæœ€ä½æƒ³å®špï¼‰ã¨EVå¸¯ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯globalsã‚’å°Šé‡ï¼‰ ======
    _P_FLOOR_BASE = globals().get("P_FLOOR", {
        "wide": 0.060, "sanpuku": 0.040, "nifuku": 0.050, "nitan": 0.040, "santan": 0.030
    })
    P_FLOOR = dict(_P_FLOOR_BASE)  # ã‚³ãƒ”ãƒ¼ã—ã¦ã‹ã‚‰åŠ å·¥

    # å±•é–‹ã§è¤‡ç³»ã ã‘å¾®èª¿æ•´ï¼ˆÂ±10%ï¼‰
    scale = 1.00
    if confidence == "å„ªä½":   scale = 0.90
    elif confidence == "æ··ç·š": scale = 1.10
    for k in ("wide","sanpuku","nifuku"):
        P_FLOOR[k] *= scale

    E_MIN = globals().get("E_MIN", 0.00)   # æœŸå¾…å€¤ä¸‹é™ï¼ˆ0%ï¼‰
    E_MAX = globals().get("E_MAX", 0.50)   # æœŸå¾…å€¤ä¸Šé™ï¼ˆ+50%ï¼‰

    def need_from_count(cnt: int) -> Optional[float]:
        if cnt <= 0: return None
        p = cnt / trials
        return round(1.0 / p, 2)

    # === ä¸‰é€£è¤‡C ===
    if len(trioC_list) > 0:
        rows = []
        for t in trioC_list:
            cnt = trioC_counts.get(t, 0)
            p = cnt / trials
            rows.append({
                "è²·ã„ç›®": f"{t[0]}-{t[1]}-{t[2]}",
                "p(æƒ³å®šçš„ä¸­ç‡)": round(p, 4),
                "å¿…è¦ã‚ªãƒƒã‚º(=1/p)": "-" if cnt==0 else need_from_count(cnt)
            })
        trioC_df = pd.DataFrame(rows)
        st.markdown("#### ä¸‰é€£è¤‡Cï¼ˆâ—-[ç›¸æ‰‹]-å…¨ï¼‰â€»è»Šç•ªé †")
        # è»Šç•ªé †ã§ã‚½ãƒ¼ãƒˆ
        def _key_nums_tri(s): return list(map(int, re.findall(r"\d+", s)))
        trioC_df = trioC_df.sort_values(by="è²·ã„ç›®", key=lambda s: s.map(_key_nums_tri)).reset_index(drop=True)
        st.dataframe(trioC_df, use_container_width=True)
    else:
        trioC_df = None
        st.info("ä¸‰é€£è¤‡Cï¼šç›¸æ‰‹ï¼ˆã€‡/â–²ï¼‰ãŒæœªè¨­å®šã®ãŸã‚è¡¨ç¤ºãªã—")

    # === ä¸‰é€£è¤‡ãƒã‚¹ã‚±ãƒƒãƒˆåˆæˆã‚ªãƒƒã‚ºã¨ã€Œç›¸æ‰‹é›†åˆSã€ ===
    S = set()
    O_combo = None
    if trioC_df is not None and len(trioC_df) > 0:
        need_list = []
        for _, r in trioC_df.iterrows():
            name = str(r["è²·ã„ç›®"])
            nums = list(map(int, re.findall(r"\d+", name)))
            # â—ï¼ˆoneï¼‰ä»¥å¤–ã‚’ç›¸æ‰‹é›†åˆã«åŠ ãˆã‚‹
            others = [x for x in nums if x != one]
            S.update(others)
            # ä¸‹é™å¿…è¦ã‚ªãƒƒã‚ºï¼ˆæ•°å€¤ã®ã¿é›†è¨ˆï¼‰
            need_val = r.get("å¿…è¦ã‚ªãƒƒã‚º(=1/p)")
            if isinstance(need_val, (int, float)):
                if float(need_val) > 0:
                    need_list.append(float(need_val))
        if need_list:
            denom = sum(1.0/x for x in need_list if x > 0)
            if denom > 0:
                O_combo = 1.0 / denom
                O_combo = float(f"{O_combo:.2f}")

    if O_combo is not None and len(S) > 0:
        st.caption(f"ä¸‰é€£è¤‡ãƒã‚¹ã‚±ãƒƒãƒˆåˆæˆã‚ªãƒƒã‚ºï¼ˆä¸‹é™åŸºæº–ï¼‰ï¼š**{O_combo:.2f}å€** / ç›¸æ‰‹é›†åˆSï¼š{sorted(list(S))}")
    elif trioC_df is not None and len(trioC_df) > 0:
        st.caption("ä¸‰é€£è¤‡ãƒã‚¹ã‚±ãƒƒãƒˆåˆæˆã‚ªãƒƒã‚ºï¼šç®—å‡ºä¸å¯ï¼ˆå¿…è¦ã‚ªãƒƒã‚ºãŒ'-'ã®ã¿ï¼‰")

    # === ãƒ¯ã‚¤ãƒ‰ï¼ˆâ—-å…¨ï¼‰â€” ä¸‰é€£è¤‡ã¨è¢«ã‚‹å´ã¯åˆæˆã‚ªãƒƒã‚ºã§è¶³åˆ‡ã‚Šï¼æ¼ã‚Œå´ã¯å¿…è¦ã‚ªãƒƒã‚ºã§OK ===
    rows = []
    for k in sorted(wide_counts.keys()):
        cnt = wide_counts[k]
        p = cnt / trials
        # pãƒ•ãƒ­ã‚¢ãƒã‚§ãƒƒã‚¯ï¼ˆã¾ãšå€™è£œã«ã™ã‚‹ï¼‰
        if p < P_FLOOR.get("wide", 0.06):
            continue
        need = None if cnt == 0 else (1.0 / p)
        if need is None or need <= 0:
            continue

        # è¢«ã‚Šå´ï¼ˆk âˆˆ Sï¼‰ã¯åˆæˆã‚ªãƒƒã‚ºåŸºæº–ã‚’é©ç”¨
        eligible = True
        rule_note = "å¿…è¦ã‚ªãƒƒã‚ºä»¥ä¸Š"
        if (O_combo is not None) and (k in S):
            if need >= O_combo:
                eligible = True
                rule_note = f"ä¸‰è¤‡è¢«ã‚Šâ†’åˆæˆ{O_combo:.2f}å€ä»¥ä¸Š"
            else:
                eligible = False

        if not eligible:
            continue

        rows.append({
            "è²·ã„ç›®": f"{one}-{k}",
            "p(æƒ³å®šçš„ä¸­ç‡)": round(p, 4),
            "å¿…è¦ã‚ªãƒƒã‚º(=1/p)": round(need, 2),
            "ãƒ«ãƒ¼ãƒ«": rule_note
        })

    wide_df = pd.DataFrame(rows)
    st.markdown("#### ãƒ¯ã‚¤ãƒ‰ï¼ˆâ—-å…¨ï¼‰â€»è»Šç•ªé †")
    if len(wide_df) > 0:
        def _key_nums_w(s): return list(map(int, re.findall(r"\d+", s)))
        wide_df = wide_df.sort_values(by("è²·ã„ç›®"), key=lambda s: s.map(_key_nums_w)).reset_index(drop=True)
        # â†‘ ä¸Šè¡Œã®ã‚¿ã‚¤ãƒä¿®æ­£: sort_values(by=...) ãŒæ­£
        wide_df = wide_df.sort_values(by="è²·ã„ç›®", key=lambda s: s.map(_key_nums_w)).reset_index(drop=True)
        st.dataframe(wide_df, use_container_width=True)
        if O_combo is not None:
            st.caption("â€»ä¸‰é€£è¤‡ã§ä½¿ç”¨ã—ãŸç›¸æ‰‹ï¼ˆSå´ï¼‰ã¯ **åˆæˆã‚ªãƒƒã‚ºä»¥ä¸Š**ã®ãƒ¯ã‚¤ãƒ‰ã®ã¿æ¡ç”¨ã€‚Så¤–ã¯ **å¿…è¦ã‚ªãƒƒã‚ºä»¥ä¸Š**ã§æ¡ç”¨ã€‚ãƒ¯ã‚¤ãƒ‰ã¯ä¸Šé™æ’¤å»ƒï¼ã€â—¯å€ä»¥ä¸Šã§è²·ã„ã€ã€‚")
        else:
            st.caption("â€»ä¸‰é€£è¤‡ãŒç„¡ã„ï¼åˆæˆä¸å¯ã®å ´åˆã€ãƒ¯ã‚¤ãƒ‰ã¯ **å¿…è¦ã‚ªãƒƒã‚ºä»¥ä¸Š**ã§æ¡ç”¨ï¼ˆä¸Šé™æ’¤å»ƒï¼‰ã€‚")
    else:
        st.info("ãƒ¯ã‚¤ãƒ‰ï¼šå¯¾è±¡å¤–ï¼ˆPãƒ•ãƒ­ã‚¢æœªæº€ã€ã¾ãŸã¯åˆæˆã‚ªãƒƒã‚ºåŸºæº–ã§é™¤å¤–ï¼‰")

    # === äºŒè»Šè¤‡ ===
    rows = []
    for k in sorted(qn_counts.keys()):
        cnt = qn_counts[k]; p = cnt / trials
        if p < P_FLOOR.get("nifuku", 0.05):  # pãƒ•ãƒ­ã‚¢é©ç”¨
            continue
        need = None if cnt==0 else (1.0/p)
        if need is None: continue
        low, high = need*(1.0+E_MIN), need*(1.0+E_MAX)
        rows.append({
            "è²·ã„ç›®": f"{one}-{k}",
            "p(æƒ³å®šçš„ä¸­ç‡)": round(p, 4),
            "è²·ãˆã‚‹å¸¯": f"{low:.1f}ã€œ{high:.1f}å€ãªã‚‰è²·ã„"
        })
    qn_df = pd.DataFrame(rows)
    st.markdown("#### äºŒè»Šè¤‡ï¼ˆâ—-å…¨ï¼‰â€»è»Šç•ªé †")
    if len(qn_df) > 0:
        def _key_nums_qn(s): return list(map(int, re.findall(r"\d+", s)))
        qn_df = qn_df.sort_values(by="è²·ã„ç›®", key=lambda s: s.map(_key_nums_qn)).reset_index(drop=True)
        st.dataframe(qn_df, use_container_width=True)
    else:
        st.info("äºŒè»Šè¤‡ï¼šå¯¾è±¡å¤–")

    # === äºŒè»Šå˜ ===
    rows = []
    for k in sorted(ex_counts.keys()):
        cnt = ex_counts[k]; p = cnt / trials
        if p < P_FLOOR.get("nitan", 0.04):
            continue
        need = None if cnt==0 else (1.0/p)
        if need is None: continue
        low, high = need*(1.0+E_MIN), need*(1.0+E_MAX)
        rows.append({
            "è²·ã„ç›®": f"{one}->{k}",
            "p(æƒ³å®šçš„ä¸­ç‡)": round(p, 4),
            "è²·ãˆã‚‹å¸¯": f"{low:.1f}ã€œ{high:.1f}å€ãªã‚‰è²·ã„"
        })
    ex_df = pd.DataFrame(rows)
    st.markdown("#### äºŒè»Šå˜ï¼ˆâ—â†’å…¨ï¼‰â€»è»Šç•ªé †")
    if len(ex_df) > 0:
        def _key_nums_ex(s): return list(map(int, re.findall(r"\d+", s)))
        ex_df = ex_df.sort_values(by="è²·ã„ç›®", key=lambda s: s.map(_key_nums_ex)).reset_index(drop=True)
        st.dataframe(ex_df, use_container_width=True)
    else:
        st.info("äºŒè»Šå˜ï¼šå¯¾è±¡å¤–")

    # === ä¸‰é€£å˜ï¼ˆâ—â†’[ç›¸æ‰‹]â†’å…¨ï¼‰ ===
    rows = []
    p_floor_santan = P_FLOOR.get("santan", 0.03)
    for (sec, thr), cnt in st3_counts.items():
        p = cnt / trials
        if p < p_floor_santan or p <= 0:
            continue
        need = 1.0 / p
        low, high = need*(1.0+E_MIN), need*(1.0+E_MAX)
        rows.append({
            "è²·ã„ç›®": f"{one}->{sec}->{thr}",
            "p(æƒ³å®šçš„ä¸­ç‡)": round(p, 5),
            "è²·ãˆã‚‹å¸¯": f"{low:.1f}ã€œ{high:.1f}å€ãªã‚‰è²·ã„"
        })
    if rows:
        santan_df = pd.DataFrame(rows)
        def _key_nums_st(s): return list(map(int, re.findall(r"\d+", s)))
        santan_df = santan_df.sort_values(by="è²·ã„ç›®", key=lambda s: s.map(_key_nums_st)).reset_index(drop=True)
        st.markdown("#### ä¸‰é€£å˜ï¼ˆâ—â†’[ç›¸æ‰‹]â†’å…¨ï¼‰â€»è»Šç•ªé †")
        st.dataframe(santan_df, use_container_width=True)
    else:
        santan_df = None
        st.info("ä¸‰é€£å˜ï¼šå¯¾è±¡å¤–ï¼ˆPãƒ•ãƒ­ã‚¢æœªæº€ãƒ»ç›¸æ‰‹æœªè¨­å®šãƒ»è©²å½“ãªã—ï¼‰")

# ==============================
# noteç”¨ï¼šãƒ˜ãƒƒãƒ€ãƒ¼ã€œå±•é–‹è©•ä¾¡ ï¼‹ ã€Œè²·ãˆã‚‹ã‚ªãƒƒã‚ºå¸¯ã€ï¼ˆæ–‡ç« å½¢å¼ãƒ»è»Šç•ªé †ï¼‰
# ==============================
st.markdown("### ğŸ“‹ noteç”¨ï¼ˆãƒ˜ãƒƒãƒ€ãƒ¼ã€œå±•é–‹è©•ä¾¡ï¼‹â€œè²·ãˆã‚‹ã‚ªãƒƒã‚ºå¸¯â€ï¼‰")

def _format_line_zone_note(name: str, bet_type: str, p: float) -> Optional[str]:
    floor = P_FLOOR.get(bet_type, 0.03 if bet_type=="santan" else 0.0)
    if p < floor: return None
    need = 1.0 / max(p, 1e-12)
    if bet_type == "wide":
        return f"{name}ï¼š{need:.1f}å€ä»¥ä¸Šã§è²·ã„"  # ä¸Šé™æ’¤å»ƒ
    low, high = need*(1.0+E_MIN), need*(1.0+E_MAX)
    return f"{name}ï¼š{low:.1f}ã€œ{high:.1f}å€ãªã‚‰è²·ã„"

def _zone_lines_from_df(df: pd.DataFrame | None, bet_type_key: str) -> list[str]:
    if df is None or len(df) == 0 or "è²·ã„ç›®" not in df.columns:
        return []
    rows = []
    for _, r in df.iterrows():
        name = str(r["è²·ã„ç›®"])
        if "è²·ãˆã‚‹å¸¯" in r and r["è²·ãˆã‚‹å¸¯"]:
            rows.append((name, f"{name}ï¼š{r['è²·ãˆã‚‹å¸¯']}"))
        else:
            p = float(r.get("p(æƒ³å®šçš„ä¸­ç‡)", 0.0) or 0.0)
            line_txt = _format_line_zone_note(name, bet_type_key, p)
            if line_txt:
                rows.append((name, line_txt))
    rows_sorted = sorted(rows, key=lambda x: _sort_key_by_numbers(x[0]))
    return [ln for _, ln in rows_sorted]

def _section_text(title: str, lines: list[str]) -> str:
    if not lines: return f"{title}\nå¯¾è±¡å¤–"
    return f"{title}\n" + "\n".join(lines)

line_text = "ã€€".join([x for x in line_inputs if str(x).strip()])
score_order_text = " ".join(str(no) for no,_ in velobi_wo)
marks_line = " ".join(f"{m}{result_marks[m]}" for m in ["â—","ã€‡","â–²","â–³","Ã—","Î±","Î²"] if m in result_marks)

txt_trioC = _section_text("ä¸‰é€£è¤‡Cï¼ˆâ—-[ç›¸æ‰‹]-å…¨ï¼‰",
                          _zone_lines_from_df(trioC_df, "sanpuku"))
txt_st    = _section_text("ä¸‰é€£å˜ï¼ˆâ—â†’[ç›¸æ‰‹]â†’å…¨ï¼‰",
                          _zone_lines_from_df(santan_df, "santan"))
txt_wide  = _section_text("ãƒ¯ã‚¤ãƒ‰ï¼ˆâ—-å…¨ï¼‰",
                          _zone_lines_from_df(wide_df, "wide"))
txt_qn    = _section_text("äºŒè»Šè¤‡ï¼ˆâ—-å…¨ï¼‰",
                          _zone_lines_from_df(qn_df, "nifuku"))
txt_ex    = _section_text("äºŒè»Šå˜ï¼ˆâ—â†’å…¨ï¼‰",
                          _zone_lines_from_df(ex_df, "nitan"))

# ãƒ«ãƒ¼ãƒ«æ³¨è¨˜ï¼ˆnoteä¸‹éƒ¨ï¼‰
wide_rule_note = "ï¼ˆãƒ¯ã‚¤ãƒ‰ã¯ä¸Šé™æ’¤å»ƒï¼šä¸‰é€£è¤‡ã§ä½¿ç”¨ã—ãŸç›¸æ‰‹ã¯åˆæˆã‚ªãƒƒã‚ºä»¥ä¸Šï¼ä¸‰é€£è¤‡ã‹ã‚‰æ¼ã‚ŒãŸç›¸æ‰‹ã¯å¿…è¦ã‚ªãƒƒã‚ºä»¥ä¸Šã§è²·ã„ï¼‰"

note_text = (
    f"ç«¶è¼ªå ´ã€€{track}{race_no}R\n"
    f"å±•é–‹è©•ä¾¡ï¼š{confidence}\n"
    f"{race_time}ã€€{race_class}\n"
    f"ãƒ©ã‚¤ãƒ³ã€€{line_text}\n"
    f"ã‚¹ã‚³ã‚¢é †ï¼ˆSBãªã—ï¼‰ã€€{score_order_text}\n"
    f"{marks_line}\n"
    f"\n"
    f"{txt_trioC}\n\n"
    f"{txt_st}\n\n"
    f"{txt_wide}\n\n"
    f"{txt_qn}\n\n"
    f"{txt_ex}\n"
    f"\nï¼ˆâ€»â€œå¯¾è±¡å¤–â€ï¼Pãƒ•ãƒ­ã‚¢æœªæº€ã€‚ã©ã‚“ãªã‚ªãƒƒã‚ºã§ã‚‚è²·ã‚ãªã„ï¼‰\n"
    f"{wide_rule_note}"
)

st.text_area("ã“ã“ã‚’é¸æŠã—ã¦ã‚³ãƒ”ãƒ¼", note_text, height=380)
